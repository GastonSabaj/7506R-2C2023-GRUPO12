{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iodHrXdgUKTi"
      },
      "source": [
        "#Checkpoint 4: Redes Neuronales\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd_9WAQtVDCw"
      },
      "source": [
        "Enunciado:\n",
        "\n",
        "* Construir una red neuronal para clasificación y mejorar su performance mediante la búsqueda de arquitectura e hiperparámetros adecuados.\n",
        "* Evaluar la performance de todos los modelos en entrenamiento y validación, explicar todas las métricas y mostrar la matriz de confusión.\n",
        "* Generar predicciones con el conjunto de test y realizar los submits correspondientes en la competencia de Kaggle.\n",
        "* Generar las conclusiones finales del trabajo práctico evaluando la performance de todos los modelos entrenados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKuIKN_SUfcR"
      },
      "source": [
        "## Importamos librerías y datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFMh-2sCSbjM"
      },
      "source": [
        "Importamos librerías:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbCC9MfvRxV0",
        "outputId": "928fa9e9-abd2-49b1-a204-7d8b8f980f04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.5-py3-none-any.whl (129 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.5/129.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-core (from keras-tuner)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-tuner) (1.23.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-tuner) (13.6.0)\n",
            "Collecting namex (from keras-core->keras-tuner)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-tuner) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-tuner) (0.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras-tuner) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-tuner) (0.1.2)\n",
            "Installing collected packages: namex, kt-legacy, keras-core, keras-tuner\n",
            "Successfully installed keras-core-0.1.7 keras-tuner-1.4.5 kt-legacy-1.0.5 namex-0.0.7\n",
            "Collecting keras==2.12.0\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.14.0 requires keras<2.15,>=2.14.0, but you have keras 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.12.0\n",
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!pip install keras-tuner --upgrade\n",
        "!pip install keras==2.12.0\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#librerias para visualizar los datos\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#modelos\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.metrics import precision_score, recall_score,accuracy_score,f1_score,precision_recall_curve,roc_curve\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_tuner as kt\n",
        "\n",
        "import time\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv2s9A86SqYz"
      },
      "source": [
        "Montamos Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fRbaKrsSot7",
        "outputId": "67e10f42-caab-4797-f083-31d328d83678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0NwMJlhSdm8"
      },
      "source": [
        "Importamos datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrGrLSxwSgWz"
      },
      "outputs": [],
      "source": [
        "ds_hoteles_train = pd.read_csv('/content/drive/MyDrive/Tp_Datos_2023_2°/hoteles_train_exportado.csv')\n",
        "ds_hoteles_test = pd.read_csv('/content/drive/MyDrive/Tp_Datos_2023_2°/hotels_test.csv')\n",
        "ds_paises_continentes = pd.read_csv('/content/drive/MyDrive/Tp_Datos_2023_2°/tabla_pais_continente.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFsey0zzdE9L"
      },
      "source": [
        "### Hacemos la copia de los datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJxKyPL5dEpz"
      },
      "outputs": [],
      "source": [
        "ds_hoteles_train_copy = ds_hoteles_train.copy()\n",
        "ds_hoteles_test_copy = ds_hoteles_test.copy()\n",
        "ds_paises_continentes_copy = ds_paises_continentes.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definimos funciones"
      ],
      "metadata": {
        "id": "8oPUOPtT9YjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_regression(modelo,x,y,title=\"\",xlabel=\"x\",ylabel=\"y\"):\n",
        "    plt.figure()\n",
        "\n",
        "    plt.plot(x,y,\"o\",label=\"Valores verdaderos\")\n",
        "    plt.plot(x,modelo.predict(x),\"x\",label=\"Valores estimados\")\n",
        "\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZMa7cPR19cGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iQNUHqxUjA6"
      },
      "source": [
        "## Realizamos transformaciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwOcUbpZTBkb"
      },
      "source": [
        "Realizamos las mismas transformaciones que en el checkpoint anterior:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfbYNPCCTKOa"
      },
      "source": [
        "### En train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4U0kG-0OTOuQ"
      },
      "outputs": [],
      "source": [
        "#country / nombre_continente\n",
        "moda_country = ds_hoteles_train_copy['country'].mode().iloc[0]\n",
        "ds_hoteles_train_copy['country'].fillna(moda_country, inplace=True)\n",
        "ds_hoteles_train_copy['country'].unique()\n",
        "\n",
        "ds_paises_continentes_copy.rename(columns={'alpha-3': 'country', 'region': 'nombre_continente'}, inplace=True)\n",
        "ds_hoteles_train_copy = pd.merge(ds_hoteles_train_copy, ds_paises_continentes_copy[['country','nombre_continente']],on='country', how='left')\n",
        "\n",
        "ds_hoteles_train_copy.loc[ds_hoteles_train_copy['country'] == 'CN', 'nombre_continente'] = \"Asia\"\n",
        "ds_hoteles_train_copy.loc[ds_hoteles_train_copy['country'] == 'ATA', 'nombre_continente'] = \"Antartica\"\n",
        "\n",
        "ds_hoteles_train_copy.drop(['country'], axis=1, inplace=True)\n",
        "\n",
        "#arrival_time\n",
        "ds_hoteles_train_copy['arrival_date'] = pd.to_datetime(ds_hoteles_train_copy['arrival_date'])\n",
        "ds_hoteles_train_copy['arrival_date'] = ds_hoteles_train_copy['arrival_date'].astype(int)\n",
        "\n",
        "#One-hot encoding\n",
        "vars_a_onehot = ['hotel','market_segment','distribution_channel','reserved_room_type','assigned_room_type','deposit_type','customer_type','meal','nombre_continente']\n",
        "\n",
        "#Les aplicamos One Hot Encoding\n",
        "ds_hoteles_train_copy = pd.get_dummies(ds_hoteles_train_copy, columns=vars_a_onehot, drop_first=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "092w_6ZETL7J"
      },
      "source": [
        "### En test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB3WtIAKUaXa"
      },
      "outputs": [],
      "source": [
        "#Obtengo la moda\n",
        "moda_country = ds_hoteles_test_copy['country'].mode().iloc[0]\n",
        "\n",
        "#Reemplazar los NaN por la moda de 'country'\n",
        "ds_hoteles_test_copy['country'].fillna(moda_country, inplace=True)\n",
        "\n",
        "#Obtenemos un nuevo dataframe, donde unimos las columnas de hoteles_test_copy y df_Tabla_Pais_Continente_copy\n",
        "ds_hoteles_test_copy = pd.merge(ds_hoteles_test_copy,ds_paises_continentes_copy[['country','nombre_continente']],on='country', how='left')\n",
        "\n",
        "#Reemplazamos los valores de continente donde eran NaN (o NULL)\n",
        "ds_hoteles_test_copy.loc[ds_hoteles_test_copy['country'] == 'CN', 'nombre_continente'] = \"Asia\"\n",
        "ds_hoteles_test_copy.loc[ds_hoteles_test_copy['country'] == 'ATA', 'nombre_continente'] = \"Antartica\"\n",
        "\n",
        "#Eliminamos la variable country\n",
        "ds_hoteles_test_copy.drop(['country'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3Rf1g0xswRK"
      },
      "outputs": [],
      "source": [
        "#Me guardo la columna id antes de borrarla\n",
        "ds_hoteles_test_id = ds_hoteles_test_copy['id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTB68j-MVAqR"
      },
      "outputs": [],
      "source": [
        "#Eliminamos la columna 'company' e 'id'\n",
        "ds_hoteles_test_copy.drop([\"company\", \"id\"], axis=1, inplace=True)\n",
        "\n",
        "#Obtenemos la moda de children y agent\n",
        "moda_children = pd.Series(ds_hoteles_test_copy['children'].values.flatten()).mode()[0]\n",
        "moda_agent = pd.Series(ds_hoteles_test_copy['agent'].values.flatten()).mode()[0]\n",
        "\n",
        "#Reemplazamos los NaN de ambas columnas por la moda\n",
        "ds_hoteles_test_copy[\"children\"] = ds_hoteles_test_copy[\"children\"].fillna(moda_children)\n",
        "ds_hoteles_test_copy[\"agent\"] = ds_hoteles_test_copy[\"agent\"].fillna(moda_agent)\n",
        "\n",
        "#Reemplazamos 'Undefined' por 'SC' en la columna meal\n",
        "ds_hoteles_test_copy['meal'].replace('Undefined', 'SC', inplace = True)\n",
        "\n",
        "#Además vamos a eliminar la columna de reservation_status_date:\n",
        "ds_hoteles_test_copy.drop([\"reservation_status_date\"], axis=1,inplace=True)\n",
        "\n",
        "# Crear una nueva columna 'arrival_date' combinando las variables con el número de semana\n",
        "ds_hoteles_test_copy['arrival_date'] = pd.to_datetime(ds_hoteles_test_copy['arrival_date_year'].astype(str) + '-' + ds_hoteles_test_copy['arrival_date_month'] + '-' + ds_hoteles_test['arrival_date_day_of_month'].astype(str), format='%Y-%B-%d')\n",
        "ds_hoteles_test_copy['arrival_date'] = ds_hoteles_test_copy['arrival_date'].astype(int)\n",
        "\n",
        "#Borramos las columnas arrival_date_year; arrival_date_month; arrival_date_day_of_month\n",
        "ds_hoteles_test_copy.drop(['arrival_date_year', 'arrival_date_month', 'arrival_date_day_of_month'], axis=1,inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Flbt6VJmVTAg"
      },
      "outputs": [],
      "source": [
        "#Les aplicamos One Hot Encoding a las misma variables que en train\n",
        "ds_hoteles_test_copy = pd.get_dummies(ds_hoteles_test_copy, columns=vars_a_onehot, drop_first=True)\n",
        "\n",
        "#Creamos la variable 'assigned_room_type_L' en el dataset de test y la llenamos de ceros\n",
        "ds_hoteles_test_copy['assigned_room_type_L'] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-wIPnNLVmnQ"
      },
      "source": [
        "Ordenamos las columnas de ambos datasets alfabeticamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaZsJpd6VltQ"
      },
      "outputs": [],
      "source": [
        "ds_hoteles_train_copy = ds_hoteles_train_copy.reindex(sorted(ds_hoteles_train_copy.columns), axis=1)\n",
        "ds_hoteles_test_copy = ds_hoteles_test_copy.reindex(sorted(ds_hoteles_test_copy.columns), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVhU4MQsV5on"
      },
      "source": [
        "Comprobamos que la limpieza esté correcta:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NiuPNu3WMDX",
        "outputId": "4069cdc6-39fa-4605-9b67-0bc2ee4f2d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 61909 entries, 0 to 61908\n",
            "Data columns (total 27 columns):\n",
            " #   Column                          Non-Null Count  Dtype  \n",
            "---  ------                          --------------  -----  \n",
            " 0   hotel                           61909 non-null  object \n",
            " 1   lead_time                       61909 non-null  int64  \n",
            " 2   arrival_date_week_number        61909 non-null  int64  \n",
            " 3   stays_in_weekend_nights         61909 non-null  int64  \n",
            " 4   stays_in_week_nights            61909 non-null  int64  \n",
            " 5   adults                          61909 non-null  int64  \n",
            " 6   children                        61909 non-null  float64\n",
            " 7   babies                          61909 non-null  int64  \n",
            " 8   meal                            61909 non-null  object \n",
            " 9   country                         61688 non-null  object \n",
            " 10  market_segment                  61909 non-null  object \n",
            " 11  distribution_channel            61909 non-null  object \n",
            " 12  is_repeated_guest               61909 non-null  int64  \n",
            " 13  previous_cancellations          61909 non-null  int64  \n",
            " 14  previous_bookings_not_canceled  61909 non-null  int64  \n",
            " 15  reserved_room_type              61909 non-null  object \n",
            " 16  assigned_room_type              61909 non-null  object \n",
            " 17  booking_changes                 61909 non-null  int64  \n",
            " 18  deposit_type                    61909 non-null  object \n",
            " 19  agent                           61909 non-null  float64\n",
            " 20  days_in_waiting_list            61909 non-null  int64  \n",
            " 21  customer_type                   61909 non-null  object \n",
            " 22  adr                             61909 non-null  float64\n",
            " 23  required_car_parking_spaces     61909 non-null  int64  \n",
            " 24  total_of_special_requests       61909 non-null  int64  \n",
            " 25  is_canceled                     61909 non-null  int64  \n",
            " 26  arrival_date                    61909 non-null  object \n",
            "dtypes: float64(3), int64(14), object(10)\n",
            "memory usage: 12.8+ MB\n"
          ]
        }
      ],
      "source": [
        "ds_hoteles_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD7RipAHV5on",
        "outputId": "337a298a-6e98-49bf-84f0-351fc8a0b917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 26535 entries, 0 to 26534\n",
            "Data columns (total 31 columns):\n",
            " #   Column                          Non-Null Count  Dtype  \n",
            "---  ------                          --------------  -----  \n",
            " 0   hotel                           26535 non-null  object \n",
            " 1   lead_time                       26535 non-null  int64  \n",
            " 2   arrival_date_year               26535 non-null  int64  \n",
            " 3   arrival_date_month              26535 non-null  object \n",
            " 4   arrival_date_week_number        26535 non-null  int64  \n",
            " 5   arrival_date_day_of_month       26535 non-null  int64  \n",
            " 6   stays_in_weekend_nights         26535 non-null  int64  \n",
            " 7   stays_in_week_nights            26535 non-null  int64  \n",
            " 8   adults                          26535 non-null  int64  \n",
            " 9   children                        26535 non-null  float64\n",
            " 10  babies                          26535 non-null  int64  \n",
            " 11  meal                            26535 non-null  object \n",
            " 12  country                         26440 non-null  object \n",
            " 13  market_segment                  26535 non-null  object \n",
            " 14  distribution_channel            26535 non-null  object \n",
            " 15  is_repeated_guest               26535 non-null  int64  \n",
            " 16  previous_cancellations          26535 non-null  int64  \n",
            " 17  previous_bookings_not_canceled  26535 non-null  int64  \n",
            " 18  reserved_room_type              26535 non-null  object \n",
            " 19  assigned_room_type              26535 non-null  object \n",
            " 20  booking_changes                 26535 non-null  int64  \n",
            " 21  deposit_type                    26535 non-null  object \n",
            " 22  agent                           23172 non-null  float64\n",
            " 23  company                         1317 non-null   float64\n",
            " 24  days_in_waiting_list            26535 non-null  int64  \n",
            " 25  customer_type                   26535 non-null  object \n",
            " 26  adr                             26535 non-null  float64\n",
            " 27  required_car_parking_spaces     26535 non-null  int64  \n",
            " 28  total_of_special_requests       26535 non-null  int64  \n",
            " 29  reservation_status_date         26535 non-null  object \n",
            " 30  id                              26535 non-null  object \n",
            "dtypes: float64(4), int64(15), object(12)\n",
            "memory usage: 6.3+ MB\n"
          ]
        }
      ],
      "source": [
        "ds_hoteles_test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wio1rSiEZLjz"
      },
      "source": [
        "## Realizamos una division de train para pruebas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Leqq7nQ6cQT8"
      },
      "source": [
        "### Aplicamos el train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4Wlem3_ZQX0"
      },
      "outputs": [],
      "source": [
        "ds_hoteles_train_x = ds_hoteles_train_copy.drop('is_canceled', axis = 1)\n",
        "ds_hoteles_train_y = ds_hoteles_train_copy['is_canceled']\n",
        "\n",
        "ds_test_x = ds_hoteles_test_copy\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(ds_hoteles_train_x,\n",
        "                                                    ds_hoteles_train_y,\n",
        "                                                    test_size=0.30,\n",
        "                                                    random_state = 99,\n",
        "                                                    stratify= ds_hoteles_train['is_canceled'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como resultado, x_train contendrá el 70% de los datos originales en ds_hoteles_train_x"
      ],
      "metadata": {
        "id": "byP7swOK21Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "are_equal_size = len(ds_hoteles_train_x) == len(x_train)\n",
        "are_equal_size\n",
        "print(len(ds_hoteles_train_x))\n",
        "print(len(x_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkHOxuou2O1e",
        "outputId": "eacc6ad7-6b54-461d-96c9-611057b1f3cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61909\n",
            "43336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creamos una versión normalizada de los datasets"
      ],
      "metadata": {
        "id": "z8LbecNe90t5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Armo una version escalada con minmax (media=0 , var=1  )\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_train_minmax = min_max_scaler.fit_transform(x_train)\n",
        "y_train_minmax = y_train.values.reshape(-1, 1)\n",
        "x_test_minmax  = min_max_scaler.transform(x_test)\n",
        "\n",
        "ds_train_minmax = min_max_scaler.fit_transform(ds_hoteles_train_x)\n",
        "ds_test_minmax = min_max_scaler.fit_transform(ds_hoteles_test_copy)\n",
        "\n",
        "#Armo una version estandarizada\n",
        "stand_scaler = preprocessing.StandardScaler()\n",
        "x_train_norm = stand_scaler.fit_transform(x_train)\n",
        "x_test_norm=stand_scaler.transform(x_test)\n",
        "\n",
        "ds_train_norm = min_max_scaler.fit_transform(ds_hoteles_train_x)\n",
        "ds_test_norm = min_max_scaler.fit_transform(ds_hoteles_test_copy)\n",
        "\n",
        "#Normalizacion solo en variables no binarias\n",
        "vars_no_binarias = ['adr','adults','agent','arrival_date',\n",
        "                    'arrival_date_week_number','babies','booking_changes',\n",
        "                    'children','lead_time','previous_bookings_not_canceled',\n",
        "                    'previous_cancellations','required_car_parking_spaces',\n",
        "                    'stays_in_week_nights','stays_in_weekend_nights',\n",
        "                    'total_of_special_requests']\n",
        "\n",
        "x_train_transformed = x_train.copy()\n",
        "x_train_transformed[vars_no_binarias] = stand_scaler.fit_transform(x_train_transformed[vars_no_binarias])"
      ],
      "metadata": {
        "id": "LHxsXj7Q98Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Establecemos una semilla en común para numpy y tensorflow"
      ],
      "metadata": {
        "id": "xv3X1G8C9CuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(99)\n",
        "tf.random.set_seed(99)"
      ],
      "metadata": {
        "id": "5d2SI6ij8kBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creamos una red neuronal básica"
      ],
      "metadata": {
        "id": "orLi-kS58fEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  #tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])"
      ],
      "metadata": {
        "id": "7Rf8sHCBH2Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd_OLs9M9NsB",
        "outputId": "ae5f0c4d-88a6-4f2b-da03-857b4a348e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "XOnXZBrpIU36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "V77wAzGWIdH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train_norm, y_train, epochs=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGs9UiA_Ih_K",
        "outputId": "b13717f3-a5fc-47f1-a2b5-4be1fec0f406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "1355/1355 [==============================] - 5s 3ms/step - loss: 0.5049 - accuracy: 0.7559\n",
            "Epoch 2/8\n",
            "1355/1355 [==============================] - 3s 2ms/step - loss: 0.4278 - accuracy: 0.7855\n",
            "Epoch 3/8\n",
            "1355/1355 [==============================] - 2s 2ms/step - loss: 0.4166 - accuracy: 0.7930\n",
            "Epoch 4/8\n",
            "1355/1355 [==============================] - 2s 2ms/step - loss: 0.4073 - accuracy: 0.8002\n",
            "Epoch 5/8\n",
            "1355/1355 [==============================] - 3s 2ms/step - loss: 0.4064 - accuracy: 0.8004\n",
            "Epoch 6/8\n",
            "1355/1355 [==============================] - 3s 2ms/step - loss: 0.4000 - accuracy: 0.8029\n",
            "Epoch 7/8\n",
            "1355/1355 [==============================] - 3s 3ms/step - loss: 0.3973 - accuracy: 0.8044\n",
            "Epoch 8/8\n",
            "1355/1355 [==============================] - 2s 2ms/step - loss: 0.3933 - accuracy: 0.8066\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7aa6df94b850>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ev = model.evaluate(x_test_norm,  y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9JxYnE2Ir7L",
        "outputId": "5f2dd37b-915c-455b-93f9-c894955b4866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "581/581 - 1s - loss: 0.3950 - accuracy: 0.8081 - 896ms/epoch - 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_probs = model.predict(x_test_norm)\n",
        "y_pred  = np.argmax(y_probs, axis=-1)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXWQtQmXJKtK",
        "outputId": "a6e33321-9c28-4dcb-a198-a5077f5dc1b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "581/581 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWqig-5VLxvJ",
        "outputId": "3262b4c7-bb0e-4f4f-f3ba-9aed917020d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.86      0.82      9292\n",
            "           1       0.84      0.76      0.80      9281\n",
            "\n",
            "    accuracy                           0.81     18573\n",
            "   macro avg       0.81      0.81      0.81     18573\n",
            "weighted avg       0.81      0.81      0.81     18573\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creo la matriz de confusión\n",
        "tabla=confusion_matrix(y_test, y_pred)\n",
        "\n",
        "#Grafico la matriz de confusión\n",
        "sns.heatmap(tabla,cmap='GnBu',annot=True,fmt='g')\n",
        "plt.xlabel('Valores predichos')\n",
        "plt.ylabel('Valores reales')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "MEwMD3NVKaF6",
        "outputId": "edc6b214-408b-44b2-e1ff-4f887c04e88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(50.722222222222214, 0.5, 'Valores reales')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "L2goOhnKIRv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Armo el mismo modelo y predigo el dataset de test completo:"
      ],
      "metadata": {
        "id": "78plDEZA2qoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])"
      ],
      "metadata": {
        "id": "KkZl2AOe3FWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "RGjBrqBk3FWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(ds_train_norm, ds_hoteles_train_y, epochs=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c4f197a-c6b3-4ea0-f5a3-2198613c9700",
        "id": "0kGOSBzu3FWM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "1935/1935 [==============================] - 12s 6ms/step - loss: 0.5049 - accuracy: 0.7461\n",
            "Epoch 2/8\n",
            "1935/1935 [==============================] - 4s 2ms/step - loss: 0.4365 - accuracy: 0.7772\n",
            "Epoch 3/8\n",
            "1935/1935 [==============================] - 5s 3ms/step - loss: 0.4208 - accuracy: 0.7874\n",
            "Epoch 4/8\n",
            "1935/1935 [==============================] - 4s 2ms/step - loss: 0.4133 - accuracy: 0.7933\n",
            "Epoch 5/8\n",
            "1935/1935 [==============================] - 4s 2ms/step - loss: 0.4075 - accuracy: 0.7975\n",
            "Epoch 6/8\n",
            "1935/1935 [==============================] - 4s 2ms/step - loss: 0.4026 - accuracy: 0.7995\n",
            "Epoch 7/8\n",
            "1935/1935 [==============================] - 6s 3ms/step - loss: 0.3977 - accuracy: 0.8044\n",
            "Epoch 8/8\n",
            "1935/1935 [==============================] - 4s 2ms/step - loss: 0.3952 - accuracy: 0.8059\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7aa6dde95d20>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_probs = model.predict(ds_test_norm)\n",
        "y_pred  = np.argmax(y_probs, axis=-1)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c333c3-a5cb-43cc-a476-d5d50dd83b61",
        "id": "kXzjxwtw3FWM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "830/830 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission_red_basica = pd.DataFrame({'id': ds_hoteles_test['id'], 'is_canceled': y_pred})\n",
        "df_submission_red_basica.to_csv('/content/drive/MyDrive/Tp_Datos_2023_2°/Submission_red_neuronal_basica.csv',index=False)"
      ],
      "metadata": {
        "id": "fe2agtyn32Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission_red_basica.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVQ8hPFp4IfT",
        "outputId": "3d88c1e5-567e-448a-9d65-1b847b7ed09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 26535 entries, 0 to 26534\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   id           26535 non-null  object\n",
            " 1   is_canceled  26535 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 414.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definición de constructores de arquitecturas\n",
        "\n",
        "Vamos a crear 4 diferentes arquitecturas de redes neuronales"
      ],
      "metadata": {
        "id": "J0tIyyzp6pRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Dropout\n",
        "from keras.regularizers import l2\n",
        "\n",
        "'''\n",
        "-Tiene 2 hiperparámetros para optimizar: cant neuronas y capas ocultas\n",
        "-Utiliza al optimizador 'adam'\n",
        "-Utiliza la funcion de activación 'relu' en la capa de entrada y en las capas ocultas\n",
        "-No tiene funcion de regularización\n",
        "'''\n",
        "def create_model_1(hidden_layers=1, neurons=32):\n",
        "    optimizer = 'adam'  # Optimizador fijo para esta arquitectura\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(neurons, input_shape=(ds_train_norm.shape[1],), activation='relu'))\n",
        "    for _ in range(hidden_layers - 1):\n",
        "        model.add(keras.layers.Dense(neurons, activation='relu'))\n",
        "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "'''\n",
        "-Tiene 3 hiperparámetros para optimizar: cant neuronas y capas ocultas, optimizador\n",
        "-Utiliza la funcion de activación 'relu' para la capa de entrada y la scapas ocultas\n",
        "-No tienen regularizador\n",
        "'''\n",
        "def create_model_2(hidden_layers=2, neurons=64, optimizer='sgd'):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(neurons, input_shape=(ds_train_norm.shape[1],), activation='relu'))\n",
        "    for _ in range(hidden_layers - 1):\n",
        "        model.add(keras.layers.Dense(neurons, activation='relu'))\n",
        "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "'''\n",
        "-Tiene 3 hiperparámetros para optimizar: cant neuronas, cant capas ocultas, valor del learning_rate\n",
        "-Utiliza el optimizador SGD con un learning_rate paramétrico\n",
        "-Utiliza el regulador L2 en la capa de entrada con un valor constante de learning_rate = 0.01\n",
        "-Utiliza el regulador Dropout en las capas ocultas\n",
        "-Utiliza el regulador L2 para la capa de salida,  con un learning_rate = 0.01\n",
        "'''\n",
        "def create_model_3(hidden_layers=1, neurons=128, ln_rate_parameter=0.01):\n",
        "    # Optimizador SGD con learning rate variable\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=ln_rate_parameter)\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(neurons, input_shape=(ds_train_norm.shape[1],), activation='relu', kernel_regularizer=l2(0.01)))\n",
        "\n",
        "    for _ in range(hidden_layers - 1):\n",
        "        model.add(keras.layers.Dense(neurons, activation='relu'))\n",
        "        model.add(Dropout(0.2))  # Añado técnica de regularización por capa oculta\n",
        "\n",
        "    model.add(keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01)))\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "'''\n",
        "-Tiene 2 hiperparámetros para optimizar: cant neuronas y de capas ocultas\n",
        "-Utiliza el optimizador rmsprop\n",
        "-Utiliza el regulador L2 con un learning_rate=0.01 en la capa de entrada\n",
        "-Las capas ocultas utilizan el regulador L2 y Dropout\n",
        "'''\n",
        "def create_model_4(hidden_layers=1, neurons=64):\n",
        "    optimizer = 'rmsprop'  # Optimizador fijo para esta arquitectura\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(neurons, input_shape=(ds_train_norm.shape[1],), activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    for _ in range(hidden_layers - 1):\n",
        "        model.add(keras.layers.Dense(neurons, activation='relu', kernel_regularizer=l2(0.01))) #Añado regulizador L2 por cada capa\n",
        "        model.add(Dropout(0.2))  # Añado técnica de regularización \"DropOut\" por cada capa oculta\n",
        "\n",
        "    model.add(keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01)))\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "PrXYCrbq_f8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arquitectura 1"
      ],
      "metadata": {
        "id": "hcAHoeGtcDbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizacion de los hiperparámetros de la arquitectura 1"
      ],
      "metadata": {
        "id": "olZTeiorPNxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from scipy.stats import randint"
      ],
      "metadata": {
        "id": "7NuWCqcAxMq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
      ],
      "metadata": {
        "id": "Jto6n0tKxNVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "-Tiene 2 hiperparámetros para optimizar: cant neuronas y capas ocultas\n",
        "-Utiliza al optimizador 'adam'\n",
        "-Utiliza la funcion de activación 'relu' en la capa de entrada y en las capas ocultas\n",
        "-No tiene funcion de regularización\n",
        "'''\n",
        "def create_model_1(hidden_layers=1, neurons=32):\n",
        "    optimizer = 'adam'  # Optimizador fijo para esta arquitectura\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(neurons, input_shape=(ds_train_norm.shape[1],), activation='relu'))\n",
        "    for _ in range(hidden_layers - 1):\n",
        "        model.add(keras.layers.Dense(neurons, activation='relu'))\n",
        "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "AjKuxecfxi61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizamos hiperparámetros de arquitectura\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model_1,callbacks=[early_stopping])\n",
        "param_dist_architecture = {\n",
        "    'neurons': [16, 32, 64, 128, 256, 512],\n",
        "    'hidden_layers': [1, 2, 3, 4, 5, 6]\n",
        "}\n",
        "\n",
        "random_search_architecture = RandomizedSearchCV(estimator=model,\n",
        "                                                param_distributions=param_dist_architecture,\n",
        "                                                n_iter=4, cv=4, verbose = 4)\n",
        "\n",
        "random_search_architecture.fit(ds_train_norm, ds_hoteles_train_y,callbacks=[early_stopping])\n",
        "\n",
        "# Obtenemos los mejores hiperparámetros de arquitectura\n",
        "best_architecture = random_search_architecture.best_params_\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XeowwJPxHOF",
        "outputId": "9f1cc863-dff6-40d0-d142-f2d6c81898f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
            "1451/1451 [==============================] - 4s 2ms/step - loss: 0.4806 - accuracy: 0.7499\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.4380 - accuracy: 0.7819\n",
            "[CV 1/4] END .......hidden_layers=6, neurons=32;, score=0.782 total time=   6.1s\n",
            "1451/1451 [==============================] - 5s 3ms/step - loss: 0.4784 - accuracy: 0.7538\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.4379 - accuracy: 0.7762\n",
            "[CV 2/4] END .......hidden_layers=6, neurons=32;, score=0.776 total time=   6.7s\n",
            "1451/1451 [==============================] - 4s 2ms/step - loss: 0.4728 - accuracy: 0.7572\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.4344 - accuracy: 0.7801\n",
            "[CV 3/4] END .......hidden_layers=6, neurons=32;, score=0.780 total time=   5.5s\n",
            "1451/1451 [==============================] - 6s 3ms/step - loss: 0.4779 - accuracy: 0.7553\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.4472 - accuracy: 0.7706\n",
            "[CV 4/4] END .......hidden_layers=6, neurons=32;, score=0.771 total time=   8.2s\n",
            "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4727 - accuracy: 0.7531\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.4363 - accuracy: 0.7822\n",
            "[CV 1/4] END .......hidden_layers=2, neurons=64;, score=0.782 total time=   5.0s\n",
            "1451/1451 [==============================] - 4s 2ms/step - loss: 0.4725 - accuracy: 0.7609\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.4343 - accuracy: 0.7779\n",
            "[CV 2/4] END .......hidden_layers=2, neurons=64;, score=0.778 total time=   7.5s\n",
            "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4708 - accuracy: 0.7594\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.4415 - accuracy: 0.7733\n",
            "[CV 3/4] END .......hidden_layers=2, neurons=64;, score=0.773 total time=   4.9s\n",
            "1451/1451 [==============================] - 3s 2ms/step - loss: 0.4687 - accuracy: 0.7598\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.4357 - accuracy: 0.7803\n",
            "[CV 4/4] END .......hidden_layers=2, neurons=64;, score=0.780 total time=   4.9s\n",
            "1451/1451 [==============================] - 4s 2ms/step - loss: 0.5120 - accuracy: 0.7394\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.4745 - accuracy: 0.7684\n",
            "[CV 1/4] END .......hidden_layers=1, neurons=16;, score=0.768 total time=   7.7s\n",
            "1451/1451 [==============================] - 3s 2ms/step - loss: 0.5105 - accuracy: 0.7426\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.4657 - accuracy: 0.7653\n",
            "[CV 2/4] END .......hidden_layers=1, neurons=16;, score=0.765 total time=   4.7s\n",
            "1451/1451 [==============================] - 4s 2ms/step - loss: 0.5265 - accuracy: 0.7252\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.4763 - accuracy: 0.7601\n",
            "[CV 3/4] END .......hidden_layers=1, neurons=16;, score=0.760 total time=   5.7s\n",
            "1451/1451 [==============================] - 3s 2ms/step - loss: 0.5102 - accuracy: 0.7380\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.4749 - accuracy: 0.7559\n",
            "[CV 4/4] END .......hidden_layers=1, neurons=16;, score=0.756 total time=   4.7s\n",
            "1451/1451 [==============================] - 4s 2ms/step - loss: 0.4604 - accuracy: 0.7603\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.4247 - accuracy: 0.7925\n",
            "[CV 1/4] END ......hidden_layers=2, neurons=128;, score=0.792 total time=   4.8s\n",
            "1451/1451 [==============================] - 8s 4ms/step - loss: 0.4633 - accuracy: 0.7640\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.4287 - accuracy: 0.7799\n",
            "[CV 2/4] END ......hidden_layers=2, neurons=128;, score=0.780 total time=  10.0s\n",
            "1451/1451 [==============================] - 4s 2ms/step - loss: 0.4611 - accuracy: 0.7647\n",
            "484/484 [==============================] - 1s 2ms/step - loss: 0.4350 - accuracy: 0.7770\n",
            "[CV 3/4] END ......hidden_layers=2, neurons=128;, score=0.777 total time=   8.0s\n",
            "1451/1451 [==============================] - 10s 6ms/step - loss: 0.4606 - accuracy: 0.7640\n",
            "484/484 [==============================] - 2s 3ms/step - loss: 0.4293 - accuracy: 0.7826\n",
            "[CV 4/4] END ......hidden_layers=2, neurons=128;, score=0.783 total time=  58.9s\n",
            "1935/1935 [==============================] - 10s 5ms/step - loss: 0.4526 - accuracy: 0.7689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_architecture"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxMbV3T_8243",
        "outputId": "36916d7f-006a-47b8-d4ca-6bc2ee93adf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neurons': 128, 'hidden_layers': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que el mejor modelo para la arquitectura 1 tiene cantidad de neuronas igual a 128 y 2 capas ocultas"
      ],
      "metadata": {
        "id": "Yj1lTu7gaRFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el mejor modelo\n",
        "best_model = create_model_1(neurons=best_architecture['neurons'], hidden_layers=best_architecture['hidden_layers'])\n",
        "\n",
        "# Optimizamos hiperparámetros de entrenamiento\n",
        "param_dist_training = {\n",
        "    'epochs': [10, 20, 30, 40],\n",
        "    'batch_size': [20, 25, 30, 35]\n",
        "}\n",
        "\n",
        "random_search_training = RandomizedSearchCV(estimator=KerasClassifier(build_fn=lambda: best_model),\n",
        "                                            param_distributions=param_dist_training,\n",
        "                                            n_iter=4,\n",
        "                                            cv=3, verbose = 4)\n",
        "\n",
        "random_search_training.fit(ds_train_norm, ds_hoteles_train_y,callbacks=[early_stopping])\n",
        "\n",
        "# Obtenemos los mejores hiperparámetros\n",
        "best_training = random_search_training.best_params_\n",
        "\n",
        "# Entrenamos el modelo con el dataset completo\n",
        "best_model.fit(ds_train_norm, ds_hoteles_train_y, epochs=best_training['epochs'], batch_size=best_training['batch_size'])\n",
        "\n",
        "# Obtenemos predicciones\n",
        "y_probs = best_model.predict(ds_test_norm)\n",
        "y_predictions = (y_probs > 0.5).astype(int)\n",
        "\n",
        "y_pred = np.ravel(y_predictions)\n",
        "\n",
        "# Unimos las predicciones con su id para realizar el subbmit en Kaggle\n",
        "df_submission = pd.DataFrame({'id': ds_hoteles_test['id'], 'is_canceled': y_pred})\n",
        "df_submission.to_csv('Submission_red_neuronal_model_optimized.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHBD-RFZ8OmH",
        "outputId": "e3b358ec-176e-45f5-e2fa-4a4066eef5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "Epoch 1/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.4631 - accuracy: 0.7606\n",
            "Epoch 2/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.4226 - accuracy: 0.7865\n",
            "Epoch 3/20\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.4090 - accuracy: 0.7935\n",
            "Epoch 4/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3999 - accuracy: 0.7994\n",
            "Epoch 5/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3941 - accuracy: 0.8028\n",
            "Epoch 6/20\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.3878 - accuracy: 0.8063\n",
            "Epoch 7/20\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.3831 - accuracy: 0.8105\n",
            "Epoch 8/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3774 - accuracy: 0.8113\n",
            "Epoch 9/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3728 - accuracy: 0.8158\n",
            "Epoch 10/20\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.3691 - accuracy: 0.8186\n",
            "Epoch 11/20\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.3643 - accuracy: 0.8209\n",
            "Epoch 12/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3606 - accuracy: 0.8227\n",
            "Epoch 13/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3573 - accuracy: 0.8251\n",
            "Epoch 14/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.3536 - accuracy: 0.8264\n",
            "Epoch 15/20\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.3503 - accuracy: 0.8292\n",
            "Epoch 16/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3471 - accuracy: 0.8288\n",
            "Epoch 17/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3444 - accuracy: 0.8323\n",
            "Epoch 18/20\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.3412 - accuracy: 0.8346\n",
            "Epoch 19/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.3391 - accuracy: 0.8351\n",
            "Epoch 20/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3344 - accuracy: 0.8364\n",
            "826/826 [==============================] - 2s 2ms/step - loss: 0.3712 - accuracy: 0.8285\n",
            "[CV 1/3] END ..........batch_size=25, epochs=20;, score=0.829 total time= 1.4min\n",
            "Epoch 1/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3539 - accuracy: 0.8322\n",
            "Epoch 2/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3452 - accuracy: 0.8357\n",
            "Epoch 3/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3420 - accuracy: 0.8374\n",
            "Epoch 4/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.3374 - accuracy: 0.8383\n",
            "Epoch 5/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3338 - accuracy: 0.8410\n",
            "Epoch 6/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3300 - accuracy: 0.8437\n",
            "Epoch 7/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3286 - accuracy: 0.8434\n",
            "Epoch 8/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.3244 - accuracy: 0.8476\n",
            "Epoch 9/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3222 - accuracy: 0.8466\n",
            "Epoch 10/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3194 - accuracy: 0.8487\n",
            "Epoch 11/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.3168 - accuracy: 0.8493\n",
            "Epoch 12/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.3135 - accuracy: 0.8518\n",
            "Epoch 13/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3111 - accuracy: 0.8526\n",
            "Epoch 14/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3091 - accuracy: 0.8534\n",
            "Epoch 15/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.3066 - accuracy: 0.8545\n",
            "Epoch 16/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.3042 - accuracy: 0.8541\n",
            "Epoch 17/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3029 - accuracy: 0.8562\n",
            "Epoch 18/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.3002 - accuracy: 0.8578\n",
            "Epoch 19/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.2979 - accuracy: 0.8596\n",
            "Epoch 20/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.2957 - accuracy: 0.8594\n",
            "826/826 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8298\n",
            "[CV 2/3] END ..........batch_size=25, epochs=20;, score=0.830 total time= 1.4min\n",
            "Epoch 1/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.3323 - accuracy: 0.8423\n",
            "Epoch 2/20\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.3214 - accuracy: 0.8477\n",
            "Epoch 3/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.3156 - accuracy: 0.8495\n",
            "Epoch 4/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.3110 - accuracy: 0.8515\n",
            "Epoch 5/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.3069 - accuracy: 0.8543\n",
            "Epoch 6/20\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.3047 - accuracy: 0.8550\n",
            "Epoch 7/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.3014 - accuracy: 0.8576\n",
            "Epoch 8/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.2984 - accuracy: 0.8586\n",
            "Epoch 9/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.2961 - accuracy: 0.8596\n",
            "Epoch 10/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.2937 - accuracy: 0.8597\n",
            "Epoch 11/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.2914 - accuracy: 0.8627\n",
            "Epoch 12/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.2880 - accuracy: 0.8623\n",
            "Epoch 13/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.2857 - accuracy: 0.8646\n",
            "Epoch 14/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.2837 - accuracy: 0.8635\n",
            "Epoch 15/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.2816 - accuracy: 0.8664\n",
            "Epoch 16/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.2793 - accuracy: 0.8670\n",
            "Epoch 17/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.2773 - accuracy: 0.8680\n",
            "Epoch 18/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.2752 - accuracy: 0.8689\n",
            "Epoch 19/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.2734 - accuracy: 0.8714\n",
            "Epoch 20/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.2716 - accuracy: 0.8701\n",
            "826/826 [==============================] - 1s 2ms/step - loss: 0.3435 - accuracy: 0.8405\n",
            "[CV 3/3] END ..........batch_size=25, epochs=20;, score=0.841 total time= 2.4min\n",
            "Epoch 1/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.3088 - accuracy: 0.8543\n",
            "Epoch 2/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2952 - accuracy: 0.8580\n",
            "Epoch 3/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2905 - accuracy: 0.8603\n",
            "Epoch 4/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2857 - accuracy: 0.8635\n",
            "Epoch 5/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2814 - accuracy: 0.8644\n",
            "Epoch 6/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2787 - accuracy: 0.8667\n",
            "Epoch 7/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2755 - accuracy: 0.8687\n",
            "Epoch 8/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2739 - accuracy: 0.8698\n",
            "Epoch 9/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2705 - accuracy: 0.8723\n",
            "Epoch 10/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2681 - accuracy: 0.8723\n",
            "Epoch 11/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2662 - accuracy: 0.8744\n",
            "Epoch 12/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2640 - accuracy: 0.8730\n",
            "Epoch 13/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2608 - accuracy: 0.8767\n",
            "Epoch 14/40\n",
            "1376/1376 [==============================] - 5s 3ms/step - loss: 0.2593 - accuracy: 0.8773\n",
            "Epoch 15/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2573 - accuracy: 0.8769\n",
            "Epoch 16/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2559 - accuracy: 0.8788\n",
            "Epoch 17/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2542 - accuracy: 0.8796\n",
            "Epoch 18/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2518 - accuracy: 0.8810\n",
            "Epoch 19/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2501 - accuracy: 0.8813\n",
            "Epoch 20/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2485 - accuracy: 0.8825\n",
            "Epoch 21/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2470 - accuracy: 0.8832\n",
            "Epoch 22/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2462 - accuracy: 0.8840\n",
            "Epoch 23/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2438 - accuracy: 0.8852\n",
            "Epoch 24/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2424 - accuracy: 0.8852\n",
            "Epoch 25/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2405 - accuracy: 0.8864\n",
            "Epoch 26/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2390 - accuracy: 0.8876\n",
            "Epoch 27/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2384 - accuracy: 0.8868\n",
            "Epoch 28/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2382 - accuracy: 0.8870\n",
            "Epoch 29/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2355 - accuracy: 0.8879\n",
            "Epoch 30/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2345 - accuracy: 0.8883\n",
            "Epoch 31/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2325 - accuracy: 0.8902\n",
            "Epoch 32/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2320 - accuracy: 0.8904\n",
            "Epoch 33/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2303 - accuracy: 0.8923\n",
            "Epoch 34/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2297 - accuracy: 0.8919\n",
            "Epoch 35/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2279 - accuracy: 0.8924\n",
            "Epoch 36/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2273 - accuracy: 0.8945\n",
            "Epoch 37/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2248 - accuracy: 0.8936\n",
            "Epoch 38/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2243 - accuracy: 0.8940\n",
            "Epoch 39/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2238 - accuracy: 0.8947\n",
            "Epoch 40/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2221 - accuracy: 0.8965\n",
            "688/688 [==============================] - 1s 2ms/step - loss: 0.3840 - accuracy: 0.8412\n",
            "[CV 1/3] END ..........batch_size=30, epochs=40;, score=0.841 total time= 2.3min\n",
            "Epoch 1/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.3064 - accuracy: 0.8634\n",
            "Epoch 2/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2774 - accuracy: 0.8720\n",
            "Epoch 3/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2667 - accuracy: 0.8764\n",
            "Epoch 4/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2594 - accuracy: 0.8794\n",
            "Epoch 5/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2558 - accuracy: 0.8800\n",
            "Epoch 6/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2515 - accuracy: 0.8816\n",
            "Epoch 7/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2490 - accuracy: 0.8842\n",
            "Epoch 8/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2455 - accuracy: 0.8850\n",
            "Epoch 9/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2436 - accuracy: 0.8861\n",
            "Epoch 10/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2401 - accuracy: 0.8871\n",
            "Epoch 11/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2379 - accuracy: 0.8893\n",
            "Epoch 12/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2363 - accuracy: 0.8897\n",
            "Epoch 13/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2336 - accuracy: 0.8914\n",
            "Epoch 14/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2326 - accuracy: 0.8921\n",
            "Epoch 15/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2304 - accuracy: 0.8929\n",
            "Epoch 16/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2294 - accuracy: 0.8924\n",
            "Epoch 17/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2278 - accuracy: 0.8934\n",
            "Epoch 18/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2255 - accuracy: 0.8955\n",
            "Epoch 19/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2239 - accuracy: 0.8960\n",
            "Epoch 20/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2230 - accuracy: 0.8943\n",
            "Epoch 21/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2214 - accuracy: 0.8967\n",
            "Epoch 22/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2198 - accuracy: 0.8982\n",
            "Epoch 23/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2181 - accuracy: 0.8990\n",
            "Epoch 24/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2165 - accuracy: 0.8996\n",
            "Epoch 25/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2161 - accuracy: 0.9008\n",
            "Epoch 26/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2145 - accuracy: 0.9003\n",
            "Epoch 27/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2138 - accuracy: 0.9001\n",
            "Epoch 28/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2119 - accuracy: 0.9020\n",
            "Epoch 29/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2111 - accuracy: 0.9015\n",
            "Epoch 30/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2099 - accuracy: 0.9038\n",
            "Epoch 31/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2082 - accuracy: 0.9043\n",
            "Epoch 32/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2077 - accuracy: 0.9034\n",
            "Epoch 33/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2059 - accuracy: 0.9057\n",
            "Epoch 34/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2052 - accuracy: 0.9048\n",
            "Epoch 35/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2037 - accuracy: 0.9066\n",
            "Epoch 36/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2029 - accuracy: 0.9053\n",
            "Epoch 37/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2008 - accuracy: 0.9076\n",
            "Epoch 38/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2011 - accuracy: 0.9061\n",
            "Epoch 39/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2012 - accuracy: 0.9071\n",
            "Epoch 40/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1981 - accuracy: 0.9095\n",
            "688/688 [==============================] - 1s 2ms/step - loss: 0.3791 - accuracy: 0.8504\n",
            "[CV 2/3] END ..........batch_size=30, epochs=40;, score=0.850 total time= 2.2min\n",
            "Epoch 1/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2925 - accuracy: 0.8709\n",
            "Epoch 2/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2581 - accuracy: 0.8809\n",
            "Epoch 3/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2470 - accuracy: 0.8867\n",
            "Epoch 4/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2411 - accuracy: 0.8880\n",
            "Epoch 5/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2356 - accuracy: 0.8890\n",
            "Epoch 6/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2323 - accuracy: 0.8937\n",
            "Epoch 7/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2292 - accuracy: 0.8941\n",
            "Epoch 8/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2276 - accuracy: 0.8939\n",
            "Epoch 9/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2240 - accuracy: 0.8956\n",
            "Epoch 10/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2228 - accuracy: 0.8966\n",
            "Epoch 11/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2204 - accuracy: 0.8983\n",
            "Epoch 12/40\n",
            "1376/1376 [==============================] - 3s 3ms/step - loss: 0.2185 - accuracy: 0.8989\n",
            "Epoch 13/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2174 - accuracy: 0.8992\n",
            "Epoch 14/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2141 - accuracy: 0.9003\n",
            "Epoch 15/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2129 - accuracy: 0.9006\n",
            "Epoch 16/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2118 - accuracy: 0.9013\n",
            "Epoch 17/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2105 - accuracy: 0.9017\n",
            "Epoch 18/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2081 - accuracy: 0.9037\n",
            "Epoch 19/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2076 - accuracy: 0.9052\n",
            "Epoch 20/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2052 - accuracy: 0.9056\n",
            "Epoch 21/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2047 - accuracy: 0.9058\n",
            "Epoch 22/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2043 - accuracy: 0.9068\n",
            "Epoch 23/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2029 - accuracy: 0.9066\n",
            "Epoch 24/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2016 - accuracy: 0.9072\n",
            "Epoch 25/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1999 - accuracy: 0.9090\n",
            "Epoch 26/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1992 - accuracy: 0.9080\n",
            "Epoch 27/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1984 - accuracy: 0.9083\n",
            "Epoch 28/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1969 - accuracy: 0.9095\n",
            "Epoch 29/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1966 - accuracy: 0.9088\n",
            "Epoch 30/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1965 - accuracy: 0.9101\n",
            "Epoch 31/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1941 - accuracy: 0.9091\n",
            "Epoch 32/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1939 - accuracy: 0.9109\n",
            "Epoch 33/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1919 - accuracy: 0.9127\n",
            "Epoch 34/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1905 - accuracy: 0.9114\n",
            "Epoch 35/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1914 - accuracy: 0.9112\n",
            "Epoch 36/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1901 - accuracy: 0.9120\n",
            "Epoch 37/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1897 - accuracy: 0.9117\n",
            "Epoch 38/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1892 - accuracy: 0.9135\n",
            "Epoch 39/40\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1874 - accuracy: 0.9133\n",
            "Epoch 40/40\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1875 - accuracy: 0.9153\n",
            "688/688 [==============================] - 1s 2ms/step - loss: 0.3406 - accuracy: 0.8607\n",
            "[CV 3/3] END ..........batch_size=30, epochs=40;, score=0.861 total time= 2.4min\n",
            "Epoch 1/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2677 - accuracy: 0.8822\n",
            "Epoch 2/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2323 - accuracy: 0.8919\n",
            "Epoch 3/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2217 - accuracy: 0.8966\n",
            "Epoch 4/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2154 - accuracy: 0.8997\n",
            "Epoch 5/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2120 - accuracy: 0.9017\n",
            "Epoch 6/20\n",
            "1376/1376 [==============================] - 5s 3ms/step - loss: 0.2099 - accuracy: 0.9007\n",
            "Epoch 7/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2064 - accuracy: 0.9022\n",
            "Epoch 8/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2038 - accuracy: 0.9053\n",
            "Epoch 9/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2014 - accuracy: 0.9056\n",
            "Epoch 10/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1980 - accuracy: 0.9073\n",
            "Epoch 11/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1981 - accuracy: 0.9083\n",
            "Epoch 12/20\n",
            "1376/1376 [==============================] - 9s 7ms/step - loss: 0.1958 - accuracy: 0.9078\n",
            "Epoch 13/20\n",
            "1376/1376 [==============================] - 7s 5ms/step - loss: 0.1949 - accuracy: 0.9099\n",
            "Epoch 14/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1934 - accuracy: 0.9104\n",
            "Epoch 15/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1918 - accuracy: 0.9115\n",
            "Epoch 16/20\n",
            "1376/1376 [==============================] - 5s 3ms/step - loss: 0.1922 - accuracy: 0.9101\n",
            "Epoch 17/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1890 - accuracy: 0.9121\n",
            "Epoch 18/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1877 - accuracy: 0.9131\n",
            "Epoch 19/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1857 - accuracy: 0.9153\n",
            "Epoch 20/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1858 - accuracy: 0.9146\n",
            "688/688 [==============================] - 1s 2ms/step - loss: 0.3001 - accuracy: 0.8749\n",
            "[CV 1/3] END ..........batch_size=30, epochs=20;, score=0.875 total time= 2.4min\n",
            "Epoch 1/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2468 - accuracy: 0.8885\n",
            "Epoch 2/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2145 - accuracy: 0.9001\n",
            "Epoch 3/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2055 - accuracy: 0.9049\n",
            "Epoch 4/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2011 - accuracy: 0.9076\n",
            "Epoch 5/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1980 - accuracy: 0.9083\n",
            "Epoch 6/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1957 - accuracy: 0.9096\n",
            "Epoch 7/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1945 - accuracy: 0.9099\n",
            "Epoch 8/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1924 - accuracy: 0.9104\n",
            "Epoch 9/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1890 - accuracy: 0.9123\n",
            "Epoch 10/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1883 - accuracy: 0.9128\n",
            "Epoch 11/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1860 - accuracy: 0.9144\n",
            "Epoch 12/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1845 - accuracy: 0.9147\n",
            "Epoch 13/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1837 - accuracy: 0.9169\n",
            "Epoch 14/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1832 - accuracy: 0.9165\n",
            "Epoch 15/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1819 - accuracy: 0.9159\n",
            "Epoch 16/20\n",
            "1376/1376 [==============================] - 5s 3ms/step - loss: 0.1800 - accuracy: 0.9164\n",
            "Epoch 17/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1813 - accuracy: 0.9171\n",
            "Epoch 18/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1771 - accuracy: 0.9199\n",
            "Epoch 19/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1772 - accuracy: 0.9189\n",
            "Epoch 20/20\n",
            "1376/1376 [==============================] - 6s 5ms/step - loss: 0.1754 - accuracy: 0.9194\n",
            "688/688 [==============================] - 2s 3ms/step - loss: 0.2959 - accuracy: 0.8769\n",
            "[CV 2/3] END ..........batch_size=30, epochs=20;, score=0.877 total time= 1.2min\n",
            "Epoch 1/20\n",
            "1376/1376 [==============================] - 10s 7ms/step - loss: 0.2367 - accuracy: 0.8950\n",
            "Epoch 2/20\n",
            "1376/1376 [==============================] - 7s 5ms/step - loss: 0.2065 - accuracy: 0.9065\n",
            "Epoch 3/20\n",
            "1376/1376 [==============================] - 5s 4ms/step - loss: 0.1997 - accuracy: 0.9086\n",
            "Epoch 4/20\n",
            "1376/1376 [==============================] - 5s 4ms/step - loss: 0.1940 - accuracy: 0.9119\n",
            "Epoch 5/20\n",
            "1376/1376 [==============================] - 6s 4ms/step - loss: 0.1902 - accuracy: 0.9128\n",
            "Epoch 6/20\n",
            "1376/1376 [==============================] - 6s 4ms/step - loss: 0.1887 - accuracy: 0.9136\n",
            "Epoch 7/20\n",
            "1376/1376 [==============================] - 7s 5ms/step - loss: 0.1859 - accuracy: 0.9146\n",
            "Epoch 8/20\n",
            "1376/1376 [==============================] - 6s 5ms/step - loss: 0.1851 - accuracy: 0.9155\n",
            "Epoch 9/20\n",
            "1376/1376 [==============================] - 5s 4ms/step - loss: 0.1821 - accuracy: 0.9165\n",
            "Epoch 10/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1820 - accuracy: 0.9177\n",
            "Epoch 11/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1803 - accuracy: 0.9186\n",
            "Epoch 12/20\n",
            "1376/1376 [==============================] - 5s 4ms/step - loss: 0.1779 - accuracy: 0.9195\n",
            "Epoch 13/20\n",
            "1376/1376 [==============================] - 7s 5ms/step - loss: 0.1784 - accuracy: 0.9197\n",
            "Epoch 14/20\n",
            "1376/1376 [==============================] - 7s 5ms/step - loss: 0.1755 - accuracy: 0.9196\n",
            "Epoch 15/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1744 - accuracy: 0.9203\n",
            "Epoch 16/20\n",
            "1376/1376 [==============================] - 7s 5ms/step - loss: 0.1742 - accuracy: 0.9217\n",
            "Epoch 17/20\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.1732 - accuracy: 0.9211\n",
            "Epoch 18/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1722 - accuracy: 0.9216\n",
            "Epoch 19/20\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.1717 - accuracy: 0.9223\n",
            "Epoch 20/20\n",
            "1376/1376 [==============================] - 5s 4ms/step - loss: 0.1701 - accuracy: 0.9233\n",
            "688/688 [==============================] - 1s 2ms/step - loss: 0.2831 - accuracy: 0.8796\n",
            "[CV 3/3] END ..........batch_size=30, epochs=20;, score=0.880 total time= 1.9min\n",
            "Epoch 1/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.2114 - accuracy: 0.9043\n",
            "Epoch 2/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1965 - accuracy: 0.9097\n",
            "Epoch 3/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1932 - accuracy: 0.9105\n",
            "Epoch 4/20\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.1926 - accuracy: 0.9120\n",
            "Epoch 5/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1908 - accuracy: 0.9122\n",
            "Epoch 6/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1887 - accuracy: 0.9129\n",
            "Epoch 7/20\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.1880 - accuracy: 0.9140\n",
            "Epoch 8/20\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.1884 - accuracy: 0.9128\n",
            "Epoch 9/20\n",
            "2064/2064 [==============================] - 7s 4ms/step - loss: 0.1861 - accuracy: 0.9136\n",
            "Epoch 10/20\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.1863 - accuracy: 0.9140\n",
            "Epoch 11/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1858 - accuracy: 0.9155\n",
            "Epoch 12/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1845 - accuracy: 0.9153\n",
            "Epoch 13/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1844 - accuracy: 0.9153\n",
            "Epoch 14/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1839 - accuracy: 0.9159\n",
            "Epoch 15/20\n",
            "2064/2064 [==============================] - 8s 4ms/step - loss: 0.1838 - accuracy: 0.9151\n",
            "Epoch 16/20\n",
            "2064/2064 [==============================] - 12s 6ms/step - loss: 0.1827 - accuracy: 0.9153\n",
            "Epoch 17/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1818 - accuracy: 0.9169\n",
            "Epoch 18/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1813 - accuracy: 0.9165\n",
            "Epoch 19/20\n",
            "2064/2064 [==============================] - 7s 3ms/step - loss: 0.1820 - accuracy: 0.9151\n",
            "Epoch 20/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1813 - accuracy: 0.9176\n",
            "Epoch 1/20\n",
            "2064/2064 [==============================] - 8s 3ms/step - loss: 0.1798 - accuracy: 0.9166\n",
            "Epoch 2/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1796 - accuracy: 0.9171\n",
            "Epoch 3/20\n",
            "2064/2064 [==============================] - 13s 6ms/step - loss: 0.1788 - accuracy: 0.9170\n",
            "Epoch 4/20\n",
            "2064/2064 [==============================] - 7s 4ms/step - loss: 0.1795 - accuracy: 0.9176\n",
            "Epoch 5/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1792 - accuracy: 0.9174\n",
            "Epoch 6/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1776 - accuracy: 0.9185\n",
            "Epoch 7/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1771 - accuracy: 0.9192\n",
            "Epoch 8/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1776 - accuracy: 0.9184\n",
            "Epoch 9/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1760 - accuracy: 0.9191\n",
            "Epoch 10/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1759 - accuracy: 0.9187\n",
            "Epoch 11/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1759 - accuracy: 0.9199\n",
            "Epoch 12/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1754 - accuracy: 0.9200\n",
            "Epoch 13/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1760 - accuracy: 0.9190\n",
            "Epoch 14/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1751 - accuracy: 0.9199\n",
            "Epoch 15/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1753 - accuracy: 0.9202\n",
            "Epoch 16/20\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.1733 - accuracy: 0.9207\n",
            "Epoch 17/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1725 - accuracy: 0.9215\n",
            "Epoch 18/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.1723 - accuracy: 0.9212\n",
            "Epoch 19/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1735 - accuracy: 0.9195\n",
            "Epoch 20/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.1727 - accuracy: 0.9209\n",
            "830/830 [==============================] - 2s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_training = random_search_training.best_params_\n",
        "best_training\n",
        "# {'epochs': 20, 'batch_size': 30}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDMFyMon3dKy",
        "outputId": "15e013f6-d8d6-4db1-e6e8-b35da1921cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epochs': 20, 'batch_size': 30}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creamos la matriz de confusión para el mejor modelo\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4LnwFUJnaDYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo con el dataset completo\n",
        "best_model.fit(x_train_norm, y_train, epochs=best_training['epochs'], batch_size=best_training['batch_size'])\n",
        "\n",
        "# Obtenemos predicciones\n",
        "y_probs = best_model.predict(x_test_norm)\n",
        "y_predictions = (y_probs > 0.5).astype(int)\n",
        "\n",
        "y_pred = np.ravel(y_predictions)\n",
        "\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj5XvIkSA1L1",
        "outputId": "fafba831-a8b6-4119-d131-0e478e3db082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1445/1445 [==============================] - 3s 2ms/step - loss: 3.5353 - accuracy: 0.7589\n",
            "Epoch 2/20\n",
            "1445/1445 [==============================] - 8s 6ms/step - loss: 3.2300 - accuracy: 0.7774\n",
            "Epoch 3/20\n",
            "1445/1445 [==============================] - 3s 2ms/step - loss: 3.0780 - accuracy: 0.7841\n",
            "Epoch 4/20\n",
            "1445/1445 [==============================] - 3s 2ms/step - loss: 2.8229 - accuracy: 0.7860\n",
            "Epoch 5/20\n",
            "1445/1445 [==============================] - 3s 2ms/step - loss: 2.3202 - accuracy: 0.7693\n",
            "Epoch 6/20\n",
            "1445/1445 [==============================] - 5s 3ms/step - loss: 1.8014 - accuracy: 0.7455\n",
            "Epoch 7/20\n",
            "1445/1445 [==============================] - 4s 2ms/step - loss: 1.3836 - accuracy: 0.7211\n",
            "Epoch 8/20\n",
            "1445/1445 [==============================] - 3s 2ms/step - loss: 1.1283 - accuracy: 0.7149\n",
            "Epoch 9/20\n",
            "1445/1445 [==============================] - 3s 2ms/step - loss: 0.9767 - accuracy: 0.7122\n",
            "Epoch 10/20\n",
            "1445/1445 [==============================] - 4s 3ms/step - loss: 0.8812 - accuracy: 0.7098\n",
            "Epoch 11/20\n",
            "1445/1445 [==============================] - 4s 3ms/step - loss: 0.8142 - accuracy: 0.7103\n",
            "Epoch 12/20\n",
            "1445/1445 [==============================] - 3s 2ms/step - loss: 0.7766 - accuracy: 0.7158\n",
            "Epoch 13/20\n",
            "1445/1445 [==============================] - 3s 2ms/step - loss: 0.7248 - accuracy: 0.7450\n",
            "Epoch 14/20\n",
            "1445/1445 [==============================] - 4s 3ms/step - loss: 0.6822 - accuracy: 0.7748\n",
            "Epoch 15/20\n",
            "1445/1445 [==============================] - 4s 3ms/step - loss: 0.6489 - accuracy: 0.7824\n",
            "Epoch 16/20\n",
            "1445/1445 [==============================] - 3s 2ms/step - loss: 0.6387 - accuracy: 0.7845\n",
            "Epoch 17/20\n",
            "1445/1445 [==============================] - 3s 2ms/step - loss: 0.6311 - accuracy: 0.7853\n",
            "Epoch 18/20\n",
            "1445/1445 [==============================] - 4s 3ms/step - loss: 0.6158 - accuracy: 0.7871\n",
            "Epoch 19/20\n",
            "1445/1445 [==============================] - 4s 3ms/step - loss: 0.5921 - accuracy: 0.7897\n",
            "Epoch 20/20\n",
            "1445/1445 [==============================] - 3s 2ms/step - loss: 0.5908 - accuracy: 0.7923\n",
            "581/581 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.84      0.80      9292\n",
            "           1       0.82      0.74      0.78      9281\n",
            "\n",
            "    accuracy                           0.79     18573\n",
            "   macro avg       0.79      0.79      0.79     18573\n",
            "weighted avg       0.79      0.79      0.79     18573\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creo la matriz de confusión\n",
        "tabla=confusion_matrix(y_test, y_pred)\n",
        "\n",
        "#Grafico la matriz de confusión\n",
        "sns.heatmap(tabla,cmap='GnBu',annot=True,fmt='g')\n",
        "plt.xlabel('Valores predichos')\n",
        "plt.ylabel('Valores reales')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "PPwQDBIoBMEl",
        "outputId": "b448ced5-645d-4bbb-dae8-82c252a642de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(50.722222222222214, 0.5, 'Valores reales')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exportamos las predicciones para la submission"
      ],
      "metadata": {
        "id": "i98vXPO9Z-1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo con el dataset completo\n",
        "best_model.fit(ds_train_norm, ds_hoteles_train_y, epochs=best_training['epochs'], batch_size=best_training['batch_size'])\n",
        "\n",
        "# Obtenemos predicciones\n",
        "y_probs = best_model.predict(ds_test_norm)\n",
        "y_predictions = (y_probs > 0.5).astype(int)\n",
        "\n",
        "y_pred = np.ravel(y_predictions)\n",
        "\n",
        "# Unimos las predicciones con su id para realizar el subbmit en Kaggle\n",
        "df_submission = pd.DataFrame({'id': ds_hoteles_test['id'], 'is_canceled': y_pred})\n",
        "df_submission.to_csv('Submission_red_neuronal_modelo1_optimized_v2.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cocbiiHoAHb3",
        "outputId": "f094a122-9c9a-461c-c4f4-76770bafe179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.4613 - accuracy: 0.7755\n",
            "Epoch 2/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.4121 - accuracy: 0.7988\n",
            "Epoch 3/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.3931 - accuracy: 0.8076\n",
            "Epoch 4/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.3820 - accuracy: 0.8146\n",
            "Epoch 5/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.3716 - accuracy: 0.8183\n",
            "Epoch 6/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.3651 - accuracy: 0.8224\n",
            "Epoch 7/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.3583 - accuracy: 0.8256\n",
            "Epoch 8/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.3531 - accuracy: 0.8285\n",
            "Epoch 9/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.3489 - accuracy: 0.8310\n",
            "Epoch 10/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.3455 - accuracy: 0.8324\n",
            "Epoch 11/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.3421 - accuracy: 0.8347\n",
            "Epoch 12/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.3388 - accuracy: 0.8362\n",
            "Epoch 13/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.3362 - accuracy: 0.8371\n",
            "Epoch 14/20\n",
            "2064/2064 [==============================] - 7s 3ms/step - loss: 0.3345 - accuracy: 0.8384\n",
            "Epoch 15/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.3310 - accuracy: 0.8402\n",
            "Epoch 16/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.3291 - accuracy: 0.8408\n",
            "Epoch 17/20\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.3264 - accuracy: 0.8422\n",
            "Epoch 18/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.3254 - accuracy: 0.8411\n",
            "Epoch 19/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.3234 - accuracy: 0.8435\n",
            "Epoch 20/20\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.3209 - accuracy: 0.8439\n",
            "830/830 [==============================] - 1s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arquitectura 2"
      ],
      "metadata": {
        "id": "BdNAl_48eBn0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimización de hiperparámetros de la arquitectura 2"
      ],
      "metadata": {
        "id": "vT49ry6OElzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from scipy.stats import randint\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "# Definimos función para crear el modelo\n",
        "'''\n",
        "-Tiene 3 hiperparámetros para optimizar: cant neuronas y capas ocultas, optimizador\n",
        "-Utiliza la funcion de activación 'relu' para la capa de entrada y la scapas ocultas\n",
        "-No tienen regularizador\n",
        "'''\n",
        "def create_model_2(hidden_layers=2, neurons=64, optimizer='sgd'):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(neurons, input_shape=(ds_train_norm.shape[1],), activation='relu'))\n",
        "    for _ in range(hidden_layers - 1):\n",
        "        model.add(keras.layers.Dense(neurons, activation='relu'))\n",
        "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# Optimizamos hiperparámetros de arquitectura\n",
        "model = KerasClassifier(build_fn=create_model_2,callbacks=[early_stopping])\n",
        "param_dist_architecture = {\n",
        "    'neurons': [16, 32, 64, 128],\n",
        "    'hidden_layers': [1, 2, 3],\n",
        "    'optimizer': ['sgd', 'adam', 'rmsprop', 'adagrad']\n",
        "}\n",
        "\n",
        "random_search_architecture = RandomizedSearchCV(estimator=model,\n",
        "                                                param_distributions=param_dist_architecture,\n",
        "                                                n_iter=1, cv=2)\n",
        "random_search_architecture.fit(ds_train_norm, ds_hoteles_train_y)\n",
        "\n",
        "# Obtenemos los mejor hiperparámetros de arquitectura\n",
        "best_architecture = random_search_architecture.best_params_\n",
        "\n",
        "# Creamos un modelo con ellos\n",
        "best_model = create_model_2(neurons=best_architecture['neurons'], hidden_layers=best_architecture['hidden_layers'], optimizer = best_architecture['optimizer'])\n",
        "\n",
        "# Optimizamos epochs y batch_size\n",
        "param_dist_training = {\n",
        "    'epochs': [10, 20, 30],\n",
        "    'batch_size': [20, 25, 30]\n",
        "}\n",
        "\n",
        "random_search_training = RandomizedSearchCV(estimator=KerasClassifier(build_fn=lambda: best_model), param_distributions=param_dist_training, n_iter=3, cv=3)\n",
        "random_search_training.fit(ds_train_norm, ds_hoteles_train_y)\n",
        "\n",
        "# Obtenemos los mejores hiperparámetros\n",
        "best_training = random_search_training.best_params_\n",
        "\n",
        "# Entrenamos el modelo\n",
        "best_model.fit(ds_train_norm, ds_hoteles_train_y, epochs=best_training['epochs'], batch_size=best_training['batch_size'])\n",
        "\n",
        "# Hacemos predicciones con el dataset completo\n",
        "y_probs = best_model.predict(ds_test_norm)\n",
        "y_predictions = (y_probs > 0.5).astype(int)\n",
        "\n",
        "y_pred = np.ravel(y_predictions)\n",
        "\n",
        "# Realizamos el subbmit a Kaggle\n",
        "df_submission = pd.DataFrame({'id': ds_hoteles_test['id'], 'is_canceled': y_pred})\n",
        "df_submission.to_csv('Submission_red_neuronal_model2_optimized.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02a2fdbe-9e20-4042-fec4-a2d4204154a3",
        "id": "jJULhNEoHRsB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "968/968 [==============================] - 4s 3ms/step - loss: 0.7214 - accuracy: 0.4865\n",
            "968/968 [==============================] - 2s 2ms/step - loss: 0.7029 - accuracy: 0.4704\n",
            "968/968 [==============================] - 2s 2ms/step - loss: 0.6928 - accuracy: 0.5287\n",
            "968/968 [==============================] - 2s 2ms/step - loss: 0.6866 - accuracy: 0.6021\n",
            "1935/1935 [==============================] - 5s 2ms/step - loss: 0.6491 - accuracy: 0.6313\n",
            "Epoch 1/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.6675 - accuracy: 0.5766\n",
            "Epoch 2/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.6343 - accuracy: 0.6326\n",
            "Epoch 3/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.6126 - accuracy: 0.6588\n",
            "Epoch 4/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5955 - accuracy: 0.6738\n",
            "Epoch 5/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5817 - accuracy: 0.6851\n",
            "Epoch 6/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5704 - accuracy: 0.6933\n",
            "Epoch 7/20\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.5611 - accuracy: 0.6978\n",
            "Epoch 8/20\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.5536 - accuracy: 0.7014\n",
            "Epoch 9/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5475 - accuracy: 0.7063\n",
            "Epoch 10/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5425 - accuracy: 0.7101\n",
            "Epoch 11/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.5382 - accuracy: 0.7135\n",
            "Epoch 12/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.5345 - accuracy: 0.7167\n",
            "Epoch 13/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5313 - accuracy: 0.7204\n",
            "Epoch 14/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5285 - accuracy: 0.7230\n",
            "Epoch 15/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5261 - accuracy: 0.7256\n",
            "Epoch 16/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.5239 - accuracy: 0.7279\n",
            "Epoch 17/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.5219 - accuracy: 0.7302\n",
            "Epoch 18/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5202 - accuracy: 0.7313\n",
            "Epoch 19/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5185 - accuracy: 0.7330\n",
            "Epoch 20/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.5171 - accuracy: 0.7341\n",
            "826/826 [==============================] - 2s 3ms/step - loss: 0.5134 - accuracy: 0.7375\n",
            "Epoch 1/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5149 - accuracy: 0.7358\n",
            "Epoch 2/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5135 - accuracy: 0.7372\n",
            "Epoch 3/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5123 - accuracy: 0.7389\n",
            "Epoch 4/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.5111 - accuracy: 0.7405\n",
            "Epoch 5/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5101 - accuracy: 0.7418\n",
            "Epoch 6/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5091 - accuracy: 0.7429\n",
            "Epoch 7/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5081 - accuracy: 0.7437\n",
            "Epoch 8/20\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.5072 - accuracy: 0.7442\n",
            "Epoch 9/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.5064 - accuracy: 0.7448\n",
            "Epoch 10/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5055 - accuracy: 0.7456\n",
            "Epoch 11/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5048 - accuracy: 0.7462\n",
            "Epoch 12/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.5040 - accuracy: 0.7472\n",
            "Epoch 13/20\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.5033 - accuracy: 0.7476\n",
            "Epoch 14/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5026 - accuracy: 0.7480\n",
            "Epoch 15/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5019 - accuracy: 0.7484\n",
            "Epoch 16/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.5013 - accuracy: 0.7486\n",
            "Epoch 17/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.5007 - accuracy: 0.7491\n",
            "Epoch 18/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.5001 - accuracy: 0.7495\n",
            "Epoch 19/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4995 - accuracy: 0.7494\n",
            "Epoch 20/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4990 - accuracy: 0.7499\n",
            "826/826 [==============================] - 1s 2ms/step - loss: 0.4992 - accuracy: 0.7475\n",
            "Epoch 1/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4974 - accuracy: 0.7501\n",
            "Epoch 2/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.4969 - accuracy: 0.7507\n",
            "Epoch 3/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4964 - accuracy: 0.7513\n",
            "Epoch 4/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4959 - accuracy: 0.7513\n",
            "Epoch 5/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4954 - accuracy: 0.7517\n",
            "Epoch 6/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.4949 - accuracy: 0.7526\n",
            "Epoch 7/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.4945 - accuracy: 0.7527\n",
            "Epoch 8/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4940 - accuracy: 0.7527\n",
            "Epoch 9/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4936 - accuracy: 0.7533\n",
            "Epoch 10/20\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.4931 - accuracy: 0.7531\n",
            "Epoch 11/20\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.4927 - accuracy: 0.7536\n",
            "Epoch 12/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4923 - accuracy: 0.7534\n",
            "Epoch 13/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4920 - accuracy: 0.7537\n",
            "Epoch 14/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.4916 - accuracy: 0.7541\n",
            "Epoch 15/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.4912 - accuracy: 0.7548\n",
            "Epoch 16/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4908 - accuracy: 0.7545\n",
            "Epoch 17/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4905 - accuracy: 0.7547\n",
            "Epoch 18/20\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4901 - accuracy: 0.7548\n",
            "Epoch 19/20\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.4898 - accuracy: 0.7549\n",
            "Epoch 20/20\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.4894 - accuracy: 0.7557\n",
            "826/826 [==============================] - 1s 2ms/step - loss: 0.4935 - accuracy: 0.7498\n",
            "Epoch 1/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4920 - accuracy: 0.7511\n",
            "Epoch 2/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4918 - accuracy: 0.7510\n",
            "Epoch 3/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.4915 - accuracy: 0.7515\n",
            "Epoch 4/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.4912 - accuracy: 0.7514\n",
            "Epoch 5/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4910 - accuracy: 0.7516\n",
            "Epoch 6/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4907 - accuracy: 0.7517\n",
            "Epoch 7/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4905 - accuracy: 0.7515\n",
            "Epoch 8/10\n",
            "1376/1376 [==============================] - 3s 3ms/step - loss: 0.4902 - accuracy: 0.7518\n",
            "Epoch 9/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.4900 - accuracy: 0.7520\n",
            "Epoch 10/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4897 - accuracy: 0.7523\n",
            "688/688 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.7596\n",
            "Epoch 1/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4880 - accuracy: 0.7556\n",
            "Epoch 2/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4877 - accuracy: 0.7555\n",
            "Epoch 3/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.4875 - accuracy: 0.7553\n",
            "Epoch 4/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.4872 - accuracy: 0.7554\n",
            "Epoch 5/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4870 - accuracy: 0.7552\n",
            "Epoch 6/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4868 - accuracy: 0.7556\n",
            "Epoch 7/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4865 - accuracy: 0.7557\n",
            "Epoch 8/10\n",
            "1376/1376 [==============================] - 3s 3ms/step - loss: 0.4863 - accuracy: 0.7560\n",
            "Epoch 9/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.4861 - accuracy: 0.7560\n",
            "Epoch 10/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4858 - accuracy: 0.7562\n",
            "688/688 [==============================] - 2s 2ms/step - loss: 0.4864 - accuracy: 0.7542\n",
            "Epoch 1/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4846 - accuracy: 0.7576\n",
            "Epoch 2/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4843 - accuracy: 0.7579\n",
            "Epoch 3/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4841 - accuracy: 0.7585\n",
            "Epoch 4/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4839 - accuracy: 0.7585\n",
            "Epoch 5/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.4837 - accuracy: 0.7586\n",
            "Epoch 6/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4835 - accuracy: 0.7586\n",
            "Epoch 7/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4833 - accuracy: 0.7588\n",
            "Epoch 8/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4831 - accuracy: 0.7594\n",
            "Epoch 9/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4829 - accuracy: 0.7595\n",
            "Epoch 10/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.4827 - accuracy: 0.7595\n",
            "688/688 [==============================] - 2s 2ms/step - loss: 0.4867 - accuracy: 0.7546\n",
            "Epoch 1/10\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.4854 - accuracy: 0.7554\n",
            "Epoch 2/10\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4852 - accuracy: 0.7555\n",
            "Epoch 3/10\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4850 - accuracy: 0.7559\n",
            "Epoch 4/10\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4847 - accuracy: 0.7560\n",
            "Epoch 5/10\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.4845 - accuracy: 0.7561\n",
            "Epoch 6/10\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.4843 - accuracy: 0.7567\n",
            "Epoch 7/10\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4841 - accuracy: 0.7570\n",
            "Epoch 8/10\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4839 - accuracy: 0.7568\n",
            "Epoch 9/10\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.4837 - accuracy: 0.7573\n",
            "Epoch 10/10\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.4835 - accuracy: 0.7576\n",
            "826/826 [==============================] - 1s 2ms/step - loss: 0.4789 - accuracy: 0.7642\n",
            "Epoch 1/10\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4816 - accuracy: 0.7606\n",
            "Epoch 2/10\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4814 - accuracy: 0.7607\n",
            "Epoch 3/10\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.4812 - accuracy: 0.7608\n",
            "Epoch 4/10\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.4809 - accuracy: 0.7607\n",
            "Epoch 5/10\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4807 - accuracy: 0.7613\n",
            "Epoch 6/10\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4805 - accuracy: 0.7615\n",
            "Epoch 7/10\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.4803 - accuracy: 0.7612\n",
            "Epoch 8/10\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.4801 - accuracy: 0.7614\n",
            "Epoch 9/10\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4799 - accuracy: 0.7613\n",
            "Epoch 10/10\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4797 - accuracy: 0.7614\n",
            "826/826 [==============================] - 1s 2ms/step - loss: 0.4805 - accuracy: 0.7584\n",
            "Epoch 1/10\n",
            "1651/1651 [==============================] - 5s 3ms/step - loss: 0.4785 - accuracy: 0.7621\n",
            "Epoch 2/10\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4783 - accuracy: 0.7625\n",
            "Epoch 3/10\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4781 - accuracy: 0.7628\n",
            "Epoch 4/10\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4779 - accuracy: 0.7628\n",
            "Epoch 5/10\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.4777 - accuracy: 0.7631\n",
            "Epoch 6/10\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.4775 - accuracy: 0.7632\n",
            "Epoch 7/10\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4773 - accuracy: 0.7631\n",
            "Epoch 8/10\n",
            "1651/1651 [==============================] - 3s 2ms/step - loss: 0.4772 - accuracy: 0.7630\n",
            "Epoch 9/10\n",
            "1651/1651 [==============================] - 4s 2ms/step - loss: 0.4770 - accuracy: 0.7631\n",
            "Epoch 10/10\n",
            "1651/1651 [==============================] - 4s 3ms/step - loss: 0.4768 - accuracy: 0.7634\n",
            "826/826 [==============================] - 1s 2ms/step - loss: 0.4809 - accuracy: 0.7585\n",
            "Epoch 1/10\n",
            "2477/2477 [==============================] - 5s 2ms/step - loss: 0.4780 - accuracy: 0.7618\n",
            "Epoch 2/10\n",
            "2477/2477 [==============================] - 7s 3ms/step - loss: 0.4777 - accuracy: 0.7617\n",
            "Epoch 3/10\n",
            "2477/2477 [==============================] - 5s 2ms/step - loss: 0.4775 - accuracy: 0.7621\n",
            "Epoch 4/10\n",
            "2477/2477 [==============================] - 5s 2ms/step - loss: 0.4772 - accuracy: 0.7620\n",
            "Epoch 5/10\n",
            "2477/2477 [==============================] - 7s 3ms/step - loss: 0.4770 - accuracy: 0.7622\n",
            "Epoch 6/10\n",
            "2477/2477 [==============================] - 5s 2ms/step - loss: 0.4768 - accuracy: 0.7624\n",
            "Epoch 7/10\n",
            "2477/2477 [==============================] - 5s 2ms/step - loss: 0.4765 - accuracy: 0.7623\n",
            "Epoch 8/10\n",
            "2477/2477 [==============================] - 7s 3ms/step - loss: 0.4763 - accuracy: 0.7626\n",
            "Epoch 9/10\n",
            "2477/2477 [==============================] - 5s 2ms/step - loss: 0.4761 - accuracy: 0.7627\n",
            "Epoch 10/10\n",
            "2477/2477 [==============================] - 5s 2ms/step - loss: 0.4758 - accuracy: 0.7628\n",
            "Epoch 1/10\n",
            "2477/2477 [==============================] - 8s 3ms/step - loss: 0.4756 - accuracy: 0.7627\n",
            "Epoch 2/10\n",
            "2477/2477 [==============================] - 5s 2ms/step - loss: 0.4754 - accuracy: 0.7630\n",
            "Epoch 3/10\n",
            "2477/2477 [==============================] - 7s 3ms/step - loss: 0.4752 - accuracy: 0.7631\n",
            "Epoch 4/10\n",
            "2477/2477 [==============================] - 6s 2ms/step - loss: 0.4750 - accuracy: 0.7629\n",
            "Epoch 5/10\n",
            "2477/2477 [==============================] - 5s 2ms/step - loss: 0.4748 - accuracy: 0.7632\n",
            "Epoch 6/10\n",
            "2477/2477 [==============================] - 8s 3ms/step - loss: 0.4745 - accuracy: 0.7633\n",
            "Epoch 7/10\n",
            "2477/2477 [==============================] - 5s 2ms/step - loss: 0.4743 - accuracy: 0.7632\n",
            "Epoch 8/10\n",
            "2477/2477 [==============================] - 9s 4ms/step - loss: 0.4741 - accuracy: 0.7635\n",
            "Epoch 9/10\n",
            "2477/2477 [==============================] - 9s 4ms/step - loss: 0.4739 - accuracy: 0.7637\n",
            "Epoch 10/10\n",
            "2477/2477 [==============================] - 10s 4ms/step - loss: 0.4737 - accuracy: 0.7638\n",
            "830/830 [==============================] - 1s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parametros utilizados"
      ],
      "metadata": {
        "id": "Uv4XKWtsQCrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_architecture"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "motlRwc_LdLU",
        "outputId": "96d4c5b5-a56f-4230-9047-e1c249f39ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'optimizer': 'sgd', 'neurons': 128, 'hidden_layers': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRfcF1iwLe5U",
        "outputId": "a22ae3bf-e55a-4b91-84e2-63aadd2132f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epochs': 10, 'batch_size': 20}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hacemos la matriz de confusion\n"
      ],
      "metadata": {
        "id": "F4fQIjIgeEvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_training = random_search_training.best_params_\n",
        "best_training\n",
        "# Entrenamos el modelo con el dataset completo\n",
        "best_model.fit(x_train_norm, y_train, epochs=best_training['epochs'], batch_size=best_training['batch_size'])\n",
        "\n",
        "# Obtenemos predicciones\n",
        "y_probs = best_model.predict(x_test_norm)\n",
        "y_predictions = (y_probs > 0.5).astype(int)  # Assuming binary classification\n",
        "\n",
        "y_pred = np.ravel(y_predictions)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "# {'epochs': 20, 'batch_size': 30}\n",
        "\n",
        "#Creo la matriz de confusión\n",
        "tabla=confusion_matrix(y_test, y_pred)\n",
        "\n",
        "#Grafico la matriz de confusión\n",
        "sns.heatmap(tabla,cmap='GnBu',annot=True,fmt='g')\n",
        "plt.xlabel('Valores predichos')\n",
        "plt.ylabel('Valores reales')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4hsqUp6QeHz9",
        "outputId": "395f5b7c-df05-498d-b88a-37b1cdbedf8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1734/1734 [==============================] - 5s 3ms/step - loss: 0.4700 - accuracy: 0.7658\n",
            "Epoch 2/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.4690 - accuracy: 0.7662\n",
            "Epoch 3/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.4681 - accuracy: 0.7665\n",
            "Epoch 4/10\n",
            "1734/1734 [==============================] - 5s 3ms/step - loss: 0.4673 - accuracy: 0.7667\n",
            "Epoch 5/10\n",
            "1734/1734 [==============================] - 5s 3ms/step - loss: 0.4666 - accuracy: 0.7670\n",
            "Epoch 6/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.4659 - accuracy: 0.7671\n",
            "Epoch 7/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.4652 - accuracy: 0.7678\n",
            "Epoch 8/10\n",
            "1734/1734 [==============================] - 6s 3ms/step - loss: 0.4645 - accuracy: 0.7681\n",
            "Epoch 9/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.4639 - accuracy: 0.7683\n",
            "Epoch 10/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.4634 - accuracy: 0.7687\n",
            "581/581 [==============================] - 1s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.83      0.78      9292\n",
            "           1       0.81      0.70      0.75      9281\n",
            "\n",
            "    accuracy                           0.77     18573\n",
            "   macro avg       0.77      0.77      0.77     18573\n",
            "weighted avg       0.77      0.77      0.77     18573\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(50.722222222222214, 0.5, 'Valores reales')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pruebo con mas cv's, más combinaciones aleatorias, valores mas bajos de batch_size"
      ],
      "metadata": {
        "id": "NUjqT1QAXboB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from scipy.stats import randint\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "# Definimos función para crear el modelo\n",
        "'''\n",
        "-Tiene 3 hiperparámetros para optimizar: cant neuronas y capas ocultas, optimizador\n",
        "-Utiliza la funcion de activación 'relu' para la capa de entrada y la scapas ocultas\n",
        "-No tienen regularizador\n",
        "'''\n",
        "def create_model_2(hidden_layers=2, neurons=64, optimizer='sgd'):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(neurons, input_shape=(ds_train_norm.shape[1],), activation='relu'))\n",
        "    for _ in range(hidden_layers - 1):\n",
        "        model.add(keras.layers.Dense(neurons, activation='relu'))\n",
        "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# Optimizamos hiperparámetros de arquitectura\n",
        "model = KerasClassifier(build_fn=create_model_2,callbacks=[early_stopping])\n",
        "param_dist_architecture = {\n",
        "    'neurons': [16, 32, 64, 128],\n",
        "    'hidden_layers': [1, 2, 3],\n",
        "    'optimizer': ['sgd', 'adam', 'rmsprop', 'adagrad']\n",
        "}\n",
        "\n",
        "random_search_architecture = RandomizedSearchCV(estimator=model,\n",
        "                                                param_distributions=param_dist_architecture,\n",
        "                                                n_iter=5, cv=4)\n",
        "random_search_architecture.fit(ds_train_norm, ds_hoteles_train_y)\n",
        "\n",
        "# Obtenemos los mejor hiperparámetros de arquitectura\n",
        "best_architecture = random_search_architecture.best_params_\n",
        "\n",
        "# Creamos un modelo con ellos\n",
        "best_model = create_model_2(neurons=best_architecture['neurons'], hidden_layers=best_architecture['hidden_layers'], optimizer = best_architecture['optimizer'])\n",
        "\n",
        "# Optimizamos epochs y batch_size\n",
        "param_dist_training = {\n",
        "    'epochs': [10, 20, 30],\n",
        "    'batch_size': [10, 15, 20]\n",
        "}\n",
        "\n",
        "random_search_training = RandomizedSearchCV(estimator=KerasClassifier(build_fn=lambda: best_model), param_distributions=param_dist_training, n_iter=4, cv=6)\n",
        "random_search_training.fit(ds_train_norm, ds_hoteles_train_y)\n",
        "\n",
        "# Obtenemos los mejores hiperparámetros\n",
        "best_training = random_search_training.best_params_\n",
        "\n",
        "# Entrenamos el modelo\n",
        "best_model.fit(ds_train_norm, ds_hoteles_train_y, epochs=best_training['epochs'], batch_size=best_training['batch_size'])\n",
        "\n",
        "# Hacemos predicciones con el dataset completo\n",
        "y_probs = best_model.predict(ds_test_norm)\n",
        "y_predictions = (y_probs > 0.5).astype(int)\n",
        "\n",
        "y_pred = np.ravel(y_predictions)\n",
        "\n",
        "# Realizamos el subbmit a Kaggle\n",
        "df_submission = pd.DataFrame({'id': ds_hoteles_test['id'], 'is_canceled': y_pred})\n",
        "df_submission.to_csv('Submission_red_neuronal_model2_optimized.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAiNEuk_XljQ",
        "outputId": "651775dd-0635-4c4d-abb8-4213c4440eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.6133 - accuracy: 0.6545\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.5622 - accuracy: 0.6879\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.6095 - accuracy: 0.6481\n",
            "484/484 [==============================] - 1s 962us/step - loss: 0.5634 - accuracy: 0.6802\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.6204 - accuracy: 0.6427\n",
            "484/484 [==============================] - 1s 921us/step - loss: 0.5649 - accuracy: 0.7026\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.6056 - accuracy: 0.6483\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.5585 - accuracy: 0.6833\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.6509 - accuracy: 0.6468\n",
            "484/484 [==============================] - 1s 995us/step - loss: 0.5915 - accuracy: 0.6758\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.6152 - accuracy: 0.6557\n",
            "484/484 [==============================] - 1s 972us/step - loss: 0.5492 - accuracy: 0.6998\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.6181 - accuracy: 0.6468\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.5587 - accuracy: 0.6888\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.6289 - accuracy: 0.6328\n",
            "484/484 [==============================] - 1s 928us/step - loss: 0.5534 - accuracy: 0.6975\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.6731 - accuracy: 0.5979\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.6561 - accuracy: 0.6398\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.6776 - accuracy: 0.5879\n",
            "484/484 [==============================] - 1s 960us/step - loss: 0.6590 - accuracy: 0.6231\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.6775 - accuracy: 0.5640\n",
            "484/484 [==============================] - 1s 961us/step - loss: 0.6581 - accuracy: 0.6143\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.6698 - accuracy: 0.5935\n",
            "484/484 [==============================] - 1s 978us/step - loss: 0.6533 - accuracy: 0.6246\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.6292 - accuracy: 0.6251\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.5636 - accuracy: 0.6825\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.5924 - accuracy: 0.6688\n",
            "484/484 [==============================] - 1s 979us/step - loss: 0.5384 - accuracy: 0.7160\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.6311 - accuracy: 0.6228\n",
            "484/484 [==============================] - 1s 977us/step - loss: 0.5610 - accuracy: 0.6955\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.6072 - accuracy: 0.6609\n",
            "484/484 [==============================] - 1s 978us/step - loss: 0.5442 - accuracy: 0.7082\n",
            "1451/1451 [==============================] - 3s 1ms/step - loss: 0.5032 - accuracy: 0.7429\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.4646 - accuracy: 0.7708\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.5140 - accuracy: 0.7352\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.4704 - accuracy: 0.7691\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.5188 - accuracy: 0.7337\n",
            "484/484 [==============================] - 1s 979us/step - loss: 0.4728 - accuracy: 0.7579\n",
            "1451/1451 [==============================] - 2s 1ms/step - loss: 0.5128 - accuracy: 0.7374\n",
            "484/484 [==============================] - 1s 958us/step - loss: 0.4708 - accuracy: 0.7611\n",
            "1935/1935 [==============================] - 3s 1ms/step - loss: 0.4964 - accuracy: 0.7486\n",
            "Epoch 1/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4871 - accuracy: 0.7502\n",
            "Epoch 2/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4465 - accuracy: 0.7744\n",
            "Epoch 3/20\n",
            "3440/3440 [==============================] - 6s 2ms/step - loss: 0.4366 - accuracy: 0.7792\n",
            "Epoch 4/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4313 - accuracy: 0.7826\n",
            "Epoch 5/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4276 - accuracy: 0.7852\n",
            "Epoch 6/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4246 - accuracy: 0.7877\n",
            "Epoch 7/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4228 - accuracy: 0.7883\n",
            "Epoch 8/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4211 - accuracy: 0.7914\n",
            "Epoch 9/20\n",
            "3440/3440 [==============================] - 6s 2ms/step - loss: 0.4188 - accuracy: 0.7925\n",
            "Epoch 10/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4172 - accuracy: 0.7958\n",
            "Epoch 11/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4159 - accuracy: 0.7972\n",
            "Epoch 12/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4149 - accuracy: 0.7965\n",
            "Epoch 13/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4141 - accuracy: 0.7983\n",
            "Epoch 14/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4135 - accuracy: 0.7992\n",
            "Epoch 15/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4124 - accuracy: 0.8007\n",
            "Epoch 16/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4114 - accuracy: 0.8022\n",
            "Epoch 17/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4112 - accuracy: 0.8011\n",
            "Epoch 18/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4104 - accuracy: 0.8018\n",
            "Epoch 19/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4103 - accuracy: 0.8023\n",
            "Epoch 20/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4095 - accuracy: 0.8036\n",
            "688/688 [==============================] - 1s 1ms/step - loss: 0.4209 - accuracy: 0.8064\n",
            "Epoch 1/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4138 - accuracy: 0.8032\n",
            "Epoch 2/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4132 - accuracy: 0.8019\n",
            "Epoch 3/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4126 - accuracy: 0.8030\n",
            "Epoch 4/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4128 - accuracy: 0.8034\n",
            "Epoch 5/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4124 - accuracy: 0.8029\n",
            "Epoch 6/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4123 - accuracy: 0.8022\n",
            "Epoch 7/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4125 - accuracy: 0.8030\n",
            "Epoch 8/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4124 - accuracy: 0.8051\n",
            "Epoch 9/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4117 - accuracy: 0.8044\n",
            "Epoch 10/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4121 - accuracy: 0.8037\n",
            "Epoch 11/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4117 - accuracy: 0.8053\n",
            "Epoch 12/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4114 - accuracy: 0.8051\n",
            "Epoch 13/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4114 - accuracy: 0.8059\n",
            "Epoch 14/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4118 - accuracy: 0.8055\n",
            "Epoch 15/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4113 - accuracy: 0.8051\n",
            "Epoch 16/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4112 - accuracy: 0.8036\n",
            "Epoch 17/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4110 - accuracy: 0.8054\n",
            "Epoch 18/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4109 - accuracy: 0.8061\n",
            "Epoch 19/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4107 - accuracy: 0.8049\n",
            "Epoch 20/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4112 - accuracy: 0.8059\n",
            "688/688 [==============================] - 1s 1ms/step - loss: 0.3997 - accuracy: 0.8098\n",
            "Epoch 1/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4095 - accuracy: 0.8083\n",
            "Epoch 2/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4090 - accuracy: 0.8074\n",
            "Epoch 3/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4085 - accuracy: 0.8078\n",
            "Epoch 4/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4085 - accuracy: 0.8071\n",
            "Epoch 5/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4080 - accuracy: 0.8092\n",
            "Epoch 6/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4080 - accuracy: 0.8083\n",
            "Epoch 7/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4079 - accuracy: 0.8078\n",
            "Epoch 8/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4079 - accuracy: 0.8090\n",
            "Epoch 9/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4071 - accuracy: 0.8087\n",
            "Epoch 10/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4075 - accuracy: 0.8081\n",
            "Epoch 11/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4071 - accuracy: 0.8091\n",
            "Epoch 12/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4072 - accuracy: 0.8094\n",
            "Epoch 13/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4069 - accuracy: 0.8095\n",
            "Epoch 14/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4071 - accuracy: 0.8100\n",
            "Epoch 15/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4067 - accuracy: 0.8099\n",
            "Epoch 16/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4070 - accuracy: 0.8089\n",
            "Epoch 17/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4067 - accuracy: 0.8108\n",
            "Epoch 18/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4062 - accuracy: 0.8099\n",
            "Epoch 19/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4063 - accuracy: 0.8105\n",
            "Epoch 20/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4062 - accuracy: 0.8112\n",
            "688/688 [==============================] - 1s 1ms/step - loss: 0.4112 - accuracy: 0.7991\n",
            "Epoch 1/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4049 - accuracy: 0.8101\n",
            "Epoch 2/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4047 - accuracy: 0.8095\n",
            "Epoch 3/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4044 - accuracy: 0.8098\n",
            "Epoch 4/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4041 - accuracy: 0.8102\n",
            "Epoch 5/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4039 - accuracy: 0.8111\n",
            "Epoch 6/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4043 - accuracy: 0.8112\n",
            "Epoch 7/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4040 - accuracy: 0.8109\n",
            "Epoch 8/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4040 - accuracy: 0.8108\n",
            "Epoch 9/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4033 - accuracy: 0.8109\n",
            "Epoch 10/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4037 - accuracy: 0.8098\n",
            "Epoch 11/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4034 - accuracy: 0.8111\n",
            "Epoch 12/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4036 - accuracy: 0.8114\n",
            "Epoch 13/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4034 - accuracy: 0.8104\n",
            "Epoch 14/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4036 - accuracy: 0.8110\n",
            "Epoch 15/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4033 - accuracy: 0.8118\n",
            "Epoch 16/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4033 - accuracy: 0.8113\n",
            "Epoch 17/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4031 - accuracy: 0.8120\n",
            "Epoch 18/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4027 - accuracy: 0.8134\n",
            "Epoch 19/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4027 - accuracy: 0.8120\n",
            "Epoch 20/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4024 - accuracy: 0.8130\n",
            "688/688 [==============================] - 1s 1ms/step - loss: 0.4209 - accuracy: 0.8017\n",
            "Epoch 1/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4042 - accuracy: 0.8122\n",
            "Epoch 2/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4040 - accuracy: 0.8120\n",
            "Epoch 3/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4037 - accuracy: 0.8128\n",
            "Epoch 4/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4035 - accuracy: 0.8131\n",
            "Epoch 5/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4031 - accuracy: 0.8134\n",
            "Epoch 6/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4034 - accuracy: 0.8137\n",
            "Epoch 7/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4035 - accuracy: 0.8136\n",
            "Epoch 8/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4035 - accuracy: 0.8138\n",
            "Epoch 9/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4031 - accuracy: 0.8133\n",
            "Epoch 10/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4033 - accuracy: 0.8131\n",
            "Epoch 11/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4032 - accuracy: 0.8130\n",
            "Epoch 12/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4033 - accuracy: 0.8138\n",
            "Epoch 13/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4032 - accuracy: 0.8130\n",
            "Epoch 14/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4031 - accuracy: 0.8133\n",
            "Epoch 15/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4031 - accuracy: 0.8138\n",
            "Epoch 16/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4031 - accuracy: 0.8132\n",
            "Epoch 17/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4032 - accuracy: 0.8142\n",
            "Epoch 18/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4029 - accuracy: 0.8134\n",
            "Epoch 19/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4030 - accuracy: 0.8148\n",
            "Epoch 20/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4030 - accuracy: 0.8138\n",
            "688/688 [==============================] - 1s 981us/step - loss: 0.4153 - accuracy: 0.8031\n",
            "Epoch 1/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4064 - accuracy: 0.8118\n",
            "Epoch 2/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4062 - accuracy: 0.8124\n",
            "Epoch 3/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4059 - accuracy: 0.8126\n",
            "Epoch 4/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4059 - accuracy: 0.8118\n",
            "Epoch 5/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4054 - accuracy: 0.8125\n",
            "Epoch 6/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4057 - accuracy: 0.8128\n",
            "Epoch 7/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4060 - accuracy: 0.8131\n",
            "Epoch 8/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4059 - accuracy: 0.8126\n",
            "Epoch 9/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4057 - accuracy: 0.8128\n",
            "Epoch 10/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4060 - accuracy: 0.8137\n",
            "Epoch 11/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4061 - accuracy: 0.8121\n",
            "Epoch 12/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4058 - accuracy: 0.8137\n",
            "Epoch 13/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4056 - accuracy: 0.8128\n",
            "Epoch 14/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4059 - accuracy: 0.8133\n",
            "Epoch 15/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4054 - accuracy: 0.8130\n",
            "Epoch 16/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4055 - accuracy: 0.8134\n",
            "Epoch 17/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4058 - accuracy: 0.8136\n",
            "Epoch 18/20\n",
            "3440/3440 [==============================] - 5s 1ms/step - loss: 0.4055 - accuracy: 0.8126\n",
            "Epoch 19/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4053 - accuracy: 0.8134\n",
            "Epoch 20/20\n",
            "3440/3440 [==============================] - 4s 1ms/step - loss: 0.4053 - accuracy: 0.8134\n",
            "688/688 [==============================] - 1s 973us/step - loss: 0.4033 - accuracy: 0.8127\n",
            "Epoch 1/20\n",
            "5159/5159 [==============================] - 7s 1ms/step - loss: 0.4065 - accuracy: 0.8117\n",
            "Epoch 2/20\n",
            "5159/5159 [==============================] - 6s 1ms/step - loss: 0.4079 - accuracy: 0.8106\n",
            "Epoch 3/20\n",
            "5159/5159 [==============================] - 7s 1ms/step - loss: 0.4082 - accuracy: 0.8119\n",
            "Epoch 4/20\n",
            "5159/5159 [==============================] - 7s 1ms/step - loss: 0.4087 - accuracy: 0.8110\n",
            "Epoch 5/20\n",
            "5159/5159 [==============================] - 7s 1ms/step - loss: 0.4093 - accuracy: 0.8112\n",
            "Epoch 6/20\n",
            "5159/5159 [==============================] - 6s 1ms/step - loss: 0.4094 - accuracy: 0.8108\n",
            "Epoch 7/20\n",
            "5159/5159 [==============================] - 6s 1ms/step - loss: 0.4095 - accuracy: 0.8101\n",
            "Epoch 8/20\n",
            "5159/5159 [==============================] - 6s 1ms/step - loss: 0.4107 - accuracy: 0.8114\n",
            "Epoch 9/20\n",
            "5159/5159 [==============================] - 6s 1ms/step - loss: 0.4107 - accuracy: 0.8107\n",
            "Epoch 10/20\n",
            "5159/5159 [==============================] - 7s 1ms/step - loss: 0.4107 - accuracy: 0.8118\n",
            "Epoch 11/20\n",
            "5159/5159 [==============================] - 6s 1ms/step - loss: 0.4111 - accuracy: 0.8098\n",
            "Epoch 12/20\n",
            "5159/5159 [==============================] - 7s 1ms/step - loss: 0.4111 - accuracy: 0.8113\n",
            "Epoch 13/20\n",
            "5159/5159 [==============================] - 6s 1ms/step - loss: 0.4112 - accuracy: 0.8107\n",
            "Epoch 14/20\n",
            "5159/5159 [==============================] - 7s 1ms/step - loss: 0.4113 - accuracy: 0.8097\n",
            "Epoch 15/20\n",
            "5159/5159 [==============================] - 6s 1ms/step - loss: 0.4113 - accuracy: 0.8115\n",
            "Epoch 16/20\n",
            "5159/5159 [==============================] - 7s 1ms/step - loss: 0.4117 - accuracy: 0.8109\n",
            "Epoch 17/20\n",
            "5159/5159 [==============================] - 6s 1ms/step - loss: 0.4116 - accuracy: 0.8098\n",
            "Epoch 18/20\n",
            "5159/5159 [==============================] - 6s 1ms/step - loss: 0.4119 - accuracy: 0.8105\n",
            "Epoch 19/20\n",
            "5159/5159 [==============================] - 6s 1ms/step - loss: 0.4119 - accuracy: 0.8100\n",
            "Epoch 20/20\n",
            "5159/5159 [==============================] - 6s 1ms/step - loss: 0.4114 - accuracy: 0.8120\n",
            "1032/1032 [==============================] - 1s 1ms/step - loss: 0.4265 - accuracy: 0.8142\n",
            "Epoch 1/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4169 - accuracy: 0.8099\n",
            "Epoch 2/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4170 - accuracy: 0.8097\n",
            "Epoch 3/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4159 - accuracy: 0.8100\n",
            "Epoch 4/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4162 - accuracy: 0.8104\n",
            "Epoch 5/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4159 - accuracy: 0.8109\n",
            "Epoch 6/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4160 - accuracy: 0.8091\n",
            "Epoch 7/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4164 - accuracy: 0.8099\n",
            "Epoch 8/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4161 - accuracy: 0.8108\n",
            "Epoch 9/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4159 - accuracy: 0.8098\n",
            "Epoch 10/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4161 - accuracy: 0.8096\n",
            "Epoch 11/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4163 - accuracy: 0.8101\n",
            "Epoch 12/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4163 - accuracy: 0.8109\n",
            "Epoch 13/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4163 - accuracy: 0.8104\n",
            "Epoch 14/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4169 - accuracy: 0.8096\n",
            "Epoch 15/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4168 - accuracy: 0.8099\n",
            "Epoch 16/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4167 - accuracy: 0.8101\n",
            "Epoch 17/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4168 - accuracy: 0.8104\n",
            "Epoch 18/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4168 - accuracy: 0.8104\n",
            "Epoch 19/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4170 - accuracy: 0.8108\n",
            "Epoch 20/20\n",
            "5160/5160 [==============================] - 8s 1ms/step - loss: 0.4173 - accuracy: 0.8109\n",
            "1032/1032 [==============================] - 1s 970us/step - loss: 0.4056 - accuracy: 0.8181\n",
            "Epoch 1/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4164 - accuracy: 0.8131\n",
            "Epoch 2/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4165 - accuracy: 0.8131\n",
            "Epoch 3/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4161 - accuracy: 0.8128\n",
            "Epoch 4/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4162 - accuracy: 0.8115\n",
            "Epoch 5/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4161 - accuracy: 0.8138\n",
            "Epoch 6/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4156 - accuracy: 0.8132\n",
            "Epoch 7/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4162 - accuracy: 0.8124\n",
            "Epoch 8/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4160 - accuracy: 0.8134\n",
            "Epoch 9/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4150 - accuracy: 0.8124\n",
            "Epoch 10/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4157 - accuracy: 0.8113\n",
            "Epoch 11/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4160 - accuracy: 0.8132\n",
            "Epoch 12/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4158 - accuracy: 0.8136\n",
            "Epoch 13/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4156 - accuracy: 0.8125\n",
            "Epoch 14/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4161 - accuracy: 0.8119\n",
            "Epoch 15/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4159 - accuracy: 0.8125\n",
            "Epoch 16/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4164 - accuracy: 0.8121\n",
            "Epoch 17/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4165 - accuracy: 0.8129\n",
            "Epoch 18/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4164 - accuracy: 0.8125\n",
            "Epoch 19/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4165 - accuracy: 0.8131\n",
            "Epoch 20/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4165 - accuracy: 0.8137\n",
            "1032/1032 [==============================] - 1s 1ms/step - loss: 0.4188 - accuracy: 0.8066\n",
            "Epoch 1/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4146 - accuracy: 0.8130\n",
            "Epoch 2/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4149 - accuracy: 0.8123\n",
            "Epoch 3/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4146 - accuracy: 0.8126\n",
            "Epoch 4/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4142 - accuracy: 0.8121\n",
            "Epoch 5/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4146 - accuracy: 0.8130\n",
            "Epoch 6/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4144 - accuracy: 0.8131\n",
            "Epoch 7/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4146 - accuracy: 0.8131\n",
            "Epoch 8/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4146 - accuracy: 0.8130\n",
            "Epoch 9/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4140 - accuracy: 0.8128\n",
            "Epoch 10/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4143 - accuracy: 0.8124\n",
            "Epoch 11/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4145 - accuracy: 0.8134\n",
            "Epoch 12/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4149 - accuracy: 0.8129\n",
            "Epoch 13/20\n",
            "5160/5160 [==============================] - 8s 2ms/step - loss: 0.4149 - accuracy: 0.8128\n",
            "Epoch 14/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4151 - accuracy: 0.8125\n",
            "Epoch 15/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4152 - accuracy: 0.8138\n",
            "Epoch 16/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4154 - accuracy: 0.8121\n",
            "Epoch 17/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4154 - accuracy: 0.8138\n",
            "Epoch 18/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4147 - accuracy: 0.8131\n",
            "Epoch 19/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4149 - accuracy: 0.8132\n",
            "Epoch 20/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4149 - accuracy: 0.8133\n",
            "1032/1032 [==============================] - 1s 976us/step - loss: 0.4326 - accuracy: 0.8073\n",
            "Epoch 1/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4172 - accuracy: 0.8131\n",
            "Epoch 2/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4178 - accuracy: 0.8135\n",
            "Epoch 3/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4172 - accuracy: 0.8126\n",
            "Epoch 4/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4170 - accuracy: 0.8136\n",
            "Epoch 5/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4170 - accuracy: 0.8142\n",
            "Epoch 6/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4167 - accuracy: 0.8139\n",
            "Epoch 7/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4172 - accuracy: 0.8134\n",
            "Epoch 8/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4173 - accuracy: 0.8141\n",
            "Epoch 9/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4173 - accuracy: 0.8138\n",
            "Epoch 10/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4173 - accuracy: 0.8128\n",
            "Epoch 11/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4174 - accuracy: 0.8138\n",
            "Epoch 12/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4176 - accuracy: 0.8139\n",
            "Epoch 13/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4174 - accuracy: 0.8127\n",
            "Epoch 14/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4175 - accuracy: 0.8139\n",
            "Epoch 15/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4175 - accuracy: 0.8132\n",
            "Epoch 16/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4178 - accuracy: 0.8138\n",
            "Epoch 17/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4182 - accuracy: 0.8139\n",
            "Epoch 18/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4175 - accuracy: 0.8137\n",
            "Epoch 19/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4175 - accuracy: 0.8138\n",
            "Epoch 20/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4179 - accuracy: 0.8135\n",
            "1032/1032 [==============================] - 1s 1ms/step - loss: 0.4258 - accuracy: 0.8013\n",
            "Epoch 1/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4203 - accuracy: 0.8119\n",
            "Epoch 2/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4202 - accuracy: 0.8128\n",
            "Epoch 3/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4193 - accuracy: 0.8111\n",
            "Epoch 4/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4197 - accuracy: 0.8126\n",
            "Epoch 5/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4193 - accuracy: 0.8118\n",
            "Epoch 6/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4192 - accuracy: 0.8122\n",
            "Epoch 7/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4201 - accuracy: 0.8110\n",
            "Epoch 8/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4197 - accuracy: 0.8119\n",
            "Epoch 9/20\n",
            "5160/5160 [==============================] - 8s 1ms/step - loss: 0.4198 - accuracy: 0.8122\n",
            "Epoch 10/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4200 - accuracy: 0.8125\n",
            "Epoch 11/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4202 - accuracy: 0.8117\n",
            "Epoch 12/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4202 - accuracy: 0.8126\n",
            "Epoch 13/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4201 - accuracy: 0.8116\n",
            "Epoch 14/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4202 - accuracy: 0.8120\n",
            "Epoch 15/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4199 - accuracy: 0.8116\n",
            "Epoch 16/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4200 - accuracy: 0.8125\n",
            "Epoch 17/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4204 - accuracy: 0.8123\n",
            "Epoch 18/20\n",
            "5160/5160 [==============================] - 7s 1ms/step - loss: 0.4199 - accuracy: 0.8107\n",
            "Epoch 19/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4199 - accuracy: 0.8112\n",
            "Epoch 20/20\n",
            "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4200 - accuracy: 0.8121\n",
            "1032/1032 [==============================] - 1s 1ms/step - loss: 0.4200 - accuracy: 0.8089\n",
            "Epoch 1/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4157 - accuracy: 0.8114\n",
            "Epoch 2/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4129 - accuracy: 0.8110\n",
            "Epoch 3/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4115 - accuracy: 0.8117\n",
            "Epoch 4/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.4104 - accuracy: 0.8119\n",
            "Epoch 5/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4097 - accuracy: 0.8126\n",
            "Epoch 6/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4091 - accuracy: 0.8124\n",
            "Epoch 7/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4085 - accuracy: 0.8114\n",
            "Epoch 8/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4081 - accuracy: 0.8128\n",
            "Epoch 9/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.4076 - accuracy: 0.8126\n",
            "Epoch 10/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4075 - accuracy: 0.8128\n",
            "Epoch 11/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4073 - accuracy: 0.8132\n",
            "Epoch 12/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4069 - accuracy: 0.8126\n",
            "Epoch 13/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.4066 - accuracy: 0.8134\n",
            "Epoch 14/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4060 - accuracy: 0.8137\n",
            "Epoch 15/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4057 - accuracy: 0.8147\n",
            "Epoch 16/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4058 - accuracy: 0.8142\n",
            "Epoch 17/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4050 - accuracy: 0.8130\n",
            "Epoch 18/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.4052 - accuracy: 0.8144\n",
            "Epoch 19/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4048 - accuracy: 0.8139\n",
            "Epoch 20/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4040 - accuracy: 0.8144\n",
            "Epoch 21/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4048 - accuracy: 0.8137\n",
            "Epoch 22/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.4041 - accuracy: 0.8132\n",
            "Epoch 23/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4039 - accuracy: 0.8133\n",
            "Epoch 24/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4043 - accuracy: 0.8144\n",
            "Epoch 25/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4040 - accuracy: 0.8149\n",
            "Epoch 26/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.4036 - accuracy: 0.8150\n",
            "Epoch 27/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4035 - accuracy: 0.8148\n",
            "Epoch 28/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4031 - accuracy: 0.8147\n",
            "Epoch 29/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4033 - accuracy: 0.8143\n",
            "Epoch 30/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4028 - accuracy: 0.8146\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.4123 - accuracy: 0.8164\n",
            "Epoch 1/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4071 - accuracy: 0.8131\n",
            "Epoch 2/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4069 - accuracy: 0.8134\n",
            "Epoch 3/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4062 - accuracy: 0.8140\n",
            "Epoch 4/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4058 - accuracy: 0.8135\n",
            "Epoch 5/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.4060 - accuracy: 0.8141\n",
            "Epoch 6/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4056 - accuracy: 0.8147\n",
            "Epoch 7/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4057 - accuracy: 0.8144\n",
            "Epoch 8/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4053 - accuracy: 0.8142\n",
            "Epoch 9/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.4052 - accuracy: 0.8143\n",
            "Epoch 10/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4052 - accuracy: 0.8144\n",
            "Epoch 11/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4052 - accuracy: 0.8152\n",
            "Epoch 12/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4048 - accuracy: 0.8149\n",
            "Epoch 13/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.4047 - accuracy: 0.8150\n",
            "Epoch 14/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.4049 - accuracy: 0.8142\n",
            "Epoch 15/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4047 - accuracy: 0.8154\n",
            "Epoch 16/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4044 - accuracy: 0.8147\n",
            "Epoch 17/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4043 - accuracy: 0.8151\n",
            "Epoch 18/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.4041 - accuracy: 0.8155\n",
            "Epoch 19/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4041 - accuracy: 0.8152\n",
            "Epoch 20/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4043 - accuracy: 0.8155\n",
            "Epoch 21/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4035 - accuracy: 0.8153\n",
            "Epoch 22/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4037 - accuracy: 0.8150\n",
            "Epoch 23/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.4039 - accuracy: 0.8155\n",
            "Epoch 24/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4035 - accuracy: 0.8154\n",
            "Epoch 25/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4038 - accuracy: 0.8150\n",
            "Epoch 26/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4038 - accuracy: 0.8152\n",
            "Epoch 27/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.4031 - accuracy: 0.8153\n",
            "Epoch 28/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4035 - accuracy: 0.8156\n",
            "Epoch 29/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4037 - accuracy: 0.8146\n",
            "Epoch 30/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4032 - accuracy: 0.8154\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3946 - accuracy: 0.8207\n",
            "Epoch 1/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.4028 - accuracy: 0.8163\n",
            "Epoch 2/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4028 - accuracy: 0.8167\n",
            "Epoch 3/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4025 - accuracy: 0.8171\n",
            "Epoch 4/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4020 - accuracy: 0.8166\n",
            "Epoch 5/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.4021 - accuracy: 0.8177\n",
            "Epoch 6/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.4015 - accuracy: 0.8167\n",
            "Epoch 7/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4018 - accuracy: 0.8173\n",
            "Epoch 8/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4016 - accuracy: 0.8170\n",
            "Epoch 9/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4011 - accuracy: 0.8172\n",
            "Epoch 10/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.4012 - accuracy: 0.8171\n",
            "Epoch 11/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4013 - accuracy: 0.8178\n",
            "Epoch 12/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4010 - accuracy: 0.8181\n",
            "Epoch 13/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4009 - accuracy: 0.8175\n",
            "Epoch 14/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.4011 - accuracy: 0.8176\n",
            "Epoch 15/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4009 - accuracy: 0.8180\n",
            "Epoch 16/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4008 - accuracy: 0.8171\n",
            "Epoch 17/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4009 - accuracy: 0.8174\n",
            "Epoch 18/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4006 - accuracy: 0.8176\n",
            "Epoch 19/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.4006 - accuracy: 0.8180\n",
            "Epoch 20/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4002 - accuracy: 0.8187\n",
            "Epoch 21/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3996 - accuracy: 0.8176\n",
            "Epoch 22/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4000 - accuracy: 0.8173\n",
            "Epoch 23/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.4006 - accuracy: 0.8187\n",
            "Epoch 24/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3998 - accuracy: 0.8174\n",
            "Epoch 25/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4002 - accuracy: 0.8180\n",
            "Epoch 26/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4003 - accuracy: 0.8176\n",
            "Epoch 27/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3995 - accuracy: 0.8176\n",
            "Epoch 28/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3998 - accuracy: 0.8179\n",
            "Epoch 29/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3999 - accuracy: 0.8167\n",
            "Epoch 30/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3999 - accuracy: 0.8175\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3994 - accuracy: 0.8136\n",
            "Epoch 1/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3978 - accuracy: 0.8174\n",
            "Epoch 2/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3980 - accuracy: 0.8186\n",
            "Epoch 3/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3978 - accuracy: 0.8181\n",
            "Epoch 4/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3973 - accuracy: 0.8172\n",
            "Epoch 5/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3975 - accuracy: 0.8189\n",
            "Epoch 6/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3973 - accuracy: 0.8179\n",
            "Epoch 7/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3976 - accuracy: 0.8179\n",
            "Epoch 8/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3972 - accuracy: 0.8174\n",
            "Epoch 9/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3971 - accuracy: 0.8176\n",
            "Epoch 10/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3971 - accuracy: 0.8175\n",
            "Epoch 11/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3974 - accuracy: 0.8180\n",
            "Epoch 12/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3972 - accuracy: 0.8187\n",
            "Epoch 13/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3973 - accuracy: 0.8183\n",
            "Epoch 14/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3974 - accuracy: 0.8186\n",
            "Epoch 15/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3973 - accuracy: 0.8188\n",
            "Epoch 16/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3974 - accuracy: 0.8187\n",
            "Epoch 17/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3973 - accuracy: 0.8176\n",
            "Epoch 18/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3967 - accuracy: 0.8192\n",
            "Epoch 19/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3970 - accuracy: 0.8186\n",
            "Epoch 20/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3965 - accuracy: 0.8185\n",
            "Epoch 21/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3961 - accuracy: 0.8171\n",
            "Epoch 22/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3968 - accuracy: 0.8184\n",
            "Epoch 23/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3973 - accuracy: 0.8185\n",
            "Epoch 24/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3966 - accuracy: 0.8182\n",
            "Epoch 25/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3968 - accuracy: 0.8188\n",
            "Epoch 26/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3966 - accuracy: 0.8188\n",
            "Epoch 27/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3962 - accuracy: 0.8182\n",
            "Epoch 28/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3963 - accuracy: 0.8185\n",
            "Epoch 29/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3963 - accuracy: 0.8183\n",
            "Epoch 30/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3964 - accuracy: 0.8185\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.4159 - accuracy: 0.8125\n",
            "Epoch 1/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3989 - accuracy: 0.8184\n",
            "Epoch 2/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3988 - accuracy: 0.8190\n",
            "Epoch 3/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3986 - accuracy: 0.8174\n",
            "Epoch 4/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3985 - accuracy: 0.8187\n",
            "Epoch 5/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3983 - accuracy: 0.8189\n",
            "Epoch 6/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3979 - accuracy: 0.8182\n",
            "Epoch 7/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3983 - accuracy: 0.8187\n",
            "Epoch 8/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3979 - accuracy: 0.8184\n",
            "Epoch 9/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3981 - accuracy: 0.8187\n",
            "Epoch 10/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3980 - accuracy: 0.8189\n",
            "Epoch 11/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3980 - accuracy: 0.8191\n",
            "Epoch 12/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3981 - accuracy: 0.8192\n",
            "Epoch 13/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3981 - accuracy: 0.8186\n",
            "Epoch 14/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3980 - accuracy: 0.8193\n",
            "Epoch 15/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3981 - accuracy: 0.8193\n",
            "Epoch 16/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3977 - accuracy: 0.8198\n",
            "Epoch 17/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3980 - accuracy: 0.8190\n",
            "Epoch 18/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3974 - accuracy: 0.8190\n",
            "Epoch 19/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3974 - accuracy: 0.8191\n",
            "Epoch 20/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3974 - accuracy: 0.8190\n",
            "Epoch 21/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3970 - accuracy: 0.8196\n",
            "Epoch 22/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3975 - accuracy: 0.8195\n",
            "Epoch 23/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3978 - accuracy: 0.8194\n",
            "Epoch 24/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3970 - accuracy: 0.8193\n",
            "Epoch 25/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3973 - accuracy: 0.8200\n",
            "Epoch 26/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3973 - accuracy: 0.8190\n",
            "Epoch 27/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3971 - accuracy: 0.8187\n",
            "Epoch 28/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3969 - accuracy: 0.8187\n",
            "Epoch 29/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3970 - accuracy: 0.8194\n",
            "Epoch 30/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3974 - accuracy: 0.8183\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.4076 - accuracy: 0.8088\n",
            "Epoch 1/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.4000 - accuracy: 0.8173\n",
            "Epoch 2/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3998 - accuracy: 0.8177\n",
            "Epoch 3/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3997 - accuracy: 0.8172\n",
            "Epoch 4/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3996 - accuracy: 0.8174\n",
            "Epoch 5/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3997 - accuracy: 0.8176\n",
            "Epoch 6/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3993 - accuracy: 0.8181\n",
            "Epoch 7/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3997 - accuracy: 0.8179\n",
            "Epoch 8/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3991 - accuracy: 0.8173\n",
            "Epoch 9/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3994 - accuracy: 0.8179\n",
            "Epoch 10/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3996 - accuracy: 0.8174\n",
            "Epoch 11/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3997 - accuracy: 0.8177\n",
            "Epoch 12/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3996 - accuracy: 0.8185\n",
            "Epoch 13/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3993 - accuracy: 0.8181\n",
            "Epoch 14/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3995 - accuracy: 0.8175\n",
            "Epoch 15/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3992 - accuracy: 0.8185\n",
            "Epoch 16/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3990 - accuracy: 0.8187\n",
            "Epoch 17/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3992 - accuracy: 0.8175\n",
            "Epoch 18/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3988 - accuracy: 0.8184\n",
            "Epoch 19/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3988 - accuracy: 0.8178\n",
            "Epoch 20/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3986 - accuracy: 0.8177\n",
            "Epoch 21/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3983 - accuracy: 0.8179\n",
            "Epoch 22/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3987 - accuracy: 0.8182\n",
            "Epoch 23/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3989 - accuracy: 0.8181\n",
            "Epoch 24/30\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3984 - accuracy: 0.8185\n",
            "Epoch 25/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3986 - accuracy: 0.8187\n",
            "Epoch 26/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3987 - accuracy: 0.8177\n",
            "Epoch 27/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3986 - accuracy: 0.8179\n",
            "Epoch 28/30\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3985 - accuracy: 0.8177\n",
            "Epoch 29/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3985 - accuracy: 0.8180\n",
            "Epoch 30/30\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3985 - accuracy: 0.8186\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.4004 - accuracy: 0.8128\n",
            "Epoch 1/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3974 - accuracy: 0.8173\n",
            "Epoch 2/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3970 - accuracy: 0.8158\n",
            "Epoch 3/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3972 - accuracy: 0.8159\n",
            "Epoch 4/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3969 - accuracy: 0.8165\n",
            "Epoch 5/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3969 - accuracy: 0.8173\n",
            "Epoch 6/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3969 - accuracy: 0.8165\n",
            "Epoch 7/20\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3967 - accuracy: 0.8167\n",
            "Epoch 8/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3967 - accuracy: 0.8168\n",
            "Epoch 9/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3967 - accuracy: 0.8170\n",
            "Epoch 10/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3969 - accuracy: 0.8171\n",
            "Epoch 11/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3971 - accuracy: 0.8166\n",
            "Epoch 12/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3967 - accuracy: 0.8171\n",
            "Epoch 13/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3967 - accuracy: 0.8168\n",
            "Epoch 14/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3963 - accuracy: 0.8181\n",
            "Epoch 15/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3963 - accuracy: 0.8174\n",
            "Epoch 16/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3966 - accuracy: 0.8173\n",
            "Epoch 17/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3961 - accuracy: 0.8169\n",
            "Epoch 18/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3966 - accuracy: 0.8178\n",
            "Epoch 19/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3966 - accuracy: 0.8179\n",
            "Epoch 20/20\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3959 - accuracy: 0.8178\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.4098 - accuracy: 0.8225\n",
            "Epoch 1/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4009 - accuracy: 0.8171\n",
            "Epoch 2/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.4007 - accuracy: 0.8164\n",
            "Epoch 3/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3999 - accuracy: 0.8165\n",
            "Epoch 4/20\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3995 - accuracy: 0.8180\n",
            "Epoch 5/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3999 - accuracy: 0.8172\n",
            "Epoch 6/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3993 - accuracy: 0.8163\n",
            "Epoch 7/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3997 - accuracy: 0.8172\n",
            "Epoch 8/20\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3997 - accuracy: 0.8168\n",
            "Epoch 9/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3993 - accuracy: 0.8166\n",
            "Epoch 10/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3994 - accuracy: 0.8177\n",
            "Epoch 11/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3996 - accuracy: 0.8172\n",
            "Epoch 12/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3993 - accuracy: 0.8170\n",
            "Epoch 13/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3991 - accuracy: 0.8177\n",
            "Epoch 14/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3995 - accuracy: 0.8172\n",
            "Epoch 15/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3992 - accuracy: 0.8171\n",
            "Epoch 16/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3993 - accuracy: 0.8167\n",
            "Epoch 17/20\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3993 - accuracy: 0.8167\n",
            "Epoch 18/20\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3990 - accuracy: 0.8180\n",
            "Epoch 19/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3990 - accuracy: 0.8165\n",
            "Epoch 20/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3992 - accuracy: 0.8175\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3887 - accuracy: 0.8229\n",
            "Epoch 1/20\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3980 - accuracy: 0.8188\n",
            "Epoch 2/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3981 - accuracy: 0.8188\n",
            "Epoch 3/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3979 - accuracy: 0.8183\n",
            "Epoch 4/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3975 - accuracy: 0.8185\n",
            "Epoch 5/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3977 - accuracy: 0.8200\n",
            "Epoch 6/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3971 - accuracy: 0.8196\n",
            "Epoch 7/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3976 - accuracy: 0.8192\n",
            "Epoch 8/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3976 - accuracy: 0.8185\n",
            "Epoch 9/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3970 - accuracy: 0.8195\n",
            "Epoch 10/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3972 - accuracy: 0.8192\n",
            "Epoch 11/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3973 - accuracy: 0.8198\n",
            "Epoch 12/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3971 - accuracy: 0.8192\n",
            "Epoch 13/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3970 - accuracy: 0.8204\n",
            "Epoch 14/20\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3974 - accuracy: 0.8197\n",
            "Epoch 15/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3971 - accuracy: 0.8194\n",
            "Epoch 16/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3972 - accuracy: 0.8195\n",
            "Epoch 17/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3975 - accuracy: 0.8192\n",
            "Epoch 18/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3972 - accuracy: 0.8192\n",
            "Epoch 19/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3970 - accuracy: 0.8191\n",
            "Epoch 20/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3966 - accuracy: 0.8200\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3990 - accuracy: 0.8134\n",
            "Epoch 1/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3946 - accuracy: 0.8187\n",
            "Epoch 2/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3947 - accuracy: 0.8197\n",
            "Epoch 3/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3947 - accuracy: 0.8191\n",
            "Epoch 4/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3942 - accuracy: 0.8190\n",
            "Epoch 5/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3944 - accuracy: 0.8196\n",
            "Epoch 6/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3943 - accuracy: 0.8190\n",
            "Epoch 7/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3944 - accuracy: 0.8193\n",
            "Epoch 8/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3942 - accuracy: 0.8191\n",
            "Epoch 9/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3941 - accuracy: 0.8185\n",
            "Epoch 10/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3942 - accuracy: 0.8187\n",
            "Epoch 11/20\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3943 - accuracy: 0.8193\n",
            "Epoch 12/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3944 - accuracy: 0.8202\n",
            "Epoch 13/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3946 - accuracy: 0.8200\n",
            "Epoch 14/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3946 - accuracy: 0.8200\n",
            "Epoch 15/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3945 - accuracy: 0.8198\n",
            "Epoch 16/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3945 - accuracy: 0.8201\n",
            "Epoch 17/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3946 - accuracy: 0.8197\n",
            "Epoch 18/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3938 - accuracy: 0.8199\n",
            "Epoch 19/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3941 - accuracy: 0.8196\n",
            "Epoch 20/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3936 - accuracy: 0.8207\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.4125 - accuracy: 0.8138\n",
            "Epoch 1/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3961 - accuracy: 0.8195\n",
            "Epoch 2/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3961 - accuracy: 0.8199\n",
            "Epoch 3/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3961 - accuracy: 0.8204\n",
            "Epoch 4/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3959 - accuracy: 0.8197\n",
            "Epoch 5/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3956 - accuracy: 0.8195\n",
            "Epoch 6/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3954 - accuracy: 0.8200\n",
            "Epoch 7/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3958 - accuracy: 0.8192\n",
            "Epoch 8/20\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3952 - accuracy: 0.8203\n",
            "Epoch 9/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3956 - accuracy: 0.8201\n",
            "Epoch 10/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3956 - accuracy: 0.8202\n",
            "Epoch 11/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3955 - accuracy: 0.8203\n",
            "Epoch 12/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3959 - accuracy: 0.8202\n",
            "Epoch 13/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3958 - accuracy: 0.8199\n",
            "Epoch 14/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3958 - accuracy: 0.8202\n",
            "Epoch 15/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3958 - accuracy: 0.8199\n",
            "Epoch 16/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3954 - accuracy: 0.8207\n",
            "Epoch 17/20\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3957 - accuracy: 0.8200\n",
            "Epoch 18/20\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3950 - accuracy: 0.8204\n",
            "Epoch 19/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3952 - accuracy: 0.8205\n",
            "Epoch 20/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3950 - accuracy: 0.8204\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.4017 - accuracy: 0.8111\n",
            "Epoch 1/20\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3977 - accuracy: 0.8183\n",
            "Epoch 2/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3976 - accuracy: 0.8188\n",
            "Epoch 3/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3975 - accuracy: 0.8193\n",
            "Epoch 4/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3976 - accuracy: 0.8180\n",
            "Epoch 5/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3978 - accuracy: 0.8192\n",
            "Epoch 6/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3974 - accuracy: 0.8195\n",
            "Epoch 7/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3978 - accuracy: 0.8188\n",
            "Epoch 8/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3973 - accuracy: 0.8180\n",
            "Epoch 9/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3976 - accuracy: 0.8191\n",
            "Epoch 10/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3979 - accuracy: 0.8185\n",
            "Epoch 11/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3980 - accuracy: 0.8190\n",
            "Epoch 12/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3980 - accuracy: 0.8192\n",
            "Epoch 13/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3977 - accuracy: 0.8195\n",
            "Epoch 14/20\n",
            "2580/2580 [==============================] - 4s 2ms/step - loss: 0.3980 - accuracy: 0.8191\n",
            "Epoch 15/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3976 - accuracy: 0.8189\n",
            "Epoch 16/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3973 - accuracy: 0.8193\n",
            "Epoch 17/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3976 - accuracy: 0.8190\n",
            "Epoch 18/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3972 - accuracy: 0.8190\n",
            "Epoch 19/20\n",
            "2580/2580 [==============================] - 4s 1ms/step - loss: 0.3973 - accuracy: 0.8197\n",
            "Epoch 20/20\n",
            "2580/2580 [==============================] - 3s 1ms/step - loss: 0.3971 - accuracy: 0.8191\n",
            "516/516 [==============================] - 1s 1ms/step - loss: 0.3943 - accuracy: 0.8157\n",
            "Epoch 1/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3969 - accuracy: 0.8182\n",
            "Epoch 2/20\n",
            "3096/3096 [==============================] - 5s 2ms/step - loss: 0.3964 - accuracy: 0.8185\n",
            "Epoch 3/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3963 - accuracy: 0.8191\n",
            "Epoch 4/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3968 - accuracy: 0.8195\n",
            "Epoch 5/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3971 - accuracy: 0.8176\n",
            "Epoch 6/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3971 - accuracy: 0.8192\n",
            "Epoch 7/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3969 - accuracy: 0.8189\n",
            "Epoch 8/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3971 - accuracy: 0.8183\n",
            "Epoch 9/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3968 - accuracy: 0.8191\n",
            "Epoch 10/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3967 - accuracy: 0.8182\n",
            "Epoch 11/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3961 - accuracy: 0.8195\n",
            "Epoch 12/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3966 - accuracy: 0.8187\n",
            "Epoch 13/20\n",
            "3096/3096 [==============================] - 5s 1ms/step - loss: 0.3970 - accuracy: 0.8190\n",
            "Epoch 14/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3963 - accuracy: 0.8193\n",
            "Epoch 15/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3963 - accuracy: 0.8190\n",
            "Epoch 16/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3966 - accuracy: 0.8190\n",
            "Epoch 17/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3965 - accuracy: 0.8188\n",
            "Epoch 18/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3966 - accuracy: 0.8178\n",
            "Epoch 19/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3959 - accuracy: 0.8197\n",
            "Epoch 20/20\n",
            "3096/3096 [==============================] - 5s 1ms/step - loss: 0.3963 - accuracy: 0.8192\n",
            "Epoch 1/20\n",
            "3096/3096 [==============================] - 5s 1ms/step - loss: 0.3904 - accuracy: 0.8186\n",
            "Epoch 2/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3902 - accuracy: 0.8185\n",
            "Epoch 3/20\n",
            "3096/3096 [==============================] - 5s 2ms/step - loss: 0.3902 - accuracy: 0.8197\n",
            "Epoch 4/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3908 - accuracy: 0.8196\n",
            "Epoch 5/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3911 - accuracy: 0.8182\n",
            "Epoch 6/20\n",
            "3096/3096 [==============================] - 5s 1ms/step - loss: 0.3912 - accuracy: 0.8191\n",
            "Epoch 7/20\n",
            "3096/3096 [==============================] - 5s 2ms/step - loss: 0.3910 - accuracy: 0.8189\n",
            "Epoch 8/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3911 - accuracy: 0.8187\n",
            "Epoch 9/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3909 - accuracy: 0.8192\n",
            "Epoch 10/20\n",
            "3096/3096 [==============================] - 5s 2ms/step - loss: 0.3910 - accuracy: 0.8184\n",
            "Epoch 11/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3905 - accuracy: 0.8195\n",
            "Epoch 12/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3908 - accuracy: 0.8189\n",
            "Epoch 13/20\n",
            "3096/3096 [==============================] - 5s 2ms/step - loss: 0.3912 - accuracy: 0.8192\n",
            "Epoch 14/20\n",
            "3096/3096 [==============================] - 5s 2ms/step - loss: 0.3905 - accuracy: 0.8196\n",
            "Epoch 15/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3907 - accuracy: 0.8189\n",
            "Epoch 16/20\n",
            "3096/3096 [==============================] - 5s 2ms/step - loss: 0.3910 - accuracy: 0.8191\n",
            "Epoch 17/20\n",
            "3096/3096 [==============================] - 5s 1ms/step - loss: 0.3908 - accuracy: 0.8189\n",
            "Epoch 18/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3909 - accuracy: 0.8183\n",
            "Epoch 19/20\n",
            "3096/3096 [==============================] - 4s 1ms/step - loss: 0.3903 - accuracy: 0.8192\n",
            "Epoch 20/20\n",
            "3096/3096 [==============================] - 5s 2ms/step - loss: 0.3906 - accuracy: 0.8196\n",
            "830/830 [==============================] - 1s 924us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arquitectura 3"
      ],
      "metadata": {
        "id": "NIoAnupaczqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimización de los hiperparámetros de la arquitectura 3"
      ],
      "metadata": {
        "id": "-fBlS5yG6Xf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from scipy.stats import randint\n",
        "from keras.regularizers import l2\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_model_3(hidden_layers=1, neurons=128, ln_rate_parameter=0.01):\n",
        "    # Optimizador SGD con learning rate variable\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=ln_rate_parameter)\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(neurons, input_shape=(ds_train_norm.shape[1],), activation='relu', kernel_regularizer=l2(0.01)))\n",
        "\n",
        "    for _ in range(hidden_layers - 1):\n",
        "        model.add(keras.layers.Dense(neurons, activation='relu'))\n",
        "        model.add(Dropout(0.2))  # Añado técnica de regularización por capa oculta\n",
        "\n",
        "    model.add(keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01)))\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "\n",
        "# Optimizamos hiperparámetros de arquitectura\n",
        "model = KerasClassifier(build_fn=create_model_3,callbacks=[early_stopping])\n",
        "param_dist_architecture = {\n",
        "    'neurons': [16, 32, 64, 128],\n",
        "    'hidden_layers': [1, 2, 3],\n",
        "    'ln_rate_parameter':[0.001, 0.005, 0.0001, 0.01]\n",
        "}\n",
        "\n",
        "random_search_architecture = RandomizedSearchCV(estimator=model,\n",
        "                                                param_distributions=param_dist_architecture,\n",
        "                                                n_iter=7, cv=3)\n",
        "random_search_architecture.fit(ds_train_norm, ds_hoteles_train_y)\n",
        "\n",
        "#Obtenemos los mejores\n",
        "best_architecture = random_search_architecture.best_params_\n",
        "\n",
        "# Creamos un modelo con ellos\n",
        "best_model = create_model_3(neurons=best_architecture['neurons'], hidden_layers=best_architecture['hidden_layers'],ln_rate_parameter=best_architecture['ln_rate_parameter'])\n",
        "\n",
        "# Optimizamos hiperparámetros de entrenamiento\n",
        "param_dist_training = {\n",
        "    'epochs': [10, 20, 30],\n",
        "    'batch_size': [20, 25, 30]\n",
        "}\n",
        "\n",
        "random_search_training = RandomizedSearchCV(estimator=KerasClassifier(build_fn=lambda: best_model), param_distributions=param_dist_training, n_iter=3, cv=3)\n",
        "random_search_training.fit(ds_train_norm, ds_hoteles_train_y)\n",
        "\n",
        "# Obtenemos los mejores\n",
        "best_training = random_search_training.best_params_\n",
        "\n",
        "# Entrenamos el dataset completo\n",
        "best_model.fit(ds_train_norm, ds_hoteles_train_y, epochs=best_training['epochs'], batch_size=best_training['batch_size'])\n",
        "\n",
        "# Hacemos predicciones\n",
        "y_probs = best_model.predict(ds_test_norm)\n",
        "y_predictions = (y_probs > 0.5).astype(int)  # Assuming binary classification\n",
        "\n",
        "y_pred = np.ravel(y_predictions)\n",
        "\n",
        "# Realizamos subbmit a Kaggle\n",
        "df_submission_model_3_optimized = pd.DataFrame({'id': ds_hoteles_test['id'], 'is_canceled': y_pred})\n",
        "df_submission_model_3_optimized.to_csv('Submission_red_neuronal_model_3_optimized.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTFJURpuGmgL",
        "outputId": "bc927669-98a1-4973-bb9f-0aaec3fbc9b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1290/1290 [==============================] - 6s 4ms/step - loss: 1.5126 - accuracy: 0.5449\n",
            "645/645 [==============================] - 4s 6ms/step - loss: 1.5081 - accuracy: 0.5515\n",
            "1290/1290 [==============================] - 8s 4ms/step - loss: 1.5501 - accuracy: 0.4760\n",
            "645/645 [==============================] - 4s 6ms/step - loss: 1.5425 - accuracy: 0.4798\n",
            "1290/1290 [==============================] - 6s 3ms/step - loss: 1.5318 - accuracy: 0.4882\n",
            "645/645 [==============================] - 1s 2ms/step - loss: 1.5263 - accuracy: 0.5091\n",
            "1290/1290 [==============================] - 9s 6ms/step - loss: 0.9975 - accuracy: 0.6185\n",
            "645/645 [==============================] - 3s 3ms/step - loss: 0.8781 - accuracy: 0.6818\n",
            "1290/1290 [==============================] - 4s 3ms/step - loss: 0.9935 - accuracy: 0.6072\n",
            "645/645 [==============================] - 1s 2ms/step - loss: 0.8780 - accuracy: 0.6669\n",
            "1290/1290 [==============================] - 4s 3ms/step - loss: 0.9728 - accuracy: 0.6562\n",
            "645/645 [==============================] - 2s 3ms/step - loss: 0.8691 - accuracy: 0.6693\n",
            "1935/1935 [==============================] - 6s 3ms/step - loss: 0.9308 - accuracy: 0.6522\n",
            "Epoch 1/30\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.9167 - accuracy: 0.6666\n",
            "Epoch 2/30\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.7212 - accuracy: 0.7128\n",
            "Epoch 3/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.6460 - accuracy: 0.7272\n",
            "Epoch 4/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.6139 - accuracy: 0.7327\n",
            "Epoch 5/30\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.5999 - accuracy: 0.7363\n",
            "Epoch 6/30\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5935 - accuracy: 0.7378\n",
            "Epoch 7/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5908 - accuracy: 0.7376\n",
            "Epoch 8/30\n",
            "2064/2064 [==============================] - 8s 4ms/step - loss: 0.5895 - accuracy: 0.7380\n",
            "Epoch 9/30\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5889 - accuracy: 0.7399\n",
            "Epoch 10/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5886 - accuracy: 0.7399\n",
            "Epoch 11/30\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5882 - accuracy: 0.7386\n",
            "Epoch 12/30\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5881 - accuracy: 0.7386\n",
            "Epoch 13/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5880 - accuracy: 0.7382\n",
            "Epoch 14/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5879 - accuracy: 0.7389\n",
            "Epoch 15/30\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5877 - accuracy: 0.7404\n",
            "Epoch 16/30\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5876 - accuracy: 0.7391\n",
            "Epoch 17/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5876 - accuracy: 0.7404\n",
            "Epoch 18/30\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5877 - accuracy: 0.7386\n",
            "Epoch 19/30\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5876 - accuracy: 0.7396\n",
            "Epoch 20/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5876 - accuracy: 0.7379\n",
            "Epoch 21/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5877 - accuracy: 0.7382\n",
            "Epoch 22/30\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5875 - accuracy: 0.7391\n",
            "Epoch 23/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5875 - accuracy: 0.7378\n",
            "Epoch 24/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5876 - accuracy: 0.7394\n",
            "Epoch 25/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5875 - accuracy: 0.7398\n",
            "Epoch 26/30\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5875 - accuracy: 0.7399\n",
            "Epoch 27/30\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5876 - accuracy: 0.7385\n",
            "Epoch 28/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5874 - accuracy: 0.7385\n",
            "Epoch 29/30\n",
            "2064/2064 [==============================] - 8s 4ms/step - loss: 0.5875 - accuracy: 0.7382\n",
            "Epoch 30/30\n",
            "2064/2064 [==============================] - 8s 4ms/step - loss: 0.5876 - accuracy: 0.7395\n",
            "1032/1032 [==============================] - 2s 2ms/step - loss: 0.5855 - accuracy: 0.7427\n",
            "Epoch 1/30\n",
            "2064/2064 [==============================] - 7s 3ms/step - loss: 0.5873 - accuracy: 0.7406\n",
            "Epoch 2/30\n",
            "2064/2064 [==============================] - 7s 3ms/step - loss: 0.5870 - accuracy: 0.7401\n",
            "Epoch 3/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5872 - accuracy: 0.7413\n",
            "Epoch 4/30\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5871 - accuracy: 0.7415\n",
            "Epoch 5/30\n",
            "2064/2064 [==============================] - 7s 4ms/step - loss: 0.5871 - accuracy: 0.7418\n",
            "Epoch 6/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5871 - accuracy: 0.7405\n",
            "Epoch 7/30\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5872 - accuracy: 0.7419\n",
            "Epoch 8/30\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.5870 - accuracy: 0.7423\n",
            "Epoch 9/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5871 - accuracy: 0.7426\n",
            "Epoch 10/30\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5871 - accuracy: 0.7402\n",
            "Epoch 11/30\n",
            "2064/2064 [==============================] - 7s 3ms/step - loss: 0.5871 - accuracy: 0.7411\n",
            "Epoch 12/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5871 - accuracy: 0.7409\n",
            "Epoch 13/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5870 - accuracy: 0.7414\n",
            "Epoch 14/30\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5871 - accuracy: 0.7414\n",
            "Epoch 15/30\n",
            "2064/2064 [==============================] - 8s 4ms/step - loss: 0.5870 - accuracy: 0.7410\n",
            "Epoch 16/30\n",
            "2064/2064 [==============================] - 11s 5ms/step - loss: 0.5871 - accuracy: 0.7408\n",
            "Epoch 17/30\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5871 - accuracy: 0.7414\n",
            "Epoch 18/30\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5871 - accuracy: 0.7421\n",
            "Epoch 19/30\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5871 - accuracy: 0.7412\n",
            "Epoch 20/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5870 - accuracy: 0.7416\n",
            "Epoch 21/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5871 - accuracy: 0.7408\n",
            "Epoch 22/30\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.5870 - accuracy: 0.7402\n",
            "Epoch 23/30\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5871 - accuracy: 0.7432\n",
            "Epoch 24/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5870 - accuracy: 0.7418\n",
            "Epoch 25/30\n",
            "2064/2064 [==============================] - 7s 4ms/step - loss: 0.5870 - accuracy: 0.7400\n",
            "Epoch 26/30\n",
            "2064/2064 [==============================] - 8s 4ms/step - loss: 0.5871 - accuracy: 0.7404\n",
            "Epoch 27/30\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5872 - accuracy: 0.7416\n",
            "Epoch 28/30\n",
            "2064/2064 [==============================] - 10s 5ms/step - loss: 0.5871 - accuracy: 0.7409\n",
            "Epoch 29/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5870 - accuracy: 0.7410\n",
            "Epoch 30/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5871 - accuracy: 0.7415\n",
            "1032/1032 [==============================] - 2s 2ms/step - loss: 0.5858 - accuracy: 0.7435\n",
            "Epoch 1/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5855 - accuracy: 0.7412\n",
            "Epoch 2/30\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5856 - accuracy: 0.7401\n",
            "Epoch 3/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5855 - accuracy: 0.7415\n",
            "Epoch 4/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5855 - accuracy: 0.7403\n",
            "Epoch 5/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5855 - accuracy: 0.7412\n",
            "Epoch 6/30\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5854 - accuracy: 0.7399\n",
            "Epoch 7/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5856 - accuracy: 0.7412\n",
            "Epoch 8/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5854 - accuracy: 0.7417\n",
            "Epoch 9/30\n",
            "2064/2064 [==============================] - 7s 3ms/step - loss: 0.5855 - accuracy: 0.7408\n",
            "Epoch 10/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5855 - accuracy: 0.7402\n",
            "Epoch 11/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5855 - accuracy: 0.7422\n",
            "Epoch 12/30\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5855 - accuracy: 0.7395\n",
            "Epoch 13/30\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.5855 - accuracy: 0.7405\n",
            "Epoch 14/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5854 - accuracy: 0.7396\n",
            "Epoch 15/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5855 - accuracy: 0.7409\n",
            "Epoch 16/30\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5855 - accuracy: 0.7416\n",
            "Epoch 17/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5856 - accuracy: 0.7407\n",
            "Epoch 18/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5854 - accuracy: 0.7418\n",
            "Epoch 19/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5856 - accuracy: 0.7396\n",
            "Epoch 20/30\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5854 - accuracy: 0.7407\n",
            "Epoch 21/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5855 - accuracy: 0.7418\n",
            "Epoch 22/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5854 - accuracy: 0.7406\n",
            "Epoch 23/30\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.5854 - accuracy: 0.7407\n",
            "Epoch 24/30\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5854 - accuracy: 0.7394\n",
            "Epoch 25/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5855 - accuracy: 0.7409\n",
            "Epoch 26/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5855 - accuracy: 0.7403\n",
            "Epoch 27/30\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5855 - accuracy: 0.7409\n",
            "Epoch 28/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5854 - accuracy: 0.7409\n",
            "Epoch 29/30\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5853 - accuracy: 0.7407\n",
            "Epoch 30/30\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.5855 - accuracy: 0.7409\n",
            "1032/1032 [==============================] - 2s 2ms/step - loss: 0.5890 - accuracy: 0.7379\n",
            "Epoch 1/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5874 - accuracy: 0.7386\n",
            "Epoch 2/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7386\n",
            "Epoch 3/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.5872 - accuracy: 0.7394\n",
            "Epoch 4/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7387\n",
            "Epoch 5/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7403\n",
            "Epoch 6/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7403\n",
            "Epoch 7/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7393\n",
            "Epoch 8/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7384\n",
            "Epoch 9/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.5872 - accuracy: 0.7400\n",
            "Epoch 10/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7404\n",
            "688/688 [==============================] - 1s 2ms/step - loss: 0.5858 - accuracy: 0.7369\n",
            "Epoch 1/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5871 - accuracy: 0.7396\n",
            "Epoch 2/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5868 - accuracy: 0.7401\n",
            "Epoch 3/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5870 - accuracy: 0.7415\n",
            "Epoch 4/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.5868 - accuracy: 0.7418\n",
            "Epoch 5/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.5869 - accuracy: 0.7417\n",
            "Epoch 6/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5869 - accuracy: 0.7407\n",
            "Epoch 7/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5870 - accuracy: 0.7424\n",
            "Epoch 8/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5869 - accuracy: 0.7431\n",
            "Epoch 9/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.5869 - accuracy: 0.7427\n",
            "Epoch 10/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.5869 - accuracy: 0.7417\n",
            "688/688 [==============================] - 1s 2ms/step - loss: 0.5857 - accuracy: 0.7451\n",
            "Epoch 1/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5853 - accuracy: 0.7426\n",
            "Epoch 2/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5853 - accuracy: 0.7418\n",
            "Epoch 3/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5853 - accuracy: 0.7420\n",
            "Epoch 4/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.5853 - accuracy: 0.7417\n",
            "Epoch 5/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.5853 - accuracy: 0.7419\n",
            "Epoch 6/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5852 - accuracy: 0.7408\n",
            "Epoch 7/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.5854 - accuracy: 0.7411\n",
            "Epoch 8/10\n",
            "1376/1376 [==============================] - 5s 4ms/step - loss: 0.5852 - accuracy: 0.7415\n",
            "Epoch 9/10\n",
            "1376/1376 [==============================] - 4s 3ms/step - loss: 0.5853 - accuracy: 0.7423\n",
            "Epoch 10/10\n",
            "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5853 - accuracy: 0.7405\n",
            "688/688 [==============================] - 1s 2ms/step - loss: 0.5895 - accuracy: 0.7365\n",
            "Epoch 1/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5875 - accuracy: 0.7381\n",
            "Epoch 2/10\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5875 - accuracy: 0.7376\n",
            "Epoch 3/10\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5874 - accuracy: 0.7390\n",
            "Epoch 4/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5874 - accuracy: 0.7374\n",
            "Epoch 5/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5875 - accuracy: 0.7393\n",
            "Epoch 6/10\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5874 - accuracy: 0.7395\n",
            "Epoch 7/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5875 - accuracy: 0.7377\n",
            "Epoch 8/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5874 - accuracy: 0.7382\n",
            "Epoch 9/10\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5874 - accuracy: 0.7398\n",
            "Epoch 10/10\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.5875 - accuracy: 0.7389\n",
            "1032/1032 [==============================] - 2s 2ms/step - loss: 0.5863 - accuracy: 0.7343\n",
            "Epoch 1/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5873 - accuracy: 0.7399\n",
            "Epoch 2/10\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5870 - accuracy: 0.7396\n",
            "Epoch 3/10\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5872 - accuracy: 0.7410\n",
            "Epoch 4/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5871 - accuracy: 0.7409\n",
            "Epoch 5/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5871 - accuracy: 0.7417\n",
            "Epoch 6/10\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5871 - accuracy: 0.7404\n",
            "Epoch 7/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5872 - accuracy: 0.7419\n",
            "Epoch 8/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5870 - accuracy: 0.7421\n",
            "Epoch 9/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5871 - accuracy: 0.7424\n",
            "Epoch 10/10\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5871 - accuracy: 0.7401\n",
            "1032/1032 [==============================] - 3s 3ms/step - loss: 0.5857 - accuracy: 0.7438\n",
            "Epoch 1/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5855 - accuracy: 0.7413\n",
            "Epoch 2/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5855 - accuracy: 0.7400\n",
            "Epoch 3/10\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.5855 - accuracy: 0.7413\n",
            "Epoch 4/10\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5855 - accuracy: 0.7402\n",
            "Epoch 5/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5855 - accuracy: 0.7409\n",
            "Epoch 6/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5853 - accuracy: 0.7401\n",
            "Epoch 7/10\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5856 - accuracy: 0.7409\n",
            "Epoch 8/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5854 - accuracy: 0.7413\n",
            "Epoch 9/10\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5855 - accuracy: 0.7407\n",
            "Epoch 10/10\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5855 - accuracy: 0.7401\n",
            "1032/1032 [==============================] - 2s 2ms/step - loss: 0.5895 - accuracy: 0.7359\n",
            "Epoch 1/30\n",
            "3096/3096 [==============================] - 8s 3ms/step - loss: 0.5867 - accuracy: 0.7401\n",
            "Epoch 2/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5868 - accuracy: 0.7396\n",
            "Epoch 3/30\n",
            "3096/3096 [==============================] - 13s 4ms/step - loss: 0.5867 - accuracy: 0.7405\n",
            "Epoch 4/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5868 - accuracy: 0.7407\n",
            "Epoch 5/30\n",
            "3096/3096 [==============================] - 8s 3ms/step - loss: 0.5867 - accuracy: 0.7410\n",
            "Epoch 6/30\n",
            "3096/3096 [==============================] - 6s 2ms/step - loss: 0.5867 - accuracy: 0.7409\n",
            "Epoch 7/30\n",
            "3096/3096 [==============================] - 8s 3ms/step - loss: 0.5867 - accuracy: 0.7405\n",
            "Epoch 8/30\n",
            "3096/3096 [==============================] - 6s 2ms/step - loss: 0.5867 - accuracy: 0.7403\n",
            "Epoch 9/30\n",
            "3096/3096 [==============================] - 8s 2ms/step - loss: 0.5868 - accuracy: 0.7404\n",
            "Epoch 10/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5867 - accuracy: 0.7400\n",
            "Epoch 11/30\n",
            "3096/3096 [==============================] - 6s 2ms/step - loss: 0.5866 - accuracy: 0.7394\n",
            "Epoch 12/30\n",
            "3096/3096 [==============================] - 8s 3ms/step - loss: 0.5868 - accuracy: 0.7397\n",
            "Epoch 13/30\n",
            "3096/3096 [==============================] - 6s 2ms/step - loss: 0.5868 - accuracy: 0.7401\n",
            "Epoch 14/30\n",
            "3096/3096 [==============================] - 8s 3ms/step - loss: 0.5867 - accuracy: 0.7405\n",
            "Epoch 15/30\n",
            "3096/3096 [==============================] - 6s 2ms/step - loss: 0.5868 - accuracy: 0.7396\n",
            "Epoch 16/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5867 - accuracy: 0.7414\n",
            "Epoch 17/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5868 - accuracy: 0.7391\n",
            "Epoch 18/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5868 - accuracy: 0.7399\n",
            "Epoch 19/30\n",
            "3096/3096 [==============================] - 8s 3ms/step - loss: 0.5868 - accuracy: 0.7407\n",
            "Epoch 20/30\n",
            "3096/3096 [==============================] - 6s 2ms/step - loss: 0.5867 - accuracy: 0.7402\n",
            "Epoch 21/30\n",
            "3096/3096 [==============================] - 8s 3ms/step - loss: 0.5868 - accuracy: 0.7395\n",
            "Epoch 22/30\n",
            "3096/3096 [==============================] - 6s 2ms/step - loss: 0.5867 - accuracy: 0.7400\n",
            "Epoch 23/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5867 - accuracy: 0.7397\n",
            "Epoch 24/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5868 - accuracy: 0.7408\n",
            "Epoch 25/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5867 - accuracy: 0.7402\n",
            "Epoch 26/30\n",
            "3096/3096 [==============================] - 8s 3ms/step - loss: 0.5868 - accuracy: 0.7401\n",
            "Epoch 27/30\n",
            "3096/3096 [==============================] - 6s 2ms/step - loss: 0.5867 - accuracy: 0.7396\n",
            "Epoch 28/30\n",
            "3096/3096 [==============================] - 9s 3ms/step - loss: 0.5867 - accuracy: 0.7404\n",
            "Epoch 29/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5867 - accuracy: 0.7402\n",
            "Epoch 30/30\n",
            "3096/3096 [==============================] - 9s 3ms/step - loss: 0.5867 - accuracy: 0.7397\n",
            "Epoch 1/30\n",
            "3096/3096 [==============================] - 8s 2ms/step - loss: 0.5867 - accuracy: 0.7397\n",
            "Epoch 2/30\n",
            "3096/3096 [==============================] - 9s 3ms/step - loss: 0.5868 - accuracy: 0.7394\n",
            "Epoch 3/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5867 - accuracy: 0.7405\n",
            "Epoch 4/30\n",
            "3096/3096 [==============================] - 9s 3ms/step - loss: 0.5868 - accuracy: 0.7406\n",
            "Epoch 5/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5867 - accuracy: 0.7410\n",
            "Epoch 6/30\n",
            "3096/3096 [==============================] - 9s 3ms/step - loss: 0.5867 - accuracy: 0.7408\n",
            "Epoch 7/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5867 - accuracy: 0.7405\n",
            "Epoch 8/30\n",
            "3096/3096 [==============================] - 9s 3ms/step - loss: 0.5867 - accuracy: 0.7402\n",
            "Epoch 9/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5868 - accuracy: 0.7404\n",
            "Epoch 10/30\n",
            "3096/3096 [==============================] - 9s 3ms/step - loss: 0.5867 - accuracy: 0.7400\n",
            "Epoch 11/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5866 - accuracy: 0.7395\n",
            "Epoch 12/30\n",
            "3096/3096 [==============================] - 9s 3ms/step - loss: 0.5868 - accuracy: 0.7397\n",
            "Epoch 13/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5868 - accuracy: 0.7402\n",
            "Epoch 14/30\n",
            "3096/3096 [==============================] - 8s 3ms/step - loss: 0.5867 - accuracy: 0.7405\n",
            "Epoch 15/30\n",
            "3096/3096 [==============================] - 8s 2ms/step - loss: 0.5868 - accuracy: 0.7396\n",
            "Epoch 16/30\n",
            "3096/3096 [==============================] - 8s 3ms/step - loss: 0.5867 - accuracy: 0.7414\n",
            "Epoch 17/30\n",
            "3096/3096 [==============================] - 8s 2ms/step - loss: 0.5868 - accuracy: 0.7392\n",
            "Epoch 18/30\n",
            "3096/3096 [==============================] - 8s 2ms/step - loss: 0.5868 - accuracy: 0.7399\n",
            "Epoch 19/30\n",
            "3096/3096 [==============================] - 8s 3ms/step - loss: 0.5868 - accuracy: 0.7407\n",
            "Epoch 20/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5867 - accuracy: 0.7403\n",
            "Epoch 21/30\n",
            "3096/3096 [==============================] - 8s 3ms/step - loss: 0.5868 - accuracy: 0.7394\n",
            "Epoch 22/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5867 - accuracy: 0.7399\n",
            "Epoch 23/30\n",
            "3096/3096 [==============================] - 9s 3ms/step - loss: 0.5867 - accuracy: 0.7397\n",
            "Epoch 24/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5868 - accuracy: 0.7408\n",
            "Epoch 25/30\n",
            "3096/3096 [==============================] - 9s 3ms/step - loss: 0.5867 - accuracy: 0.7402\n",
            "Epoch 26/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5868 - accuracy: 0.7401\n",
            "Epoch 27/30\n",
            "3096/3096 [==============================] - 9s 3ms/step - loss: 0.5867 - accuracy: 0.7396\n",
            "Epoch 28/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5867 - accuracy: 0.7404\n",
            "Epoch 29/30\n",
            "3096/3096 [==============================] - 9s 3ms/step - loss: 0.5867 - accuracy: 0.7402\n",
            "Epoch 30/30\n",
            "3096/3096 [==============================] - 7s 2ms/step - loss: 0.5867 - accuracy: 0.7396\n",
            "830/830 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parametros utilizados"
      ],
      "metadata": {
        "id": "6YCMfiQUW1C3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64febcc-b2c0-49b7-836a-e789f0546cd6",
        "id": "WkO3mTDMW1C3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epochs': 30, 'batch_size': 25}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_architecture"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "996ca38c-24c1-4537-fc98-aa5686d2918e",
        "id": "TsBRp9EDW1C4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neurons': 128, 'ln_rate_parameter': 0.01, 'hidden_layers': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hacemos la matriz de confusion"
      ],
      "metadata": {
        "id": "UHMrpK3gcrmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_training = random_search_training.best_params_\n",
        "best_training\n",
        "# Entrenamos el modelo con el dataset completo\n",
        "best_model.fit(x_train_norm, y_train, epochs=best_training['epochs'], batch_size=best_training['batch_size'])\n",
        "\n",
        "# Obtenemos predicciones\n",
        "y_probs = best_model.predict(x_test_norm)\n",
        "y_predictions = (y_probs > 0.5).astype(int)  # Assuming binary classification\n",
        "\n",
        "y_pred = np.ravel(y_predictions)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "# {'epochs': 20, 'batch_size': 30}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgcwF5jWc3MQ",
        "outputId": "e47a04c6-f9af-4b62-c44c-23e5f635eb83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1734/1734 [==============================] - 5s 3ms/step - loss: 0.6267 - accuracy: 0.7344\n",
            "Epoch 2/10\n",
            "1734/1734 [==============================] - 5s 3ms/step - loss: 0.5780 - accuracy: 0.7412\n",
            "Epoch 3/10\n",
            "1734/1734 [==============================] - 5s 3ms/step - loss: 0.5512 - accuracy: 0.7453\n",
            "Epoch 4/10\n",
            "1734/1734 [==============================] - 5s 3ms/step - loss: 0.5339 - accuracy: 0.7493\n",
            "Epoch 5/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.5216 - accuracy: 0.7519\n",
            "Epoch 6/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.5124 - accuracy: 0.7535\n",
            "Epoch 7/10\n",
            "1734/1734 [==============================] - 5s 3ms/step - loss: 0.5051 - accuracy: 0.7551\n",
            "Epoch 8/10\n",
            "1734/1734 [==============================] - 4s 3ms/step - loss: 0.4993 - accuracy: 0.7563\n",
            "Epoch 9/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.4946 - accuracy: 0.7577\n",
            "Epoch 10/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.4906 - accuracy: 0.7591\n",
            "581/581 [==============================] - 1s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.81      0.77      9292\n",
            "           1       0.79      0.70      0.74      9281\n",
            "\n",
            "    accuracy                           0.76     18573\n",
            "   macro avg       0.76      0.76      0.76     18573\n",
            "weighted avg       0.76      0.76      0.76     18573\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creo la matriz de confusión\n",
        "tabla=confusion_matrix(y_test, y_pred)\n",
        "\n",
        "#Grafico la matriz de confusión\n",
        "sns.heatmap(tabla,cmap='GnBu',annot=True,fmt='g')\n",
        "plt.xlabel('Valores predichos')\n",
        "plt.ylabel('Valores reales')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "INl8eh0fdSAQ",
        "outputId": "f5377890-af81-401a-af08-bbf45c0efe0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(50.722222222222214, 0.5, 'Valores reales')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGwCAYAAACZ7H64AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABD90lEQVR4nO3deVxV5dr/8e8GZRAFFAWccJ4wNcVSSi2NRMXKk2maY+Lp2IMTmCkns7KOmJ0yzczSEk8nT2qpmeY84IRDKIaKYxSlgpoD4QAI+/eHP3fuHDbb9nIjft7Pa71e7rXuda9rreeUV9d932uZzGazWQAAAE7k4uwAAAAASEgAAIDTkZAAAACnIyEBAABOR0ICAACcjoQEAAA4HQkJAABwOhISAADgdCWcHYARPNuOc3YIQJF0ZvUwZ4cAFDkerj6GX8NRfy9dXDfWIf0URVRIAACA0xXLCgkAAEWKyeTsCIo8EhIAAIzmwoCELSQkAAAYjQqJTaRsAADA6aiQAABgNCokNpGQAABgNBMDErbwhAAAgNNRIQEAwGguDNnYQkICAIDRmENiE0M2AADA6aiQAABgNCa12kRCAgCA0RiysYmUDQAAOB0VEgAAjMYqG5tISAAAMBpzSGwiIQEAwGjMIbGJlA0AADgdFRIAAIzGkI1NJCQAABiNSa02kbIBAACno0ICAIDRmNRqEwkJAABGYw6JTTwhAADgdFRIAAAwGkM2NpGQAABgNFbZ2MSQDQAAcDoqJAAAGI1JrTaRkAAAYDTmkNhEQgIAgNFISGyihgQAAJyOhAQAAKO5uDhms0P16tVlMpmu26KioiRJly5dUlRUlPz8/FS6dGl17dpVmZmZVn2kp6crIiJCpUqVkr+/v0aOHKnLly9btVm/fr2aNWsmd3d31a5dW/Hx8bf3iG7rLAAAUHgmk2M2O+zYsUPHjx+3bKtWrZIkdevWTZIUHR2tb7/9VvPnz1dCQoKOHTump59+2nJ+fn6+IiIilJubqy1btmj27NmKj4/X2LFjLW3S0tIUERGhtm3bKjk5WcOHD9fAgQO1YsUK+x+R2Ww2231WEefZdpyzQwCKpDOrhzk7BKDI8XD1Mfwann1nO6Sfi//pd9vnDh8+XEuWLNGhQ4eUlZWlChUqaM6cOXrmmWckSfv371eDBg2UmJioli1batmyZercubOOHTumgIAASdL06dM1atQonTx5Um5ubho1apSWLl2qPXv2WK7To0cPnT17VsuXL7crPiokAAAYzUEVkpycHGVlZVltOTk5Ni+fm5ur//73vxowYIBMJpOSkpKUl5ensLAwS5v69esrKChIiYmJkqTExEQ1atTIkoxIUnh4uLKysrR3715Lm2v7uNrmah/2ICEBAMBoJheHbHFxcfLx8bHa4uLibF5+0aJFOnv2rPr37y9JysjIkJubm3x9fa3aBQQEKCMjw9Lm2mTk6vGrx27VJisrSxcvXrTrEbHsFwCAu0RsbKxiYmKs9rm7u9s879NPP1XHjh1VqVIlo0L7y0hIAAAwmoO+ZePu7l6oBORaP//8s1avXq0FCxZY9gUGBio3N1dnz561qpJkZmYqMDDQ0mb79u1WfV1dhXNtmz+vzMnMzJS3t7c8PT3tipMhGwAAjOaEVTZXzZo1S/7+/oqIiLDsCwkJUcmSJbVmzRrLvgMHDig9PV2hoaGSpNDQUKWkpOjEiROWNqtWrZK3t7eCg4Mtba7t42qbq33Yg4QEAIBiqqCgQLNmzVK/fv1UosQfgyI+Pj6KjIxUTEyM1q1bp6SkJD3//PMKDQ1Vy5YtJUnt27dXcHCw+vTpo927d2vFihUaM2aMoqKiLFWaQYMG6ccff9TLL7+s/fv3a9q0aZo3b56io6PtjpUhGwAAjOakj+utXr1a6enpGjBgwHXHJk2aJBcXF3Xt2lU5OTkKDw/XtGnTLMddXV21ZMkSvfjiiwoNDZWXl5f69eunceP+eLVGjRo1tHTpUkVHR2vy5MmqUqWKZs6cqfDwcLtj5T0kwD2E95AA17sj7yH5+1yH9HNxxrMO6acookICAIDRHDSptThjDgkAAHA6KiQAABjNSXNI7iYkJAAAGO02l+zeS0jZAACA01EhAQDAYCYqJDaRkAAAYDDyEdsYsgEAAE5HhQQAAIOZeA+JTSQkAAAYjHzENoZsAACA01EhAQDAYKyysY2EBAAAg5GP2EZCAgCAwaiQ2MYcEgAA4HRUSAAAMBgVEttISAAAMBj5iG0M2QAAAKejQgIAgMEYsrGNhAQAAIOZGI+wiUcEAACcjgoJAAAGY8jGNhISAAAMRj5iG0M2AADA6aiQAABgMBdKJDaRkAAAYDDmkNhGQgIAgMHIR2xjDgkAAHA6KiQAABiMIRvbSEgAADAY+YhtDNkAAACno0ICAIDBTC6USGwhIQEAwGAM2djGkA0AAHA6KiQAABiMVTa2kZAAAGAw8hHbGLIBAABOR4UEAACDMWRjGwkJAAAGIyGxjYQEAACD8RoS25hDAgAAnI4KCQAABuNNrbaRkAAAYDCmkNjGkA0AAHA6KiS4pf3/G6pqgb7X7Z++aIeiJy/Tikl91eb+6lbHZiz+XkMnfWe1r3d4Ew3t1lJ1qvop63yOFiTsU/TkZZIk95Ku+iAmQk3rVlT9ahW0LPGgur86z6hbAhwi6fudiv/sv0rdu18nT57SpCkT1S7sUcvxJsEP3vC86BFD1D+yjyRpaNQIHUg9qNOnz8jbu4xahD6o4SMGy9+/giQpJydHb70xQfv27lfajz+pzSMP6/2p/zb83uB4rLKxjYQEt9Rq0Ey5XjP2GVzDX9+920cL1u+z7Pt0SZLe/Gy95feFnDyrPoZ2a6lh3Vrqnx+v1vbUo/LyKGmV5Li6uuhizmVNW7BdXdo0MOxeAEe6eOGS6tWroy5PP6GYoaOuO74mwTop37QxUa+/+pbC2rez7HvgwRANfKG/ypcvrxMnTuq9dybrpeGj9Z85n0qS8vML5O7urud6P6vVq9Yae0MwFPmIbSQkuKVT5y5Y/X7puTo6cvS0Nu7+2bLv4qU8ZZ45f8PzfUt76LUBbdX1lS+1fmeaZf+eH09Y/nzhUp6GvX/lX96h91WVb2kPR94CYIhWbR5SqzYP3fR4+QrlrX6vX5ugBx4MUZWqlS37+vR7zvLnSpUrasDAfho+ZKTy8i6rZMkSKlXKU2NeGy1JSt61W79n/e7guwCKDhISFFrJEi7q8XhjTZm/1Wr/s2GN1OPxxso8na3vthxU3OcbdDHnsiTpseY15eJiUqXyZbQr/kWVKeWurXt/0ehpq/TrySxn3AZwx/126jdt3LBZb45/7aZtzp09p6VLlqtJ08YqWZJ/NRc3DNnY5tT/1Z86dUqfffaZEhMTlZGRIUkKDAzUQw89pP79+6tChQrODA9/8mSr+vIt7aH/Lk+27Ju7Zo/SM8/p+Knf1aiWv956IUx1q/qpx2vzJUk1KpaVi8mkl3u10ktTVygr+5Jei2yrJf/urQcipyvvcoGT7ga4cxZ/s1SlSnnpscfbXnds0rsf6Ms583Xp4iU1bnKfPvjoPSdECKORkNjmtFU2O3bsUN26dTVlyhT5+PioTZs2atOmjXx8fDRlyhTVr19f33//vc1+cnJylJWVZbWZCy7fgTu49/Tr1FQrth3W8d+yLfs+W7JTq3cc0d60E/py9R5Fxi3SU20aqEalspKurL13K+mqER8s1+odR7Q99aj6vblAtSuX0yNNazjrVoA7atGCb9Wpc7jc3d2vO9Z/QB/N/fpzTZ/5gVxcXTVm9Bsym81OiBJwLqdVSIYMGaJu3bpp+vTp12WOZrNZgwYN0pAhQ5SYmHjLfuLi4vTGG29Y7XOt9qhK1rj+v0Rw+4ICfNSuWQ31eO3Wq192pB6VJNWqXE5px84o47crY977fzppaXPq3AWdOndBVf29jQsYKCJ2fr9LP6X9rInv/uuGx8uW9VXZsr6qXr2aatasrvbtntAPu1PU5P7GdzhSGIkCiW1Oq5Ds3r1b0dHRNyxjmUwmRUdHKzk52WY/sbGxOnfunNVWolprAyK+t/XpcL9OnD2vZYmHbtmuSe1ASbIkIol7fpEk1Qn6Y4Jf2TIeKu9TSumZ5wyKFig6Fi5YrOCG9VWvfl2bbQsKrlRGcnPzbLTE3cbkYnLIVpw5LSEJDAzU9u3bb3p8+/btCggIsNmPu7u7vL29rTaTCxPCHMlkkvp2aKIvVvyg/II/Ssk1KpXV6D6t1bRuRQUF+CjiobqaOfopbdz9s2UVzeFfT+vbTfv178HhatmwioKrV9CM0V104JdTStj1k6Wv+tXKq3GtAJUt4ylvLw81rhWgxrVs//8fcJYL5y9of+pB7U89KEk6evSY9qce1PFjGZY22dnZWrlijf7W9anrzv9h9x7974t52p96UMeOHte2rTs0euQYVa1aRU3ub2Rpd+Twj9qfelDnzmXp9+zzVtfE3cNkcsxmr6NHj6p3797y8/OTp6enGjVqZDUdwmw2a+zYsapYsaI8PT0VFhamQ4es/8Pz9OnT6tWrl7y9veXr66vIyEhlZ2dbtfnhhx/UunVreXh4qGrVqpo4caLdsTrtb+6XXnpJL7zwgpKSkvTYY49Zko/MzEytWbNGM2bM0L//zQuAioJ2ITUVFOir2ct2We3Py8tXu5CaGty1hbw83fTriXNatHG/Jny+wapdZNwiTYwK14K4niooMGvT7p/11MtzdDn/jwmtiyY8Z/Vukm0z/yFJ8mw7zrgbA/6CvXtTNbD/i5bf/377fUnSk10iLKtpln+3SjKb1TEi/LrzPT09tGb1On009RNdvHhJ5Sv46eFWoZr43gC5ublZ2g0eFK1jx45bfj/btbckafe+m/8HHSBJZ86c0cMPP6y2bdtq2bJlqlChgg4dOqSyZcta2kycOFFTpkzR7NmzVaNGDb366qsKDw/Xvn375OFx5RUMvXr10vHjx7Vq1Srl5eXp+eef1wsvvKA5c+ZIkrKystS+fXuFhYVp+vTpSklJ0YABA+Tr66sXXnih0PGazE6cPTV37lxNmjRJSUlJys/PlyS5uroqJCREMTEx6t69+231y19iwI2dWT3M2SEARY6Hq4/h17h/coJD+kke9kih244ePVqbN2/Wxo0bb3jcbDarUqVKGjFihF566SVJ0rlz5xQQEKD4+Hj16NFDqampCg4O1o4dO9S8eXNJ0vLly9WpUyf9+uuvqlSpkj766CO98sorysjIsCTTo0eP1qJFi7R///5Cx+vUb9k8++yz2rp1qy5cuKCjR4/q6NGjunDhgrZu3XrbyQgAAEWNyWRyyHajlaU5OTk3vObixYvVvHlzdevWTf7+/mratKlmzJhhOZ6WlqaMjAyFhYVZ9vn4+KhFixaWBSWJiYny9fW1JCOSFBYWJhcXF23bts3Spk2bNlaVvfDwcB04cEBnzpwp9DMqEh/XK1mypCpWrKiKFSuqZMmSzg4HAIAiKS4uTj4+PlZbXFzcDdv++OOP+uijj1SnTh2tWLFCL774ooYOHarZs2dLkuX9X3+erxkQEGA5lpGRIX9/f6vjJUqUULly5aza3KiPa69RGMz+BADAYI5a9hsbG6uYmBirfTd6v40kFRQUqHnz5ho/frwkqWnTptqzZ4+mT5+ufv36OSYgByoSFRIAAIozRy37vdHK0pslJBUrVlRwcLDVvgYNGig9PV3SldWu0pXFJNfKzMy0HAsMDNSJEyesjl++fFmnT5+2anOjPq69RmGQkAAAUAw9/PDDOnDggNW+gwcPqlq1apKkGjVqKDAwUGvWrLEcz8rK0rZt2xQaGipJCg0N1dmzZ5WUlGRps3btWhUUFKhFixaWNhs2bFBe3h/vz1m1apXq1atntaLHFhISAAAM5qhJrfaIjo7W1q1bNX78eB0+fFhz5szRJ598oqioKEtMw4cP11tvvaXFixcrJSVFffv2VaVKldSlSxdJVyoqHTp00N///ndt375dmzdv1uDBg9WjRw9VqlRJkvTcc8/Jzc1NkZGR2rt3r+bOnavJkydfN7RkC3NIAAAwmDNeHf/AAw9o4cKFio2N1bhx41SjRg29//776tWrl6XNyy+/rPPnz+uFF17Q2bNn1apVKy1fvtzyDhJJ+uKLLzR48GA99thjcnFxUdeuXTVlyhTLcR8fH61cuVJRUVEKCQlR+fLlNXbsWLveQSI5+T0kRuE9JMCN8R4S4Hp34j0kD3y0ySH97HixlUP6KYqokAAAYDB7h1vuRSQkAAAYrLh/GM8RSEgAADAYBRLbWGUDAACcjgoJAAAGYw6JbSQkAAAYzIWExCaGbAAAgNNRIQEAwGAUSGwjIQEAwGAs+7WNIRsAAOB0VEgAADAYq2xsIyEBAMBg5CO2MWQDAACcjgoJAAAGY8jGNhISAAAMxiob20hIAAAwGAUS25hDAgAAnI4KCQAABmMOiW0kJAAAGIyExDaGbAAAgNNRIQEAwGAssrGNhAQAAIOx7Nc2hmwAAIDTUSEBAMBgTGq1jYQEAACDkY/YxpANAABwOiokAAAYjCEb20hIAAAwGKtsbCMhAQDAYBRIbGMOCQAAcDoqJAAAGIw5JLaRkAAAYDASEtv+8pBNVlaWFi1apNTUVEfEAwAA7kF2JyTdu3fX1KlTJUkXL15U8+bN1b17dzVu3Fhff/21wwMEAOBu52JyzFac2Z2QbNiwQa1bt5YkLVy4UGazWWfPntWUKVP01ltvOTxAAADudiaT2SFbcWZ3QnLu3DmVK1dOkrR8+XJ17dpVpUqVUkREhA4dOuTwAAEAQPFnd0JStWpVJSYm6vz581q+fLnat28vSTpz5ow8PDwcHiAAAHc7k8kxW3Fm9yqb4cOHq1evXipdurSCgoL06KOPSroylNOoUSNHxwcAwF3PpZgPtziC3QnJ//3f/+nBBx/UL7/8oscff1wuLleKLDVr1mQOCQAAN1DMixsOcVvvIWnevLkaN26stLQ01apVSyVKlFBERISjYwMAAPcIu+eQXLhwQZGRkSpVqpQaNmyo9PR0SdKQIUM0YcIEhwcIAMDdzsVkdshWnNmdkMTGxmr37t1av3691STWsLAwzZ0716HBAQBQHDCp1Ta7h2wWLVqkuXPnqmXLllavwm3YsKGOHDni0OAAAMC9we6E5OTJk/L3979u//nz53lXPwAAN8Bfj7bZPWTTvHlzLV261PL7ahIyc+ZMhYaGOi4yAACKCeaQ2GZ3hWT8+PHq2LGj9u3bp8uXL2vy5Mnat2+ftmzZooSEBCNiBAAAxZzdFZJWrVopOTlZly9fVqNGjbRy5Ur5+/srMTFRISEhRsQIAMBdzeSgrTi7rfeQ1KpVSzNmzHB0LAAAFEvFfbjFEQqVkGRlZRW6Q29v79sOBgAA3JsKlZD4+vraXEFjNptlMpmUn5/vkMAAACguWGVjW6ESknXr1hkdBwAAxZaJIRubCpWQPPLII0bHAQBAsWX3CpJ70G1NapWufNMmPT1dubm5VvsbN278l4MCAAD3FruTtpMnT6pz584qU6aMGjZsqKZNm1ptAADAmslkdshmj9dff10mk8lqq1+/vuX4pUuXFBUVJT8/P5UuXVpdu3ZVZmamVR/p6emKiIhQqVKl5O/vr5EjR+ry5ctWbdavX69mzZrJ3d1dtWvXVnx8/G09I7sTkuHDh+vs2bPatm2bPD09tXz5cs2ePVt16tTR4sWLbysIAACKMxeTYzZ7NWzYUMePH7dsmzZtshyLjo7Wt99+q/nz5yshIUHHjh3T008/bTmen5+viIgI5ebmasuWLZo9e7bi4+M1duxYS5u0tDRFRESobdu2Sk5O1vDhwzVw4ECtWLHC7ljtHrJZu3atvvnmGzVv3lwuLi6qVq2aHn/8cXl7eysuLk4RERF2BwEAAGzLyclRTk6O1T53d3e5u7vfsH2JEiUUGBh43f5z587p008/1Zw5c9SuXTtJ0qxZs9SgQQNt3bpVLVu21MqVK7Vv3z6tXr1aAQEBuv/++/Xmm29q1KhRev311+Xm5qbp06erRo0aevfddyVJDRo00KZNmzRp0iSFh4fbdW92V0jOnz9v+bhe2bJldfLkSUlSo0aNtHPnTnu7AwCg2HPUkE1cXJx8fHystri4uJte99ChQ6pUqZJq1qypXr16KT09XZKUlJSkvLw8hYWFWdrWr19fQUFBSkxMlCQlJiaqUaNGCggIsLQJDw9XVlaW9u7da2lzbR9X21ztwx52V0jq1aunAwcOqHr16mrSpIk+/vhjVa9eXdOnT1fFihXtDgAAgOLudoZbbiQ2NlYxMTFW+25WHWnRooXi4+NVr149HT9+XG+88YZat26tPXv2KCMjQ25ubvL19bU6JyAgQBkZGZKkjIwMq2Tk6vGrx27VJisrSxcvXpSnp2eh783uhGTYsGE6fvy4JOm1115Thw4d9MUXX8jNze22J7IAAADbbjU882cdO3a0/Llx48Zq0aKFqlWrpnnz5tmVKNwpdickvXv3tvw5JCREP//8s/bv36+goCCVL1/eocEBAFAcmOT8F6P5+vqqbt26Onz4sB5//HHl5ubq7NmzVlWSzMxMy5yTwMBAbd++3aqPq6twrm3z55U5mZmZ8vb2tjvpue13teTm5urAgQNyc3NTs2bNSEYAALgJk8kx21+RnZ2tI0eOqGLFigoJCVHJkiW1Zs0ay/EDBw4oPT1doaGhkqTQ0FClpKToxIkTljarVq2St7e3goODLW2u7eNqm6t92MPuhOTChQuKjIxUqVKl1LBhQ8sEmSFDhmjChAl2BwAAABzvpZdeUkJCgn766Sdt2bJFf/vb3+Tq6qqePXvKx8dHkZGRiomJ0bp165SUlKTnn39eoaGhatmypSSpffv2Cg4OVp8+fbR7926tWLFCY8aMUVRUlGXYaNCgQfrxxx/18ssva//+/Zo2bZrmzZun6Ohou+O1OyGJjY3V7t27tX79enl4eFj2h4WFae7cuXYHAABAcediMjtks8evv/6qnj17ql69eurevbv8/Py0detWVahQQZI0adIkde7cWV27dlWbNm0UGBioBQsWWM53dXXVkiVL5OrqqtDQUPXu3Vt9+/bVuHHjLG1q1KihpUuXatWqVWrSpIneffddzZw50+4lv5JkMpvNdt1htWrVNHfuXLVs2VJlypTR7t27VbNmTR0+fFjNmjVTVlaW3UE4mmfbcbYbAfegM6uHOTsEoMjxcPUx/BpDNm+33agQPnj4QYf0UxTZPan15MmTlveQXOv8+fMy8X1lAACuY291415k95BN8+bNtXTpUsvvq0nIzJkzb2sSCwAAgN0VkvHjx6tjx47at2+fLl++rMmTJ2vfvn3asmWLEhISjIgRAIC7GuMHttldIWnVqpV2796ty5cvq1GjRlq5cqX8/f2VmJiokJAQI2IEAOCuVhSW/RZ1dlVI8vLy9I9//EOvvvqqZsyYYVRMAADgHmNXhaRkyZL6+uuvjYoFAIBiyRnLfu82dg/ZdOnSRYsWLTIgFAAAiieGbGyze1JrnTp1NG7cOG3evFkhISHy8vKyOj506FCHBQcAAO4Ndickn376qXx9fZWUlKSkpCSrYyaTiYQEAIA/cSkCH9cr6uxOSNLS0oyIAwCAYqu4D7c4wm1/7RcAAMBR7K6QAAAA+5iK+QoZRyAhAQDAYC4M2dhEQgIAgMGokNjGHBIAAOB0dldIli9frtKlS6tVq1aSpA8//FAzZsxQcHCwPvzwQ5UtW9bhQdpr18Iuzg4BKJJqvrrZ2SEARc6x8Z0Mvwb/9W+b3c9o5MiRysrKkiSlpKRoxIgR6tSpk9LS0hQTE+PwAAEAuNuZTGaHbMXZbb2HJDg4WJL09ddfq3Pnzho/frx27typTp2MzzIBAEDxY3eFxM3NTRcuXJAkrV69Wu3bt5cklStXzlI5AQAAf3Bx0Fac2V0hadWqlWJiYvTwww9r+/btmjt3riTp4MGDqlKlisMDBADgblfch1scwe6Ea+rUqSpRooS++uorffTRR6pcubIkadmyZerQoYPDAwQAAMWf3RWSoKAgLVmy5Lr9kyZNckhAAAAUN7wXzbbbGpI6cuSIxowZo549e+rEiROSrlRI9u7d69DgAAAoDlxMZodsxZndCUlCQoIaNWqkbdu2acGCBcrOzpYk7d69W6+99prDAwQAAMWf3QnJ6NGj9dZbb2nVqlVyc3Oz7G/Xrp22bt3q0OAAACgOTA7aijO755CkpKRozpw51+339/fXqVOnHBIUAADFSXEfbnEEuyskvr6+On78+HX7d+3aZVlxAwAA/mAyOWYrzuxOSHr06KFRo0YpIyNDJpNJBQUF2rx5s1566SX17dvXiBgBAEAxZ3dCMn78eNWvX19Vq1ZVdna2goOD1aZNGz300EMaM2aMETECAHBXYw6JbXbNITGbzcrIyNCUKVM0duxYpaSkKDs7W02bNlWdOnWMihEAgLsac0hsszshqV27tvbu3as6deqoatWqRsUFAADuIXYN2bi4uKhOnTr67bffjIoHAIBihyEb2+yeQzJhwgSNHDlSe/bsMSIeAACKHd7Uapvd7yHp27evLly4oCZNmsjNzU2enp5Wx0+fPu2w4AAAwL3B7oTk/fffNyAMAACKr+I+3OIIdick/fr1MyIOAACKLVMxH25xBLsTEknKz8/XokWLlJqaKklq2LChnnzySbm6ujo0OAAAcG+wOyE5fPiwOnXqpKNHj6pevXqSpLi4OFWtWlVLly5VrVq1HB4kAAB3M7tXkNyD7H5GQ4cOVa1atfTLL79o586d2rlzp9LT01WjRg0NHTrUiBgBALirmUxmh2zFmd0VkoSEBG3dulXlypWz7PPz89OECRP08MMPOzQ4AACKAyokttn9jNzd3fX7779ftz87O1tubm4OCQoAANxb7E5IOnfurBdeeEHbtm2T2WyW2WzW1q1bNWjQID355JNGxAgAwF2NIRvb7E5IpkyZolq1aik0NFQeHh7y8PDQww8/rNq1a2vy5MlGxAgAwF3NxUFbcWb3HBJfX1998803OnTokPbv3y9JatCggWrXru3w4AAAwL3htt5DIkl16tRRnTp1HBkLAADFUnEfbnGEQiUkMTExhe7wvffeu+1gAAAojnh1vG2FSkh27dpVqM5MJh45AACwX6ESknXr1hkdBwAAxZYLQzY23fYcEgAAUDgMINh2WwnJ999/r3nz5ik9PV25ublWxxYsWOCQwAAAwL3D7mXNX375pR566CGlpqZq4cKFysvL0969e7V27Vr5+PgYESMAAHc1F5kdshVndick48eP16RJk/Ttt9/Kzc1NkydP1v79+9W9e3cFBQUZESMAAHc1k8kxW3Fmd0Jy5MgRRURESJLc3Nx0/vx5mUwmRUdH65NPPnF4gAAA3O1MDtr+igkTJshkMmn48OGWfZcuXVJUVJT8/PxUunRpde3aVZmZmVbnpaenKyIiQqVKlZK/v79Gjhypy5cvW7VZv369mjVrJnd3d9WuXVvx8fF2x2d3QlK2bFnLx/UqV66sPXv2SJLOnj2rCxcu2B0AAAAw1o4dO/Txxx+rcePGVvujo6P17bffav78+UpISNCxY8f09NNPW47n5+crIiJCubm52rJli2bPnq34+HiNHTvW0iYtLU0RERFq27atkpOTNXz4cA0cOFArVqywK0a7E5I2bdpo1apVkqRu3bpp2LBh+vvf/66ePXvqscces7c7AACKPReT2SHb7cjOzlavXr00Y8YMlS1b1rL/3Llz+vTTT/Xee++pXbt2CgkJ0axZs7RlyxZt3bpVkrRy5Urt27dP//3vf3X//ferY8eOevPNN/Xhhx9aFrVMnz5dNWrU0LvvvqsGDRpo8ODBeuaZZzRp0iT7nlFhG16thEydOlU9evSQJL3yyiuKiYlRZmamunbtqk8//dSuiwMAcC9w1JBNTk6OsrKyrLacnJxbXjsqKkoREREKCwuz2p+UlKS8vDyr/fXr11dQUJASExMlSYmJiWrUqJECAgIsbcLDw5WVlaW9e/da2vy57/DwcEsfhVXohKRx48Zq0aKFvv76a5UpU+bKyS4uGj16tBYvXqx3333XKvMCAACOFRcXJx8fH6stLi7upu2//PJL7dy584ZtMjIy5ObmJl9fX6v9AQEBysjIsLS5Nhm5evzqsVu1ycrK0sWLFwt9b4VOSBISEtSwYUONGDFCFStWVL9+/bRx48ZCXwgAgHuVo4ZsYmNjde7cOastNjb2htf85ZdfNGzYMH3xxRfy8PC4w3dsv0InJK1bt9Znn32m48eP64MPPtBPP/2kRx55RHXr1tXbb79tyZQAAIA1Rw3ZuLu7y9vb22pzd3e/4TWTkpJ04sQJNWvWTCVKlFCJEiWUkJCgKVOmqESJEgoICFBubq7Onj1rdV5mZqYCAwMlSYGBgdeturn621Ybb29veXp6FvoZ2T2p1cvLS88//7wSEhJ08OBBdevWTR9++KGCgoL05JNP2tsdAAAwwGOPPaaUlBQlJydbtubNm6tXr16WP5csWVJr1qyxnHPgwAGlp6crNDRUkhQaGqqUlBSdOHHC0mbVqlXy9vZWcHCwpc21fVxtc7WPwvpL37KpXbu2/vnPf6patWqKjY3V0qVL/0p3AAAUSyYnfFyvTJkyuu+++6z2eXl5yc/Pz7I/MjJSMTExKleunLy9vTVkyBCFhoaqZcuWkqT27dsrODhYffr00cSJE5WRkaExY8YoKirKUpkZNGiQpk6dqpdfflkDBgzQ2rVrNW/ePLtzgttOSDZs2KDPPvtMX3/9tVxcXNS9e3dFRkbebncAABRbdg9H3CGTJk2Si4uLunbtqpycHIWHh2vatGmW466urlqyZIlefPFFhYaGysvLS/369dO4ceMsbWrUqKGlS5cqOjpakydPVpUqVTRz5kyFh4fbFYvJbDYXOm07duyY4uPjFR8fr8OHD+uhhx5SZGSkunfvLi8vL7subKT9Z39wdghAkdRu4q/ODgEoco6N72T4Neb9+J1D+ule0/hYnaXQFZKOHTtq9erVKl++vPr27asBAwaoXr16RsYGAECxYCruH6JxgEInJCVLltRXX32lzp07y9XV1ciYAAAoVkhHbCt0QrJ48WIj4wAAoNiiQmJbUZ1nAwAA7iF/adkvAACwjfqIbSQkAAAYzERKYhNDNgAAwOmokAAAYDDmtNpGQgIAgMFcGLKxiSEbAADgdFRIAAAwGEM2tpGQAABgMFbZ2MaQDQAAcDoqJAAAGIwhG9tISAAAMBhDNraRkAAAYDAqJLYxhwQAADgdFRIAAAzGkI1tJCQAABiM4QjbeEYAAMDpqJAAAGAwE7NabSIhAQDAYKQjtjFkAwAAnI4KCQAABmPIxjYSEgAADEY6YhtDNgAAwOmokAAAYDCGbGwjIQEAwGCkI7aRkAAAYDBeHW8bc0gAAIDTUSEBAMBgLhRIbCIhAQDAYAzZ2MaQDQAAcDoqJAAAGIxVv7aRkAAAYDCGbGxjyAYAADgdFRIAAAzGkI1tJCQAABiMIRvbGLIBAABOR4UEt/RV/EIlrt+mX38+Knd3N9VvVE99B/dSlWqVJUmZx07ohb9F3fDcl8fH6OHHQiVJu3ek6IuPv9TPR9Ll4eGudhGPqvegnnIt4SpJSknaq8X/W6JD+w7rwvmLqlQ1UF16P6VHO7S+MzcK2CnQ212vhNdX23oV5FnSVT/9dkHRX/+gH46eu67thKfuU98WQRq7ZJ9mbvnJsr+mn5de7VhfD1Qrq5KuJqVm/K6Jqw9qy4+nLW1a1fLTy2F1VT+wjC7k5mv+zl81YdVB5ReY78RtwkEYsrGNhAS3tGfXXnV6Jlx1gmsr/3K+Pv9ojl4f+pamfjlJHp4eKh/gp/jvPrE6Z8XC1Vr4xWI1C71fkpR28CeNix6vbv2fVvRrg/XbydP66O0ZKsgv0PPD+kqS9qccUPXa1fR03y7yLeej7zclafIbH8irdCk90CrkTt82cEs+HiX0zT9CteXH0+odv0O/nc9VTT8vnbuYd13bDsEBCqnqq+PnLl13bHa/5ko7dV7dPt2mS3n5+vvDNfSfvs0V+u/1Opmdq+DAMvq8X3NNWX9EQ+fvVqCPh95+6j65upg0btn+O3GrcBCGbGwjIcEtvT55jNXvYWOj1LfDQB3Z/6MaNg2Wq6uryvqVtWqzNWG7Wj0WKs9SnpKkTau3qHrtauoxsJskqWLViuo3uLfeeeU9PTuwm0p5eapb/6et+niiR4R2bdutxHXbSEhQ5EQ9UkvHzl1S9Nc/WPb9cubide0Cvd311hPBem7WDn3er7nVsXKlSqpWeS+NWPCDUjN+lyT9a/l+9W9ZTfUDyuhk9m96snFFpWb8rklrD0uSfjp9QW8t36/pPZvq3TWHdD4338C7hCMxP8I2nhHsciH7giSptHfpGx4/nHpEaQd/UtiTj1n25eXlyc2tpFU7N3c35ebk6cj+H295rTI3uQ7gTO0b+Gv3r+f0cc+m+uGfj2nl4If1XPOqVm1MJmlKtyb6aGOaDp7Ivq6P0xfydPhktro1rSzPkq5ydTGpz4NBOpmdYxn2cXN1Uc7lAqvzLuXly7OkqxpX9jHuBgEnuOsTkpycHGVlZVltuTm5zg6rWCooKNDMSfFq0LieqtUKumGb1d+uVZXqldWgcT3LvqYt7tf+lAPasGKT8vPz9duJ3zT3068kSWdOnblhP5tWb9Gh1CN67Im2jr8R4C8KKltKfVsEKe2383pu1g7N3pauN58IVremlS1totrUUn6BWZ9eM2fkz579dLvuq+ijQ6+1V9ob4XqhVQ31mrVD5y5dliQlHDql5kFl1aVxRbmYrlRcotvVkSQFlHE39B7hWCaTySFbcVakE5JffvlFAwYMuGWbuLg4+fj4WG2fTPr0DkV4b/n4nZlK//EXvfRW9A2P51zK0YYVm/T4NdURSWrason6D+mjj97+RM+0fk4vdhumkIeaSpJMN/gE5g/f79GUN6cp6p+DFFSz6nXHAWdzMZm051iWJqw8qD3Hs/TFjl80Z8cv6tPiSqLeqJK3Bj5UXcO/+uGW/Yx/sqFOnc/R3z7ZqoiPtmj5vkzF9w2R//9PNhIOn9Kby/ZrQpf79NO4DtoU84jWHjghSWJO693G5KCt+CrSc0hOnz6t2bNn67PPPrtpm9jYWMXExFjt++niQaNDu+d8/M5M7di0U3Efv6HyAX43bLNl7VblXMpR205trjv21HNP6MmenXX61BmVLuOlE8dP6vNpcxRYOcCq3Z6de/WvlyYocng/tev0iCH3AvxVJ37PuW4Y5tDJbHVqGChJalG9nMp7uWnHy39U+Eq4uui1Tg3094erq8U769Wqlp/C6vurwZurlJ1zpSKSsniv2tQur+5NK2vqhivDmZ9sTtMnm9MUUMZd5y7mqUpZT/2zQ339fPrCHbpb4M5wakKyePHiWx7/8cebzy+4yt3dXe7u1qVLtwK3vxQX/mA2m/XJvz/V1oTt+te0NxRQKeCmbVd/u1YPtG4un7I3Hts2mUzyq1BOkrRh5SaVD/BTzXo1LMdTkvbqrRFx6hvVW+F/e9yxNwI40I70M6pVwctqX00/Lx09e2Vi69e7jmrjkVNWx+f0f1BfJx/V3KRfJUmeJa8seS8wW5c6zGbzDUvzmb/nSJL+1qSSjp69qJRj1y8vRtFVvGsbjuHUhKRLly4ymUwym29eeyzuY2ZF3cfvzNSGFZv0z3delqeXh878dmXORymvUnL3+CMRPP7Lce3dlaqxk2Jv2M+Cz79Rs9D75eLiosR127TgP4s0cnyMXF2v/Ev5h+/36K0RE/TEs530ULsWluuUKFFCZXzKGHyXgH0+2ZSmxYNCNeSRWvo25biaVvVV7werauTCPZKkMxfzdOZPS4AvFxToxO85OnLqvCQpKf2Mzl3M0+RnmmjS2kO6lFegXg9UVdWypbTm/w/LSNKLrWto3cFTKjCb1alhoKLa1NKg/+1iyOYuw99ltjk1IalYsaKmTZump5566obHk5OTFRLCkk9nWvb1SknSKy++brV/6Kv/p8c6/1GOXv3tOvn5l9P9LZrcsJ+dibv0VfwC5eXlqXrt6vrnO6Ms80gkad1365VzKUdfzV6or2YvtOy/r1mw/vXRGw68I+Cv2330nCL/u1Ox4fUU3a62fjlzUWOXpGrh7mOF7uP0hTw9F79Dox+vq3kDW6iki0kHTmTr+f8mad//XwYsSW3rVtDQR2vLrYSL9h3P0vP/TdK6gyeNuC3AqUzmW5UnDPbkk0/q/vvv17hx4254fPfu3WratKkKCgpuePxm9p+99UQy4F7VbuKvzg4BKHKOje9k+DV2/bbNIf009WvhkH6KIqdWSEaOHKnz58/f9Hjt2rW1bt26OxgRAACOx4CNbU5NSFq3vvV3Sry8vPTII6y0AACguCvSy34BACgO+JaNbUX6xWgAABQLJpNjNjt89NFHaty4sby9veXt7a3Q0FAtW7bMcvzSpUuKioqSn5+fSpcura5duyozM9Oqj/T0dEVERKhUqVLy9/fXyJEjdfnyZas269evV7NmzeTu7q7atWsrPj7+th4RCQkAAAZzxntaq1SpogkTJigpKUnff/+92rVrp6eeekp79+6VJEVHR+vbb7/V/PnzlZCQoGPHjunpp//40Gl+fr4iIiKUm5urLVu2aPbs2YqPj9fYsWMtbdLS0hQREaG2bdsqOTlZw4cP18CBA7VixQr7n5EzV9kYhVU2wI2xyga43p1YZfPD6R0O6aeeV2Pl5ORY7bvRC0Jvply5cnrnnXf0zDPPqEKFCpozZ46eeeYZSdL+/fvVoEEDJSYmqmXLllq2bJk6d+6sY8eOKSDgyksxp0+frlGjRunkyZNyc3PTqFGjtHTpUu3Zs8dyjR49eujs2bNavny5XfdGhQQAAMM5pkZyo++3xcXF2bx6fn6+vvzyS50/f16hoaFKSkpSXl6ewsLCLG3q16+voKAgJSYmSpISExPVqFEjSzIiSeHh4crKyrJUWRITE636uNrmah/2YFIrAAAGc9Sk1ht9v+1W1ZGUlBSFhobq0qVLKl26tBYuXKjg4GAlJyfLzc1Nvr6+Vu0DAgKUkZEhScrIyLBKRq4ev3rsVm2ysrJ08eJFeXp6FvreSEgAALhL2DM8I0n16tVTcnKyzp07p6+++kr9+vVTQkKCgRHePhISAAAM5qxP2bi5ual27dqSpJCQEO3YsUOTJ0/Ws88+q9zcXJ09e9aqSpKZmanAwCtfrQ4MDNT27dut+ru6CufaNn9emZOZmSlvb2+7qiMSc0gAALgDnLHO5noFBQXKyclRSEiISpYsqTVr1liOHThwQOnp6QoNDZUkhYaGKiUlRSdO/PGxx1WrVsnb21vBwcGWNtf2cbXN1T7sQYUEAIBiKDY2Vh07dlRQUJB+//13zZkzR+vXr9eKFSvk4+OjyMhIxcTEqFy5cvL29taQIUMUGhqqli1bSpLat2+v4OBg9enTRxMnTlRGRobGjBmjqKgoy7DRoEGDNHXqVL388ssaMGCA1q5dq3nz5mnp0qV2x0tCAgCAwZzxptYTJ06ob9++On78uHx8fNS4cWOtWLFCjz/+uCRp0qRJcnFxUdeuXZWTk6Pw8HBNmzbNcr6rq6uWLFmiF198UaGhofLy8lK/fv2sPohbo0YNLV26VNHR0Zo8ebKqVKmimTNnKjw83O54eQ8JcA/hPSTA9e7Ee0j2ndnlkH6CyzZ1SD9FEXNIAACA0zFkAwCA0Zy1zOYuQkICAIDB+NqvbSQkAAAYjITENuaQAAAApyMhAQAATseQDQAABjMxqdUmKiQAAMDpqJAAAGA4KiS2kJAAAGAw0hHbGLIBAABOR4UEAACD8R4S20hIAAAwGqtsbGLIBgAAOB0VEgAADEZ9xDYSEgAADMYcEttISAAAMBwJiS3MIQEAAE5HhQQAAIOxyMY2EhIAAAxHRmILQzYAAMDpqJAAAGAwVtnYRkICAIDBSEhsY8gGAAA4HRUSAACMRoHEJhISAAAMxpCNbQzZAAAAp6NCAgCAwaiQ2EZCAgCA0chHbCIhAQDAYFRIbGMOCQAAcDoqJAAAGIwKiW0kJAAAGIx0xDaGbAAAgNNRIQEAwGgmaiS2kJAAAGAw5pDYxpANAABwOiokAAAYjPqIbSQkAAAYjTkkNjFkAwAAnI4KCQAABmNSq20kJAAAGIx0xDYSEgAADEaFxDbmkAAAAKejQgIAgNEokNhEQgIAgMEYsrGNIRsAAOB0VEgAADAYFRLbqJAAAACnIyEBAABOx5ANAAAGM/EtG5tISAAAMBhzSGxjyAYAgGIoLi5ODzzwgMqUKSN/f3916dJFBw4csGpz6dIlRUVFyc/PT6VLl1bXrl2VmZlp1SY9PV0REREqVaqU/P39NXLkSF2+fNmqzfr169WsWTO5u7urdu3aio+PtzteEhIAAAxmctBmj4SEBEVFRWnr1q1atWqV8vLy1L59e50/f97SJjo6Wt9++63mz5+vhIQEHTt2TE8//bTleH5+viIiIpSbm6stW7Zo9uzZio+P19ixYy1t0tLSFBERobZt2yo5OVnDhw/XwIEDtWLFCvuekdlsNtt5j0Xe/rM/ODsEoEhqN/FXZ4cAFDnHxncy/BpncjNtNyqEsm4Bt33uyZMn5e/vr4SEBLVp00bnzp1ThQoVNGfOHD3zzDOSpP3796tBgwZKTExUy5YttWzZMnXu3FnHjh1TQMCVa0+fPl2jRo3SyZMn5ebmplGjRmnp0qXas2eP5Vo9evTQ2bNntXz58kLHR4UEAACDmRz0fzk5OcrKyrLacnJyChXDuXPnJEnlypWTJCUlJSkvL09hYWGWNvXr11dQUJASExMlSYmJiWrUqJElGZGk8PBwZWVlae/evZY21/Zxtc3VPgqLhAQAgLtEXFycfHx8rLa4uDib5xUUFGj48OF6+OGHdd9990mSMjIy5ObmJl9fX6u2AQEBysjIsLS5Nhm5evzqsVu1ycrK0sWLFwt9b6yyAQDAYI5aYxMbG6uYmBirfe7u7jbPi4qK0p49e7Rp0yYHReJ4JCQAABjMUct+3d3dC5WAXGvw4MFasmSJNmzYoCpVqlj2BwYGKjc3V2fPnrWqkmRmZiowMNDSZvv27Vb9XV2Fc22bP6/MyczMlLe3tzw9PQsdJ0M2AAAUQ2azWYMHD9bChQu1du1a1ahRw+p4SEiISpYsqTVr1lj2HThwQOnp6QoNDZUkhYaGKiUlRSdOnLC0WbVqlby9vRUcHGxpc20fV9tc7aOwqJAAAGA0J7ypNSoqSnPmzNE333yjMmXKWOZ8+Pj4yNPTUz4+PoqMjFRMTIzKlSsnb29vDRkyRKGhoWrZsqUkqX379goODlafPn00ceJEZWRkaMyYMYqKirJUagYNGqSpU6fq5Zdf1oABA7R27VrNmzdPS5cutStelv0C9xCW/QLXuxPLfn/PO+WQfsqULF/otjd7Xf2sWbPUv39/SVdejDZixAj973//U05OjsLDwzVt2jTLcIwk/fzzz3rxxRe1fv16eXl5qV+/fpowYYJKlPijprF+/XpFR0dr3759qlKlil599VXLNQodLwkJcO8gIQGuV1wTkrsNQzYAABiMb9nYRkICAIDR+NqvTayyAQAATkeFBAAAg1EfsY2EBAAAgzGHxDYSEgAADEZCYhtzSAAAgNNRIQEAwGgUSGwiIQEAwGAM2djGkA0AAHC6YvnqeBQNOTk5iouLU2xsrN2fywaKM/7ZAK5HQgLDZGVlycfHR+fOnZO3t7ezwwGKDP7ZAK7HkA0AAHA6EhIAAOB0JCQAAMDpSEhgGHd3d7322mtM2gP+hH82gOsxqRUAADgdFRIAAOB0JCQAAMDpSEgAAIDTkZAAAACnIyGBYT788ENVr15dHh4eatGihbZv3+7skACn2rBhg5544glVqlRJJpNJixYtcnZIQJFBQgJDzJ07VzExMXrttde0c+dONWnSROHh4Tpx4oSzQwOc5vz582rSpIk+/PBDZ4cCFDks+4UhWrRooQceeEBTp06VJBUUFKhq1aoaMmSIRo8e7eToAOczmUxauHChunTp4uxQgCKBCgkcLjc3V0lJSQoLC7Psc3FxUVhYmBITE50YGQCgqCIhgcOdOnVK+fn5CggIsNofEBCgjIwMJ0UFACjKSEgAAIDTkZDA4cqXLy9XV1dlZmZa7c/MzFRgYKCTogIAFGUkJHA4Nzc3hYSEaM2aNZZ9BQUFWrNmjUJDQ50YGQCgqCrh7ABQPMXExKhfv35q3ry5HnzwQb3//vs6f/68nn/+eWeHBjhNdna2Dh8+bPmdlpam5ORklStXTkFBQU6MDHA+lv3CMFOnTtU777yjjIwM3X///ZoyZYpatGjh7LAAp1m/fr3atm173f5+/fopPj7+zgcEFCEkJAAAwOmYQwIAAJyOhAQAADgdCQkAAHA6EhIAAOB0JCQAAMDpSEgAAIDTkZAAAACnIyEBAABOR0IC/AWPPvqohg8f7uwwnM5kMmnRokWSpJ9++kkmk0nJycmFOrd///7q0qWLYbEBuDuQkOCe9MQTT6hDhw43PLZx40aZTCb98MMPdziq4qFq1ao6fvy47rvvPmeHAuAuQkKCe1JkZKRWrVqlX3/99bpjs2bNUvPmzdW4cWPD48jPz1dBQYHh1ymMvLw8h/Tj6uqqwMBAlSjBtzsBFB4JCe5JnTt3VoUKFa77oFl2drbmz5+vyMhI/fbbb+rZs6cqV66sUqVKqVGjRvrf//53y37PnDmjvn37qmzZsipVqpQ6duyoQ4cOWY7Hx8fL19dXixcvVnBwsNzd3ZWenq6cnBy99NJLqly5sry8vNSiRQutX7/ect7PP/+sJ554QmXLlpWXl5caNmyo77777qZxVK9eXW+++aZ69uwpLy8vVa5cWR9++KFVG5PJpI8++khPPvmkvLy89K9//UuS9M0336hZs2by8PBQzZo19cYbb+jy5cuW8w4dOqQ2bdrIw8NDwcHBWrVqlVW/Nxqy2bt3rzp37ixvb2+VKVNGrVu31pEjR6zO+/e//62KFSvKz89PUVFRVgmSredq7/MBUPSQkOCeVKJECfXt21fx8fG69vuS8+fPV35+vnr27KlLly4pJCRES5cu1Z49e/TCCy+oT58+2r59+0377d+/v77//nstXrxYiYmJMpvN6tSpk9VfrhcuXNDbb7+tmTNnau/evfL399fgwYOVmJioL7/8Uj/88IO6deumDh06WP7SjYqKUk5OjjZs2KCUlBS9/fbbKl269C3v8Z133lGTJk20a9cujR49WsOGDbsueXj99df1t7/9TSkpKRowYIA2btyovn37atiwYdq3b58+/vhjxcfHW5KVgoICPf3003Jzc9O2bds0ffp0jRo16pZxHD16VG3atJG7u7vWrl2rpKQkDRgwwCrJWbdunY4cOaJ169Zp9uzZio+Pt0oWbT3X23k+AIoYM3CPSk1NNUsyr1u3zrKvdevW5t69e9/0nIiICPOIESMsvx955BHzsGHDzGaz2Xzw4EGzJPPmzZstx0+dOmX29PQ0z5s3z2w2m82zZs0ySzInJydb2vz8889mV1dX89GjR62u9dhjj5ljY2PNZrPZ3KhRI/Prr79e6HurVq2auUOHDlb7nn32WXPHjh0tvyWZhw8fft01x48fb7Xv888/N1esWNFsNpvNK1asMJcoUcIq1mXLlpklmRcuXGg2m83mtLQ0syTzrl27zGaz2RwbG2uuUaOGOTc394ax9uvXz1ytWjXz5cuXLfu6detmfvbZZ81mc+Geq73PB0DRwyAv7ln169fXQw89pM8++0yPPvqoDh8+rI0bN2rcuHGSrszvGD9+vObNm6ejR48qNzdXOTk5KlWq1A37S01NVYkSJdSiRQvLPj8/P9WrV0+pqamWfW5ublbzU1JSUpSfn6+6deta9ZeTkyM/Pz9J0tChQ/Xiiy9q5cqVCgsLU9euXW3OcQkNDb3u9/vvv2+1r3nz5la/d+/erc2bN1sqIlefw6VLl3ThwgWlpqaqatWqqlSp0k2v82fJyclq3bq1SpYsedM2DRs2lKurq+V3xYoVlZKSIqlwz/V2ng+AooUhG9zTIiMj9fXXX+v333/XrFmzVKtWLT3yyCOSrgx5TJ48WaNGjdK6deuUnJys8PBw5ebm/qVrenp6ymQyWX5nZ2fL1dVVSUlJSk5OtmypqamaPHmyJGngwIH68ccf1adPH6WkpKh58+b64IMP/lIckuTl5WX1Ozs7W2+88YZVHCkpKTp06JA8PDxu6xqenp422/w5WTGZTHZN9jXq+QC4c0hIcE/r3r27XFxcNGfOHP3nP//RgAEDLMnC5s2b9dRTT6l3795q0qSJatasqYMHD960rwYNGujy5cvatm2bZd9vv/2mAwcOKDg4+KbnNW3aVPn5+Tpx4oRq165ttQUGBlraVa1aVYMGDdKCBQs0YsQIzZgx45b3tnXr1ut+N2jQ4JbnNGvWTAcOHLgujtq1a8vFxUUNGjTQL7/8ouPHj9/0On/WuHFjbdy48bZX8RT2udr7fAAULSQkuKeVLl1azz77rGJjY3X8+HH179/fcqxOnTpatWqVtmzZotTUVP3jH/9QZmbmTfuqU6eOnnrqKf3973/Xpk2btHv3bvXu3VuVK1fWU089ddPz6tatq169eqlv375asGCB0tLStH37dsXFxWnp0qWSpOHDh2vFihVKS0vTzp07tW7dOpvJxebNmzVx4kQdPHhQH374oebPn69hw4bd8pyxY8fqP//5j9544w3t3btXqamp+vLLLzVmzBhJUlhYmOrWrat+/fpp9+7d2rhxo1555ZVb9jl48GBlZWWpR48e+v7773Xo0CF9/vnnOnDgwC3Pu6owz/V2ng+AooWEBPe8yMhInTlzRuHh4VZzI8aMGaNmzZopPDxcjz76qAIDA22+UXTWrFkKCQlR586dFRoaKrPZrO++++6W8yeunte3b1+NGDFC9erVU5cuXbRjxw4FBQVJujKPIyoqSg0aNFCHDh1Ut25dTZs27ZZ9jhgxQt9//72aNm2qt956S++9957Cw8NveU54eLiWLFmilStX6oEHHlDLli01adIkVatWTZLk4uKihQsX6uLFi3rwwQc1cOBAq/kmN+Ln56e1a9cqOztbjzzyiEJCQjRjxgybz+TPz+dWz/V2ng+AosVkNl+z5hFAsVC9enUNHz6c19oDuGtQIQEAAE5HQgIAAJyOIRsAAOB0VEgAAIDTkZAAAACnIyEBAABOR0ICAACcjoQEAAA4HQkJAABwOhISAADgdCQkAADA6f4fDxRmrVIE0RAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Entrenamos el modelo con el dataset completo\n",
        "# best_model.fit(x_train_norm, y_train, epochs=best_training['epochs'], batch_size=best_training['batch_size'])\n",
        "\n",
        "# # Obtenemos predicciones\n",
        "# y_probs = best_model.predict(x_test_norm)\n",
        "# y_predictions = (y_probs > 0.5).astype(int)  # Assuming binary classification\n",
        "\n",
        "# y_pred = np.ravel(y_predictions)\n",
        "\n",
        "# print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "Y0Ik597sca30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arquitectura 4"
      ],
      "metadata": {
        "id": "E2mvHKRodfa_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimización de los hiperparámetros de la arquitectura 4"
      ],
      "metadata": {
        "id": "3StlrnZmHRr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from scipy.stats import randint\n",
        "from keras.regularizers import l2\n",
        "\n",
        "'''\n",
        "-Tiene 2 hiperparámetros para optimizar: cant neuronas y de capas ocultas\n",
        "-Utiliza el optimizador rmsprop\n",
        "-Utiliza el regulador L2 con un learning_rate=0.01 en la capa de entrada\n",
        "-Las capas ocultas utilizan el regulador L2 y Dropout\n",
        "'''\n",
        "def create_model_4(hidden_layers=1, neurons=64):\n",
        "    optimizer = 'rmsprop'  # Optimizador fijo para esta arquitectura\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(neurons, input_shape=(ds_train_norm.shape[1],), activation='relu', kernel_regularizer=l2(0.01)))\n",
        "    for _ in range(hidden_layers - 1):\n",
        "        model.add(keras.layers.Dense(neurons, activation='relu', kernel_regularizer=l2(0.01))) #Añado regulizador L2 por cada capa\n",
        "        model.add(Dropout(0.2))  # Añado técnica de regularización \"DropOut\" por cada capa oculta\n",
        "\n",
        "    model.add(keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01)))\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "# Optimizamos hiperparáemtros de arquitectura\n",
        "model = KerasClassifier(build_fn=create_model_4,callbacks=[early_stopping])\n",
        "param_dist_architecture = {\n",
        "    'neurons': [16, 32, 64, 128],\n",
        "    'hidden_layers': [1, 2, 3],\n",
        "}\n",
        "\n",
        "random_search_architecture = RandomizedSearchCV(estimator=model,\n",
        "                                                param_distributions=param_dist_architecture,\n",
        "                                                n_iter=5, cv=5)\n",
        "random_search_architecture.fit(ds_train_norm, ds_hoteles_train_y)\n",
        "\n",
        "# Obtenemos los mejores\n",
        "best_architecture = random_search_architecture.best_params_\n",
        "\n",
        "# Creamos un modelo con esos hiperparámetros\n",
        "best_model = create_model_4(neurons=best_architecture['neurons'], hidden_layers=best_architecture['hidden_layers'])\n",
        "\n",
        "# Optimizamos hiperparámetros de entrenamiento\n",
        "param_dist_training = {\n",
        "    'epochs': [10, 20, 30],\n",
        "    'batch_size': [20, 25, 30]\n",
        "}\n",
        "\n",
        "random_search_training = RandomizedSearchCV(estimator=KerasClassifier(build_fn=lambda: best_model), param_distributions=param_dist_training, n_iter=3, cv=4)\n",
        "random_search_training.fit(ds_train_norm, ds_hoteles_train_y)\n",
        "\n",
        "# Obtenemos los mejores\n",
        "best_training = random_search_training.best_params_\n",
        "\n",
        "# Entrenamos con el dataset completo\n",
        "best_model.fit(ds_train_norm, ds_hoteles_train_y, epochs=best_training['epochs'], batch_size=best_training['batch_size'])\n",
        "\n",
        "# Hacemos predicciones con test\n",
        "y_probs = best_model.predict(ds_test_norm)\n",
        "y_predictions = (y_probs > 0.5).astype(int)  # Assuming binary classification\n",
        "\n",
        "y_pred = np.ravel(y_predictions)\n",
        "\n",
        "# Realizamos subbmit en Kaggle\n",
        "df_submission = pd.DataFrame({'id': ds_hoteles_test['id'], 'is_canceled': y_pred})\n",
        "df_submission.to_csv('Submission_red_neuronal_model4_optimized.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bd3ad60-50ed-46ea-8425-5c0272f8f5bb",
        "id": "LyZ_pZKvHRsA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.6252 - accuracy: 0.7137\n",
            "387/387 [==============================] - 1s 2ms/step - loss: 0.5928 - accuracy: 0.7392\n",
            "1548/1548 [==============================] - 6s 3ms/step - loss: 0.6307 - accuracy: 0.7053\n",
            "387/387 [==============================] - 1s 2ms/step - loss: 0.5858 - accuracy: 0.7383\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.6278 - accuracy: 0.7145\n",
            "387/387 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.7287\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.6229 - accuracy: 0.7091\n",
            "387/387 [==============================] - 1s 3ms/step - loss: 0.5906 - accuracy: 0.7344\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.6276 - accuracy: 0.7049\n",
            "387/387 [==============================] - 1s 2ms/step - loss: 0.5957 - accuracy: 0.7271\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.6320 - accuracy: 0.7217\n",
            "387/387 [==============================] - 1s 2ms/step - loss: 0.5931 - accuracy: 0.7382\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.6335 - accuracy: 0.7203\n",
            "387/387 [==============================] - 1s 2ms/step - loss: 0.5848 - accuracy: 0.7395\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.6313 - accuracy: 0.7216\n",
            "387/387 [==============================] - 1s 2ms/step - loss: 0.5945 - accuracy: 0.7286\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.6321 - accuracy: 0.7177\n",
            "387/387 [==============================] - 1s 3ms/step - loss: 0.5891 - accuracy: 0.7317\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.6317 - accuracy: 0.7213\n",
            "387/387 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.7172\n",
            "1548/1548 [==============================] - 7s 4ms/step - loss: 0.6299 - accuracy: 0.7163\n",
            "387/387 [==============================] - 1s 3ms/step - loss: 0.5925 - accuracy: 0.7399\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.6338 - accuracy: 0.7173\n",
            "387/387 [==============================] - 1s 2ms/step - loss: 0.5858 - accuracy: 0.7380\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.6326 - accuracy: 0.7170\n",
            "387/387 [==============================] - 1s 2ms/step - loss: 0.5953 - accuracy: 0.7286\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.6343 - accuracy: 0.7170\n",
            "387/387 [==============================] - 1s 2ms/step - loss: 0.5905 - accuracy: 0.7331\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.6324 - accuracy: 0.7119\n",
            "387/387 [==============================] - 1s 2ms/step - loss: 0.5960 - accuracy: 0.7227\n",
            "1935/1935 [==============================] - 6s 3ms/step - loss: 0.6202 - accuracy: 0.7143\n",
            "Epoch 1/20\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.6301 - accuracy: 0.7192\n",
            "Epoch 2/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5911 - accuracy: 0.7343\n",
            "Epoch 3/20\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5891 - accuracy: 0.7349\n",
            "Epoch 4/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5887 - accuracy: 0.7358\n",
            "Epoch 5/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5885 - accuracy: 0.7358\n",
            "Epoch 6/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5885 - accuracy: 0.7348\n",
            "Epoch 7/20\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5884 - accuracy: 0.7348\n",
            "Epoch 8/20\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5883 - accuracy: 0.7350\n",
            "Epoch 9/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5880 - accuracy: 0.7369\n",
            "Epoch 10/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5881 - accuracy: 0.7352\n",
            "Epoch 11/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5877 - accuracy: 0.7361\n",
            "Epoch 12/20\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5880 - accuracy: 0.7345\n",
            "Epoch 13/20\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5881 - accuracy: 0.7356\n",
            "Epoch 14/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5881 - accuracy: 0.7362\n",
            "Epoch 15/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5879 - accuracy: 0.7367\n",
            "Epoch 16/20\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5880 - accuracy: 0.7351\n",
            "Epoch 17/20\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5879 - accuracy: 0.7360\n",
            "Epoch 18/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5880 - accuracy: 0.7356\n",
            "Epoch 19/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5880 - accuracy: 0.7352\n",
            "Epoch 20/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5879 - accuracy: 0.7360\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.5883 - accuracy: 0.7415\n",
            "Epoch 1/20\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5886 - accuracy: 0.7364\n",
            "Epoch 2/20\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5884 - accuracy: 0.7366\n",
            "Epoch 3/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5887 - accuracy: 0.7359\n",
            "Epoch 4/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5886 - accuracy: 0.7377\n",
            "Epoch 5/20\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5887 - accuracy: 0.7349\n",
            "Epoch 6/20\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5885 - accuracy: 0.7360\n",
            "Epoch 7/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5885 - accuracy: 0.7348\n",
            "Epoch 8/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5888 - accuracy: 0.7345\n",
            "Epoch 9/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5885 - accuracy: 0.7364\n",
            "Epoch 10/20\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5884 - accuracy: 0.7350\n",
            "Epoch 11/20\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5886 - accuracy: 0.7350\n",
            "Epoch 12/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5886 - accuracy: 0.7353\n",
            "Epoch 13/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5886 - accuracy: 0.7357\n",
            "Epoch 14/20\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5887 - accuracy: 0.7358\n",
            "Epoch 15/20\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5888 - accuracy: 0.7357\n",
            "Epoch 16/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5885 - accuracy: 0.7345\n",
            "Epoch 17/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5885 - accuracy: 0.7358\n",
            "Epoch 18/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5886 - accuracy: 0.7341\n",
            "Epoch 19/20\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5884 - accuracy: 0.7353\n",
            "Epoch 20/20\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5886 - accuracy: 0.7355\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.5865 - accuracy: 0.7391\n",
            "Epoch 1/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5877 - accuracy: 0.7354\n",
            "Epoch 2/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5878 - accuracy: 0.7363\n",
            "Epoch 3/20\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5879 - accuracy: 0.7385\n",
            "Epoch 4/20\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5878 - accuracy: 0.7359\n",
            "Epoch 5/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5879 - accuracy: 0.7351\n",
            "Epoch 6/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5876 - accuracy: 0.7364\n",
            "Epoch 7/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5876 - accuracy: 0.7353\n",
            "Epoch 8/20\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5879 - accuracy: 0.7377\n",
            "Epoch 9/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5878 - accuracy: 0.7358\n",
            "Epoch 10/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5878 - accuracy: 0.7363\n",
            "Epoch 11/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5877 - accuracy: 0.7364\n",
            "Epoch 12/20\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5880 - accuracy: 0.7359\n",
            "Epoch 13/20\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5879 - accuracy: 0.7360\n",
            "Epoch 14/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5879 - accuracy: 0.7350\n",
            "Epoch 15/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5877 - accuracy: 0.7360\n",
            "Epoch 16/20\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5876 - accuracy: 0.7359\n",
            "Epoch 17/20\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5877 - accuracy: 0.7363\n",
            "Epoch 18/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5877 - accuracy: 0.7354\n",
            "Epoch 19/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5877 - accuracy: 0.7352\n",
            "Epoch 20/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5877 - accuracy: 0.7368\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.5873 - accuracy: 0.7425\n",
            "Epoch 1/20\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5871 - accuracy: 0.7365\n",
            "Epoch 2/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5871 - accuracy: 0.7366\n",
            "Epoch 3/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5871 - accuracy: 0.7375\n",
            "Epoch 4/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5870 - accuracy: 0.7375\n",
            "Epoch 5/20\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5871 - accuracy: 0.7361\n",
            "Epoch 6/20\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5870 - accuracy: 0.7359\n",
            "Epoch 7/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5870 - accuracy: 0.7367\n",
            "Epoch 8/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5870 - accuracy: 0.7369\n",
            "Epoch 9/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5871 - accuracy: 0.7374\n",
            "Epoch 10/20\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5872 - accuracy: 0.7356\n",
            "Epoch 11/20\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5872 - accuracy: 0.7366\n",
            "Epoch 12/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7371\n",
            "Epoch 13/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5871 - accuracy: 0.7356\n",
            "Epoch 14/20\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5872 - accuracy: 0.7355\n",
            "Epoch 15/20\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5870 - accuracy: 0.7365\n",
            "Epoch 16/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5869 - accuracy: 0.7368\n",
            "Epoch 17/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7363\n",
            "Epoch 18/20\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5870 - accuracy: 0.7357\n",
            "Epoch 19/20\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5870 - accuracy: 0.7356\n",
            "Epoch 20/20\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5870 - accuracy: 0.7373\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.5892 - accuracy: 0.7322\n",
            "Epoch 1/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5882 - accuracy: 0.7331\n",
            "Epoch 2/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5881 - accuracy: 0.7344\n",
            "Epoch 3/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5878 - accuracy: 0.7329\n",
            "Epoch 4/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5880 - accuracy: 0.7349\n",
            "Epoch 5/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5880 - accuracy: 0.7351\n",
            "Epoch 6/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5882 - accuracy: 0.7342\n",
            "Epoch 7/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5881 - accuracy: 0.7341\n",
            "Epoch 8/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5881 - accuracy: 0.7343\n",
            "Epoch 9/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5879 - accuracy: 0.7367\n",
            "Epoch 10/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5880 - accuracy: 0.7345\n",
            "Epoch 11/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5877 - accuracy: 0.7355\n",
            "Epoch 12/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5879 - accuracy: 0.7341\n",
            "Epoch 13/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5880 - accuracy: 0.7360\n",
            "Epoch 14/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5880 - accuracy: 0.7354\n",
            "Epoch 15/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5879 - accuracy: 0.7352\n",
            "Epoch 16/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5880 - accuracy: 0.7347\n",
            "Epoch 17/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5879 - accuracy: 0.7349\n",
            "Epoch 18/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5881 - accuracy: 0.7339\n",
            "Epoch 19/30\n",
            "2322/2322 [==============================] - 4s 2ms/step - loss: 0.5880 - accuracy: 0.7350\n",
            "Epoch 20/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5879 - accuracy: 0.7349\n",
            "Epoch 21/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5878 - accuracy: 0.7353\n",
            "Epoch 22/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5879 - accuracy: 0.7366\n",
            "Epoch 23/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5881 - accuracy: 0.7349\n",
            "Epoch 24/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5879 - accuracy: 0.7353\n",
            "Epoch 25/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5881 - accuracy: 0.7356\n",
            "Epoch 26/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5880 - accuracy: 0.7346\n",
            "Epoch 27/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5880 - accuracy: 0.7356\n",
            "Epoch 28/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5877 - accuracy: 0.7357\n",
            "Epoch 29/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5880 - accuracy: 0.7333\n",
            "Epoch 30/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5879 - accuracy: 0.7352\n",
            "774/774 [==============================] - 2s 2ms/step - loss: 0.5877 - accuracy: 0.7356\n",
            "Epoch 1/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5886 - accuracy: 0.7358\n",
            "Epoch 2/30\n",
            "2322/2322 [==============================] - 7s 3ms/step - loss: 0.5884 - accuracy: 0.7354\n",
            "Epoch 3/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5887 - accuracy: 0.7354\n",
            "Epoch 4/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5886 - accuracy: 0.7365\n",
            "Epoch 5/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5887 - accuracy: 0.7342\n",
            "Epoch 6/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5885 - accuracy: 0.7361\n",
            "Epoch 7/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5885 - accuracy: 0.7337\n",
            "Epoch 8/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5888 - accuracy: 0.7347\n",
            "Epoch 9/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5885 - accuracy: 0.7371\n",
            "Epoch 10/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5886 - accuracy: 0.7345\n",
            "Epoch 11/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5886 - accuracy: 0.7345\n",
            "Epoch 12/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5886 - accuracy: 0.7344\n",
            "Epoch 13/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5887 - accuracy: 0.7350\n",
            "Epoch 14/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5887 - accuracy: 0.7349\n",
            "Epoch 15/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5888 - accuracy: 0.7355\n",
            "Epoch 16/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5885 - accuracy: 0.7340\n",
            "Epoch 17/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5885 - accuracy: 0.7348\n",
            "Epoch 18/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5886 - accuracy: 0.7334\n",
            "Epoch 19/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5885 - accuracy: 0.7361\n",
            "Epoch 20/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5886 - accuracy: 0.7351\n",
            "Epoch 21/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5886 - accuracy: 0.7359\n",
            "Epoch 22/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5884 - accuracy: 0.7356\n",
            "Epoch 23/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5884 - accuracy: 0.7367\n",
            "Epoch 24/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5884 - accuracy: 0.7367\n",
            "Epoch 25/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5885 - accuracy: 0.7365\n",
            "Epoch 26/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5885 - accuracy: 0.7352\n",
            "Epoch 27/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5884 - accuracy: 0.7372\n",
            "Epoch 28/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5886 - accuracy: 0.7346\n",
            "Epoch 29/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5886 - accuracy: 0.7370\n",
            "Epoch 30/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5884 - accuracy: 0.7354\n",
            "774/774 [==============================] - 1s 2ms/step - loss: 0.5865 - accuracy: 0.7354\n",
            "Epoch 1/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5876 - accuracy: 0.7358\n",
            "Epoch 2/30\n",
            "2322/2322 [==============================] - 7s 3ms/step - loss: 0.5876 - accuracy: 0.7374\n",
            "Epoch 3/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5877 - accuracy: 0.7377\n",
            "Epoch 4/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5877 - accuracy: 0.7349\n",
            "Epoch 5/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5876 - accuracy: 0.7354\n",
            "Epoch 6/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5875 - accuracy: 0.7371\n",
            "Epoch 7/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5875 - accuracy: 0.7357\n",
            "Epoch 8/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5877 - accuracy: 0.7370\n",
            "Epoch 9/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5876 - accuracy: 0.7360\n",
            "Epoch 10/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5877 - accuracy: 0.7371\n",
            "Epoch 11/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5876 - accuracy: 0.7361\n",
            "Epoch 12/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5878 - accuracy: 0.7366\n",
            "Epoch 13/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5877 - accuracy: 0.7361\n",
            "Epoch 14/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5878 - accuracy: 0.7349\n",
            "Epoch 15/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5876 - accuracy: 0.7366\n",
            "Epoch 16/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5875 - accuracy: 0.7355\n",
            "Epoch 17/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5876 - accuracy: 0.7367\n",
            "Epoch 18/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5876 - accuracy: 0.7356\n",
            "Epoch 19/30\n",
            "2322/2322 [==============================] - 4s 2ms/step - loss: 0.5876 - accuracy: 0.7354\n",
            "Epoch 20/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5876 - accuracy: 0.7362\n",
            "Epoch 21/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5876 - accuracy: 0.7344\n",
            "Epoch 22/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5877 - accuracy: 0.7347\n",
            "Epoch 23/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5876 - accuracy: 0.7373\n",
            "Epoch 24/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5874 - accuracy: 0.7376\n",
            "Epoch 25/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5877 - accuracy: 0.7361\n",
            "Epoch 26/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5877 - accuracy: 0.7355\n",
            "Epoch 27/30\n",
            "2322/2322 [==============================] - 7s 3ms/step - loss: 0.5877 - accuracy: 0.7380\n",
            "Epoch 28/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5878 - accuracy: 0.7353\n",
            "Epoch 29/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5877 - accuracy: 0.7362\n",
            "Epoch 30/30\n",
            "2322/2322 [==============================] - 7s 3ms/step - loss: 0.5876 - accuracy: 0.7371\n",
            "774/774 [==============================] - 1s 2ms/step - loss: 0.5897 - accuracy: 0.7330\n",
            "Epoch 1/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5870 - accuracy: 0.7376\n",
            "Epoch 2/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5870 - accuracy: 0.7354\n",
            "Epoch 3/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5870 - accuracy: 0.7373\n",
            "Epoch 4/30\n",
            "2322/2322 [==============================] - 4s 2ms/step - loss: 0.5869 - accuracy: 0.7369\n",
            "Epoch 5/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5869 - accuracy: 0.7360\n",
            "Epoch 6/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5869 - accuracy: 0.7361\n",
            "Epoch 7/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5869 - accuracy: 0.7369\n",
            "Epoch 8/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5870 - accuracy: 0.7368\n",
            "Epoch 9/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5870 - accuracy: 0.7368\n",
            "Epoch 10/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5871 - accuracy: 0.7353\n",
            "Epoch 11/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5871 - accuracy: 0.7375\n",
            "Epoch 12/30\n",
            "2322/2322 [==============================] - 7s 3ms/step - loss: 0.5871 - accuracy: 0.7361\n",
            "Epoch 13/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5869 - accuracy: 0.7349\n",
            "Epoch 14/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5871 - accuracy: 0.7357\n",
            "Epoch 15/30\n",
            "2322/2322 [==============================] - 7s 3ms/step - loss: 0.5869 - accuracy: 0.7362\n",
            "Epoch 16/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5867 - accuracy: 0.7370\n",
            "Epoch 17/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5871 - accuracy: 0.7368\n",
            "Epoch 18/30\n",
            "2322/2322 [==============================] - 7s 3ms/step - loss: 0.5869 - accuracy: 0.7364\n",
            "Epoch 19/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5869 - accuracy: 0.7360\n",
            "Epoch 20/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5869 - accuracy: 0.7376\n",
            "Epoch 21/30\n",
            "2322/2322 [==============================] - 7s 3ms/step - loss: 0.5871 - accuracy: 0.7352\n",
            "Epoch 22/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5870 - accuracy: 0.7354\n",
            "Epoch 23/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5870 - accuracy: 0.7347\n",
            "Epoch 24/30\n",
            "2322/2322 [==============================] - 6s 3ms/step - loss: 0.5868 - accuracy: 0.7356\n",
            "Epoch 25/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5872 - accuracy: 0.7351\n",
            "Epoch 26/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5870 - accuracy: 0.7376\n",
            "Epoch 27/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5870 - accuracy: 0.7359\n",
            "Epoch 28/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5871 - accuracy: 0.7356\n",
            "Epoch 29/30\n",
            "2322/2322 [==============================] - 5s 2ms/step - loss: 0.5869 - accuracy: 0.7368\n",
            "Epoch 30/30\n",
            "2322/2322 [==============================] - 6s 2ms/step - loss: 0.5869 - accuracy: 0.7354\n",
            "774/774 [==============================] - 1s 2ms/step - loss: 0.5888 - accuracy: 0.7290\n",
            "Epoch 1/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5874 - accuracy: 0.7355\n",
            "Epoch 2/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7369\n",
            "Epoch 3/30\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5871 - accuracy: 0.7383\n",
            "Epoch 4/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5872 - accuracy: 0.7381\n",
            "Epoch 5/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7373\n",
            "Epoch 6/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7352\n",
            "Epoch 7/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7364\n",
            "Epoch 8/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5874 - accuracy: 0.7358\n",
            "Epoch 9/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5872 - accuracy: 0.7378\n",
            "Epoch 10/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7364\n",
            "Epoch 11/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5870 - accuracy: 0.7372\n",
            "Epoch 12/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7362\n",
            "Epoch 13/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5873 - accuracy: 0.7383\n",
            "Epoch 14/30\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5874 - accuracy: 0.7373\n",
            "Epoch 15/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7382\n",
            "Epoch 16/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7361\n",
            "Epoch 17/30\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5872 - accuracy: 0.7374\n",
            "Epoch 18/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5874 - accuracy: 0.7385\n",
            "Epoch 19/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7372\n",
            "Epoch 20/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7373\n",
            "Epoch 21/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7372\n",
            "Epoch 22/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5872 - accuracy: 0.7385\n",
            "Epoch 23/30\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5874 - accuracy: 0.7370\n",
            "Epoch 24/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7373\n",
            "Epoch 25/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5874 - accuracy: 0.7376\n",
            "Epoch 26/30\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5872 - accuracy: 0.7363\n",
            "Epoch 27/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5873 - accuracy: 0.7381\n",
            "Epoch 28/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5870 - accuracy: 0.7381\n",
            "Epoch 29/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7360\n",
            "Epoch 30/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7369\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.5872 - accuracy: 0.7391\n",
            "Epoch 1/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5880 - accuracy: 0.7368\n",
            "Epoch 2/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5878 - accuracy: 0.7372\n",
            "Epoch 3/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5881 - accuracy: 0.7369\n",
            "Epoch 4/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5880 - accuracy: 0.7378\n",
            "Epoch 5/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5880 - accuracy: 0.7366\n",
            "Epoch 6/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5879 - accuracy: 0.7372\n",
            "Epoch 7/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5879 - accuracy: 0.7359\n",
            "Epoch 8/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5881 - accuracy: 0.7357\n",
            "Epoch 9/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5880 - accuracy: 0.7385\n",
            "Epoch 10/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5879 - accuracy: 0.7361\n",
            "Epoch 11/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5880 - accuracy: 0.7363\n",
            "Epoch 12/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5880 - accuracy: 0.7373\n",
            "Epoch 13/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5880 - accuracy: 0.7379\n",
            "Epoch 14/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5881 - accuracy: 0.7372\n",
            "Epoch 15/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5881 - accuracy: 0.7367\n",
            "Epoch 16/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5880 - accuracy: 0.7354\n",
            "Epoch 17/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5879 - accuracy: 0.7372\n",
            "Epoch 18/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5880 - accuracy: 0.7362\n",
            "Epoch 19/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5879 - accuracy: 0.7377\n",
            "Epoch 20/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5880 - accuracy: 0.7366\n",
            "Epoch 21/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5881 - accuracy: 0.7374\n",
            "Epoch 22/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5879 - accuracy: 0.7376\n",
            "Epoch 23/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5878 - accuracy: 0.7385\n",
            "Epoch 24/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5879 - accuracy: 0.7380\n",
            "Epoch 25/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5880 - accuracy: 0.7379\n",
            "Epoch 26/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5880 - accuracy: 0.7373\n",
            "Epoch 27/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5879 - accuracy: 0.7392\n",
            "Epoch 28/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5881 - accuracy: 0.7364\n",
            "Epoch 29/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5880 - accuracy: 0.7378\n",
            "Epoch 30/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5880 - accuracy: 0.7375\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.5858 - accuracy: 0.7346\n",
            "Epoch 1/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7383\n",
            "Epoch 2/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5872 - accuracy: 0.7377\n",
            "Epoch 3/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5873 - accuracy: 0.7390\n",
            "Epoch 4/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7374\n",
            "Epoch 5/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7375\n",
            "Epoch 6/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5871 - accuracy: 0.7384\n",
            "Epoch 7/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5871 - accuracy: 0.7379\n",
            "Epoch 8/30\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5872 - accuracy: 0.7381\n",
            "Epoch 9/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7363\n",
            "Epoch 10/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7389\n",
            "Epoch 11/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5871 - accuracy: 0.7387\n",
            "Epoch 12/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5873 - accuracy: 0.7379\n",
            "Epoch 13/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7370\n",
            "Epoch 14/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7370\n",
            "Epoch 15/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7383\n",
            "Epoch 16/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5871 - accuracy: 0.7384\n",
            "Epoch 17/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5872 - accuracy: 0.7383\n",
            "Epoch 18/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5871 - accuracy: 0.7376\n",
            "Epoch 19/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5871 - accuracy: 0.7379\n",
            "Epoch 20/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7383\n",
            "Epoch 21/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5872 - accuracy: 0.7357\n",
            "Epoch 22/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5873 - accuracy: 0.7373\n",
            "Epoch 23/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7392\n",
            "Epoch 24/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5870 - accuracy: 0.7389\n",
            "Epoch 25/30\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5872 - accuracy: 0.7377\n",
            "Epoch 26/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5873 - accuracy: 0.7372\n",
            "Epoch 27/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5872 - accuracy: 0.7396\n",
            "Epoch 28/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7379\n",
            "Epoch 29/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5873 - accuracy: 0.7380\n",
            "Epoch 30/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5872 - accuracy: 0.7380\n",
            "516/516 [==============================] - 1s 3ms/step - loss: 0.5900 - accuracy: 0.7305\n",
            "Epoch 1/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5866 - accuracy: 0.7385\n",
            "Epoch 2/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5865 - accuracy: 0.7374\n",
            "Epoch 3/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5865 - accuracy: 0.7391\n",
            "Epoch 4/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5865 - accuracy: 0.7384\n",
            "Epoch 5/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5865 - accuracy: 0.7389\n",
            "Epoch 6/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5865 - accuracy: 0.7371\n",
            "Epoch 7/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5865 - accuracy: 0.7382\n",
            "Epoch 8/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5865 - accuracy: 0.7390\n",
            "Epoch 9/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5866 - accuracy: 0.7378\n",
            "Epoch 10/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5866 - accuracy: 0.7365\n",
            "Epoch 11/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5866 - accuracy: 0.7380\n",
            "Epoch 12/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5866 - accuracy: 0.7381\n",
            "Epoch 13/30\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5866 - accuracy: 0.7363\n",
            "Epoch 14/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5866 - accuracy: 0.7369\n",
            "Epoch 15/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5865 - accuracy: 0.7390\n",
            "Epoch 16/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5864 - accuracy: 0.7387\n",
            "Epoch 17/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5866 - accuracy: 0.7385\n",
            "Epoch 18/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5865 - accuracy: 0.7374\n",
            "Epoch 19/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5864 - accuracy: 0.7376\n",
            "Epoch 20/30\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5865 - accuracy: 0.7388\n",
            "Epoch 21/30\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5865 - accuracy: 0.7372\n",
            "Epoch 22/30\n",
            "1548/1548 [==============================] - 4s 3ms/step - loss: 0.5866 - accuracy: 0.7359\n",
            "Epoch 23/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5865 - accuracy: 0.7371\n",
            "Epoch 24/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5864 - accuracy: 0.7377\n",
            "Epoch 25/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5867 - accuracy: 0.7370\n",
            "Epoch 26/30\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5865 - accuracy: 0.7386\n",
            "Epoch 27/30\n",
            "1548/1548 [==============================] - 5s 3ms/step - loss: 0.5865 - accuracy: 0.7382\n",
            "Epoch 28/30\n",
            "1548/1548 [==============================] - 4s 2ms/step - loss: 0.5866 - accuracy: 0.7378\n",
            "Epoch 29/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5865 - accuracy: 0.7374\n",
            "Epoch 30/30\n",
            "1548/1548 [==============================] - 3s 2ms/step - loss: 0.5865 - accuracy: 0.7367\n",
            "516/516 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7326\n",
            "Epoch 1/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5872 - accuracy: 0.7374\n",
            "Epoch 2/20\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5873 - accuracy: 0.7378\n",
            "Epoch 3/20\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5871 - accuracy: 0.7376\n",
            "Epoch 4/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5873 - accuracy: 0.7386\n",
            "Epoch 5/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5872 - accuracy: 0.7396\n",
            "Epoch 6/20\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5871 - accuracy: 0.7396\n",
            "Epoch 7/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5871 - accuracy: 0.7375\n",
            "Epoch 8/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5872 - accuracy: 0.7377\n",
            "Epoch 9/20\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5873 - accuracy: 0.7378\n",
            "Epoch 10/20\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5871 - accuracy: 0.7382\n",
            "Epoch 11/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5871 - accuracy: 0.7373\n",
            "Epoch 12/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5872 - accuracy: 0.7375\n",
            "Epoch 13/20\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5873 - accuracy: 0.7384\n",
            "Epoch 14/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5872 - accuracy: 0.7379\n",
            "Epoch 15/20\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.5872 - accuracy: 0.7379\n",
            "Epoch 16/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5872 - accuracy: 0.7400\n",
            "Epoch 17/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5872 - accuracy: 0.7375\n",
            "Epoch 18/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5872 - accuracy: 0.7377\n",
            "Epoch 19/20\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5872 - accuracy: 0.7384\n",
            "Epoch 20/20\n",
            "2064/2064 [==============================] - 4s 2ms/step - loss: 0.5871 - accuracy: 0.7380\n",
            "Epoch 1/20\n",
            "2064/2064 [==============================] - 7s 3ms/step - loss: 0.5872 - accuracy: 0.7376\n",
            "Epoch 2/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5872 - accuracy: 0.7379\n",
            "Epoch 3/20\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.5871 - accuracy: 0.7378\n",
            "Epoch 4/20\n",
            "2064/2064 [==============================] - 7s 3ms/step - loss: 0.5872 - accuracy: 0.7387\n",
            "Epoch 5/20\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.5871 - accuracy: 0.7396\n",
            "Epoch 6/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5871 - accuracy: 0.7397\n",
            "Epoch 7/20\n",
            "2064/2064 [==============================] - 7s 3ms/step - loss: 0.5871 - accuracy: 0.7377\n",
            "Epoch 8/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5871 - accuracy: 0.7377\n",
            "Epoch 9/20\n",
            "2064/2064 [==============================] - 7s 3ms/step - loss: 0.5872 - accuracy: 0.7383\n",
            "Epoch 10/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5871 - accuracy: 0.7383\n",
            "Epoch 11/20\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.5871 - accuracy: 0.7373\n",
            "Epoch 12/20\n",
            "2064/2064 [==============================] - 7s 4ms/step - loss: 0.5872 - accuracy: 0.7379\n",
            "Epoch 13/20\n",
            "2064/2064 [==============================] - 5s 3ms/step - loss: 0.5873 - accuracy: 0.7384\n",
            "Epoch 14/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5872 - accuracy: 0.7380\n",
            "Epoch 15/20\n",
            "2064/2064 [==============================] - 7s 3ms/step - loss: 0.5872 - accuracy: 0.7379\n",
            "Epoch 16/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5872 - accuracy: 0.7398\n",
            "Epoch 17/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5872 - accuracy: 0.7376\n",
            "Epoch 18/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5872 - accuracy: 0.7377\n",
            "Epoch 19/20\n",
            "2064/2064 [==============================] - 5s 2ms/step - loss: 0.5872 - accuracy: 0.7385\n",
            "Epoch 20/20\n",
            "2064/2064 [==============================] - 6s 3ms/step - loss: 0.5871 - accuracy: 0.7378\n",
            "830/830 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "bQJA0jz9HRsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parametros utilizados"
      ],
      "metadata": {
        "id": "5troSjUFMnNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55ca7d85-1d77-4d5a-e859-b9728877ca2c",
        "id": "z27WerlVHRsA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epochs': 2, 'batch_size': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_architecture"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1761737-f0c3-4ba2-ce86-cdd183f50575",
        "id": "RRNP3tgPHRsB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neurons': 64, 'hidden_layers': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'epochs': 2, 'batch_size': 10}{'neurons': 64, 'hidden_layers': 2}"
      ],
      "metadata": {
        "id": "jaA6yBE-HRsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matriz de confusion"
      ],
      "metadata": {
        "id": "TZoW12RVdjO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_training = random_search_training.best_params_\n",
        "best_training\n",
        "# Entrenamos el modelo con el dataset completo\n",
        "best_model.fit(x_train_norm, y_train, epochs=best_training['epochs'], batch_size=best_training['batch_size'])\n",
        "\n",
        "# Obtenemos predicciones\n",
        "y_probs = best_model.predict(x_test_norm)\n",
        "y_predictions = (y_probs > 0.5).astype(int)  # Assuming binary classification\n",
        "\n",
        "y_pred = np.ravel(y_predictions)\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "# {'epochs': 20, 'batch_size': 30}\n",
        "\n",
        "#Creo la matriz de confusión\n",
        "tabla=confusion_matrix(y_test, y_pred)\n",
        "\n",
        "#Grafico la matriz de confusión\n",
        "sns.heatmap(tabla,cmap='GnBu',annot=True,fmt='g')\n",
        "plt.xlabel('Valores predichos')\n",
        "plt.ylabel('Valores reales')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "78Z1vKbEdmTJ",
        "outputId": "cc9a5c10-8884-44ad-bfa9-b70d8eb7812a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.4873 - accuracy: 0.7614\n",
            "Epoch 2/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.4845 - accuracy: 0.7620\n",
            "Epoch 3/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.4820 - accuracy: 0.7622\n",
            "Epoch 4/10\n",
            "1734/1734 [==============================] - 6s 4ms/step - loss: 0.4799 - accuracy: 0.7627\n",
            "Epoch 5/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.4780 - accuracy: 0.7636\n",
            "Epoch 6/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.4763 - accuracy: 0.7638\n",
            "Epoch 7/10\n",
            "1734/1734 [==============================] - 5s 3ms/step - loss: 0.4748 - accuracy: 0.7641\n",
            "Epoch 8/10\n",
            "1734/1734 [==============================] - 5s 3ms/step - loss: 0.4734 - accuracy: 0.7649\n",
            "Epoch 9/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.4722 - accuracy: 0.7650\n",
            "Epoch 10/10\n",
            "1734/1734 [==============================] - 4s 2ms/step - loss: 0.4710 - accuracy: 0.7654\n",
            "581/581 [==============================] - 1s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.83      0.78      9292\n",
            "           1       0.80      0.70      0.75      9281\n",
            "\n",
            "    accuracy                           0.76     18573\n",
            "   macro avg       0.77      0.76      0.76     18573\n",
            "weighted avg       0.77      0.76      0.76     18573\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(50.722222222222214, 0.5, 'Valores reales')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iFsey0zzdE9L",
        "8oPUOPtT9YjY",
        "1iQNUHqxUjA6",
        "VfbYNPCCTKOa",
        "wio1rSiEZLjz",
        "Leqq7nQ6cQT8",
        "z8LbecNe90t5",
        "xv3X1G8C9CuQ",
        "olZTeiorPNxy",
        "BdNAl_48eBn0",
        "NIoAnupaczqf",
        "3StlrnZmHRr_"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}